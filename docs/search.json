[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EA Market testing data analysis",
    "section": "",
    "text": "However, we’re not sure yet if and how it can be integrated with the https://app.gitbook.com/ content.↩︎\nNote: as this is Quarto and not Rmd, packages need to be loaded in every chapter. I’ll put these in code/shared_packages_code.R.↩︎"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html",
    "href": "chapters/oftw_upsell_input_first_analysis.html",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "",
    "text": "In December 2021, OftW sent out a sequence of emails to existing OftW pledgers/participants asking them for an additional donation. Ther e were two ‘treatment variants’; an emotional email and a standard impact-based email. The treatment was constant by individual (the same person always got emails with the same theme.\nThe details are presented in our (currently private) gitbook HERE and in the linked pre-registration (also on OSF)."
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#capturing-data",
    "href": "chapters/oftw_upsell_input_first_analysis.html#capturing-data",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.2 Capturing data",
    "text": "1.2 Capturing data\nKennan and Chloe captured the data and Metadata from\n\nThe OFTW database\nSurveyMonkey\n\nPutting this into the (private) Google sheet linked HERE\nWe added some metadata/explainers to that data.1"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#input-and-clean-data",
    "href": "chapters/oftw_upsell_input_first_analysis.html#input-and-clean-data",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.3 Input and clean data",
    "text": "1.3 Input and clean data\nWe input the sheets from the external Google sheet location (access required)…\n\n\nCode\ngs4_auth(scope = \"https://www.googleapis.com/auth/drive\")\ndrive_auth(token = gs4_token())\n\n#Mailchimp data \n\noftw_21_22_mc <- read_sheet(\"https://docs.google.com/spreadsheets/d/1iUKXkEqoadBgtUG_epBzUzCgA_J5mdWWstcXtpAdNJs/edit#gid=521638649\", \n  sheet=\"Raw data (Mailchimp)\")  %>% \n  select(-`Treatment group`) %>%  #remove an un-useful repeated name column \n    mutate(`Treatment Group` = purrr::map_chr(`Treatment Group`, ~ .[[1]])) %>%\n  select(`Email Address`, `Email Date`, `Treatment Group`, Opens, `Donate link clicks`, everything()) %>% #Most relevant features organized first\n  arrange(`Email Address`)\n\n\n#later: remove features brought in from OFTW database, reconstruct it\n\noftw_21_22_mc %>% names() %>% paste(collapse=\", \")\n\n\n[1] \"Email Address, Email Date, Treatment Group, Opens, Donate link clicks, sheet_descriptor, First Name, Last Name, Email Number, Class Year, Donor status, Total Given, Donation amount, Donation frequency, Start string, Platform, Portfolio string, Class lead, Impact 1, Impact 2, Impact 3, Employer, Pledge string, School string, Pledge year, Cancellation Type, Donation Amount String, OFTW matching, OFTW match amount, Corporate match amount, Bonuses announced, Post-bonus contact date, Email Preferences, Start Date, Lives Saved, Member Rating, Record rank, Total Giving Season contributions, Total Giving Season contribution amount\"\n\n\nCode\n#...input descriptors for the above (do this later from \"doc: ...Mailchimp\" sheet\n\n\n\n\nCode\n#Donations data (and OftW database info)\n\noftw_21_22_db_don <- read_sheet(\n  \"https://docs.google.com/spreadsheets/d/1iUKXkEqoadBgtUG_epBzUzCgA_J5mdWWstcXtpAdNJs/edit#gid=521638649\", \n  sheet=\"Giving Season contributions (BigQuery)\") %>% \n  mutate(`Treatment group` = purrr::map_chr(`Treatment group`, ~ .[[1]])) %>%\n    select(`email`, `primary_email`, `donation_date`, `Net_Contribution_Amount_USD`, `payment_platform`, everything()) %>%  #Most relevant features organized first\n  filter(donation_date>=as.Date(\"2021-11-15\")) # At least for now, remove pre-treatment donation data\n\noftw_21_22_db_don %>% names() %>% paste(collapse=\", \")\n\n\n[1] \"email, primary_email, donation_date, Net_Contribution_Amount_USD, payment_platform, Treatment group, Number of email opens, oftw_partner, school, chapter_type, portfolio, contribution_frequency, pledge_date, pledge_start_date, pledge_end_date, donor_status, cancellation_type, pledge_amount, pledge_contribution_frequency, x\"\n\n\n\n\n1.3.1 Labeling and cleaning\nThe code …\n…makes names snake_case, using original names as labels…\n\n\nCode\nlabelled::var_label(oftw_21_22_mc) <- names(oftw_21_22_mc) \nnames(oftw_21_22_mc) <- snakecase::to_snake_case(names(oftw_21_22_mc)) \n\nlabelled::var_label(oftw_21_22_db_don) <- names(oftw_21_22_db_don) \nnames(oftw_21_22_db_don) <- snakecase::to_snake_case(names(oftw_21_22_db_don)) \n\n\n\n…and anonymizes the data, hashing anything with the chance of being identifying\n\n\nCode\nsalty_hash <- function(x) {\n  salt(.seed = 42, x) %>% hash(.algo = \"crc32\")\n}\n\noftw_21_22_mc <- oftw_21_22_mc %>%\n  dplyr::select(-first_name, -last_name) %>%\n    mutate(across(c(email_address,  employer, school_string), salty_hash))\n\n  \noftw_21_22_db_don <- oftw_21_22_db_don %>%\n      mutate(across(c(primary_email, email, school), salty_hash))\n\n\nRoll up to 1 per person; summarize and pivot_wider\n\n\nCode\noutcomes_base_mc <- c(\"opens\", \"donate_link_clicks\")\n\n\noftw_21_22_mc_wide <- oftw_21_22_mc %>%\n  mutate(treat_emotion = case_when(\n    treatment_group == \"1.000000\" ~ 0,\n    treatment_group == \"2.000000\" ~ 1\n  )) %>%\n  group_by(email_address) %>%\n  mutate(across(all_of(outcomes_base_mc), sum, .names = \"{.col}_tot\")) %>%\n  tidyr::pivot_wider(names_from = email_number,\n    values_from = c(\"opens\", \"donate_link_clicks\")) %>%\n  mutate(d_click_don_link = donate_link_clicks_tot > 0) %>%\n  arrange(email_address) %>%\n  filter(row_number() == 1)\n\noftw_21_22_db_don <- oftw_21_22_db_don %>%\n  ungroup() %>%\n  group_by(email) %>%\n  mutate(\n    don_tot = sum(net_contribution_amount_usd),\n    num_don = n(),\n    d_don = num_don > 0,\n    don_tot_ot = sum(net_contribution_amount_usd[contribution_frequency ==\n        \"One-time\"]),\n    num_don_ot = sum(contribution_frequency == \"One-time\"),\n    d_don_ot = num_don_ot > 0,\n    #WAIT THIS IS NOT WIDE DATA -- don't interpret it as 'number of individuals'\n    don_tot_ss = sum(net_contribution_amount_usd[payment_platform == \"Squarespace\"]),\n    num_don_ss = sum(payment_platform == \"Squarespace\"),\n    d_don_ss = num_don_ss > 0,\n  )\n\n\noftw_21_22_db_don_persons <- oftw_21_22_db_don %>%  \n  arrange(email) %>%\n  filter(row_number()==1)     %>%\nmutate(\n      treat_emotion = case_when(\n        treatment_group==\"1.000000\" ~ 0,\n        treatment_group == \"2.000000\" ~ 1)\n    ) \n\n\noftw_mc_db <- power_full_join(oftw_21_22_mc_wide,\n   oftw_21_22_db_don_persons,  by = c(\"email_address\" = \"email\"), conflict = coalesce_xy) %>%\n   mutate(across(starts_with(\"d_don\"), ~replace(., is.na(.), 0)), #make it a 0 if it's not in the donation database\n   d_open= if_else(!is.na(treat_emotion),1,0)\n  )\n\n\noftw_mc_db_openers <- oftw_mc_db %>% \n  filter(!is.na(treat_emotion))\n\n# oftw_21_22_db_don_wide <- oftw_21_22_db_don %>%\n#   select(email, donation_date, net_contribution_amount_usd, payment_platform) %>% \n#    group_by(email) %>%\n#    mutate(row = row_number()) %>%\n#       tidyr::pivot_wider(names_from = row, values_from = c(\"donation_date\", \"net_contribution_amount_usd\"))\n\n\nPrelim results ::: {.cell}\n\nCode\noftw_mc_db %>% tabyl(treat_emotion, d_don)\n\n\n treat_emotion    0   1\n             0 1139 273\n             1  968 231\n            NA    0 395\n\n\nCode\noftw_mc_db %>% tabyl(treat_emotion, d_don_ss)\n\n\n treat_emotion    0 1\n             0 1404 8\n             1 1190 9\n            NA  391 4\n\n\nCode\noftw_21_22_db_don_persons %>% tabyl(treat_emotion, d_don_ot)\n\n\n treat_emotion FALSE TRUE NA_\n             0   248   15  10\n             1   215   12   4\n            NA   328   59   8\n\n\nCode\n#todo: simple statistical measures along with this\n\n:::\n\n\n1.3.2 Constructing outcome measures, especially ‘donations likely driven by email’\n\nDonations (presence, count, amounts) in giving seasons, 1 row per user (with treatment etc.)\n\n\noverall\nnon-regular\n‘likely from email’\n\nare in Giving Season contributions (BigQuery)\n\nsubset for payment platform = squarespace (unlikely to come from any other checkout page)\nemail as primary key, link to Raw Data (mailchimp), filter on ‘Donate link clicks`>0 (note that one needs aggregating by donor because it is ’per email’)\n\n\nGiving season donations ..\n\nGiving Season contributions (BigQuery), sum donation_date Net_Contribution_Amount_USD with filters for one-time etc\nCan check against fields ‘Total Giving Season contributions Total Giving Season contribution amount’\n\n\n\nCode\n#list/matrix of rates for later use\n\noc_mat <- oftw_mc_db %>% \n  mutate(d_open=n()) %>% \n  group_by(treat_emotion) %>% \n  dplyr::summarise(across(starts_with(\"d_\"), ~sum(.x, na.rm = TRUE), .names = \"tot_{.col}\"))\n\noc_mat_r <- oc_mat %>% filter(!is.na(treat_emotion)) #where treatment observed \n\nassigned_emails <- c(2000, 2000) #I was told that about 4000 emails were sent, 2000 to each group"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#descriptives-and-exploratory-analysis",
    "href": "chapters/oftw_upsell_input_first_analysis.html#descriptives-and-exploratory-analysis",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.4 Descriptives and exploratory analysis",
    "text": "1.4 Descriptives and exploratory analysis\nNotes:2\n\n1.4.1 Donation and outcome summary statistics, by treatment"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#basic-tests-donation-incidence-and-amounts",
    "href": "chapters/oftw_upsell_input_first_analysis.html#basic-tests-donation-incidence-and-amounts",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.5 Basic tests: Donation incidence and amounts",
    "text": "1.5 Basic tests: Donation incidence and amounts\n(See preregistration – go through preregistered tests one at a time. Note that given the observed conversion rates I do not expect any ‘significant differences’.)"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#basic-tests-clicks-and-retention-outcomes",
    "href": "chapters/oftw_upsell_input_first_analysis.html#basic-tests-clicks-and-retention-outcomes",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.6 Basic tests: Clicks and retention outcomes",
    "text": "1.6 Basic tests: Clicks and retention outcomes\nI’m following the approach discussed in the ‘RP methods discussion’ under “Significance and equivalence testing” with randomization inference/simulation; building to Bayes\nWe see a ‘small difference’ between treatment groups and it is ‘not significant in standard tests’ (tests not shown here yet). But can we put meaningful bounds on this? Can we statistically ‘rule out large effects’?\n(This parallels the analysis done in HERE, which includes some further explanation of the methods)\n\n\n\n1.6.1 Difference between two binomial random variables: Bayesian binomial test\n\n\nCode\n#would need to generate 'fill in data' if we want to use bayesAB, which requires actual vectors\n\n#add blank rows for 'assigned'\n\nblank_impact <- as_tibble(matrix(NA, nrow = assigned_emails[1]- oc_mat_r$tot_d_open[1], ncol = NCOL(oftw_mc_db)))\n\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0.\nUsing compatibility `.name_repair`.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\n\nCode\nnames(blank_impact) <- names(oftw_mc_db)\n\nblank_impact %<>% \n  mutate(across(starts_with(\"d_\"), ~ifelse(is.na(.), 0, 0)),\n    treat_emotion=0)\n  \nblank_emotion <- as_tibble(matrix(NA, nrow = assigned_emails[1]- oc_mat_r$tot_d_open[2], ncol = NCOL(oftw_mc_db)))\nnames(blank_emotion) <- names(oftw_mc_db)\n\nblank_emotion %<>% \n  mutate(across(starts_with(\"d_\"), ~ifelse(is.na(.), 0, 0)),\n    treat_emotion=1)\n\noftw_mc_db_assigned <- \n    bind_rows(oftw_mc_db, blank_impact, blank_emotion) %>%\n  filter(!is.na(treat_emotion))\n\noftw_mc_db_assigned %>% tabyl(treat_emotion)\n\n\n treat_emotion    n percent\n             0 2000     0.5\n             1 2000     0.5\n\n\nOpens by treatment:\n\n\nCode\n# Following r https://www.sumsar.net/blog/2014/06/bayesian-first-aid-prop-test/  \n# alt: http://frankportman.github.io/bayesAB/ \n\n\n#opens_by_treat_fit <- bayes.prop.test(oc_mat_r$tot_d_open, assigned_emails, cred.mass = 0.95) #here I highlight the 95% bounds because it's a strong effect!\n\n#plot(opens_by_treat_fit)\n\nunif_prior <- c('alpha' = 1, 'beta' = 1)\n \nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_open), 'beta' = sum(assigned_emails))\n\n\n#same with AB  package\n# Fit bernoulli test\nopens_by_treat_AB <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_open[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_open[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\nopens_by_treat_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_open[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_open[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(opens_by_treat_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(opens_by_treat_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\n#WTF -- I need to advance this by command prompt!?\n\n#AB1 <- bayesTest(oftw_21_22_db_don_persons$d_don_ot[trea], B_binom, priors = c('alpha' = 65, 'beta' = 200), n_samples = 1e5, distribution = 'bernoulli')\n\n\n\n\n‘Some donation’ by treatment (only for those who opened, otherwise donations are surely undercounted for Emotion treatment)\n\n\nCode\noftw_21_22_db_don_persons %>% tabyl(treat_emotion, d_don)\n\n\n treat_emotion TRUE\n             0  273\n             1  231\n            NA  395\n\n\nCode\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_don), 'beta' = sum(oc_mat_r$tot_d_open))\n\n(\n  don_by_treat_opened_fit <- bayes.prop.test(oc_mat_r$tot_d_don, oc_mat_r$tot_d_open, cred.mass = 0.80) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_don out of oc_mat_r$tot_d_open\nnumber of successes:   273,  231\nnumber of trials:     1412, 1199\nEstimated relative frequency of success [80% credible interval]:\n  Group 1: 0.19 [0.18, 0.21]\n  Group 2: 0.19 [0.18, 0.21]\nEstimated group difference (Group 1 - Group 2):\n  0 [-0.02, 0.02]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.515 and larger for Group 2 by a probability of 0.485 .\n\n\nCode\nplot(don_by_treat_opened_fit)\n\n\n\n\n\nCode\n#same with AB  package\n# Fit bernoulli test\ndon_by_treat_AB <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don[oftw_mc_db_openers$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_by_treat_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don[oftw_mc_db_openers$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(don_by_treat_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_by_treat_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nThus we put 80% probability on the difference between the donation rates being no more than (hard-coded) .023/.19 = 12% in either direction. Note that this is not terribly narrowly bounded.\n\n\nNext, for one-time donations only; again as a share of opens\n\n\nCode\n(\n  don_ot_by_treat_opened_fit <- bayes.prop.test(oc_mat_r$tot_d_don_ot, oc_mat_r$tot_d_open, cred.mass = 0.80) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_don_ot out of oc_mat_r$tot_d_open\nnumber of successes:    15,   12\nnumber of trials:     1412, 1199\nEstimated relative frequency of success [80% credible interval]:\n  Group 1: 0.011 [0.0075, 0.015]\n  Group 2: 0.011 [0.0068, 0.014]\nEstimated group difference (Group 1 - Group 2):\n  0 [-0.0048, 0.0056]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.55 and larger for Group 2 by a probability of 0.45 .\n\n\nCode\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_don_ot), 'beta' = sum(oc_mat_r$tot_d_open))\n\n#same with AB  package\n# Fit bernoulli test\ndon_ot_by_treat_AB <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don_ot[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don_ot[oftw_mc_db_openers$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_ot_by_treat_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don_ot[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don_ot[oftw_mc_db_openers$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(don_ot_by_treat_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_ot_by_treat_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\ndon_ot_by_treat_AB %>% summary(credInt=0.9)\n\n\nQuantiles of posteriors for A and B:\n\n$Probability\n$Probability$A\n         0%         25%         50%         75%        100% \n0.002702340 0.009300256 0.011076158 0.013056869 0.028481793 \n\n$Probability$B\n         0%         25%         50%         75%        100% \n0.002578133 0.008699817 0.010557270 0.012664164 0.031399003 \n\n\n--------------------------------------------\n\nP(A > B) by (0)%: \n\n$Probability\n[1] 0.5518\n\n--------------------------------------------\n\nCredible Interval on (A - B) / B for interval length(s) (0.9) : \n\n$Probability\n       5%       95% \n-0.434144  0.969118 \n\n--------------------------------------------\n\nPosterior Expected Loss for choosing A over B:\n\n$Probability\n[1] 0.1618676\n\n\nCode\ndon_ot_by_treat_AB_lift_int80 <- don_ot_by_treat_AB %>% summary(credInt=0.8)\n\n\ndon_ot_by_treat_AB_lift_int80_empir <- don_ot_by_treat_AB_empir %>% summary(credInt=0.8)\n\n\n80% credible intervals with the uniform prior for the ‘lift’ of Impact relative to Emotion are\n-0.351, 0.707\nand for the empirically informed (but symmetric prior):\n-0.234, 0.357\n(Hard-coded) Here there is just a trace of suggestive evidence that the emotion treatment performed worse. But even our 80% bounds are very wide.\n\n\nFor ‘Squarespace donations only’; these are the donations that plausibly came from the email. First as a share of opens for each treatment :\n\n\nCode\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_don_ss), 'beta' = sum(oc_mat_r$tot_d_open))\n\n\n(\n  don_ss_by_treat_opened_fit <- bayes.prop.test(oc_mat_r$tot_d_don_ss, oc_mat_r$tot_d_open, cred.mass = 0.80) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_don_ss out of oc_mat_r$tot_d_open\nnumber of successes:     8,    9\nnumber of trials:     1412, 1199\nEstimated relative frequency of success [80% credible interval]:\n  Group 1: 0.0062 [0.0033, 0.0085]\n  Group 2: 0.0081 [0.0047, 0.011]\nEstimated group difference (Group 1 - Group 2):\n  0 [-0.0062, 0.0023]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.282 and larger for Group 2 by a probability of 0.718 .\n\n\nCode\n#same with AB  package\n# Fit bernoulli test\ndon_ss_by_treat_AB <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don_ss[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don_ss[oftw_mc_db_openers$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_ss_by_treat_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don_ss[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don_ss[oftw_mc_db_openers$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\n\nplot(don_ss_by_treat_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_ss_by_treat_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\ndon_ss_by_treat_AB %>% summary(credInt=0.9)\n\n\nQuantiles of posteriors for A and B:\n\n$Probability\n$Probability$A\n          0%          25%          50%          75%         100% \n0.0009902386 0.0048437368 0.0061367516 0.0076340142 0.0191421384 \n\n$Probability$B\n         0%         25%         50%         75%        100% \n0.001462728 0.006437438 0.008042132 0.009891706 0.025724099 \n\n\n--------------------------------------------\n\nP(A > B) by (0)%: \n\n$Probability\n[1] 0.27906\n\n--------------------------------------------\n\nCredible Interval on (A - B) / B for interval length(s) (0.9) : \n\n$Probability\n        5%        95% \n-0.6515304  0.6391667 \n\n--------------------------------------------\n\nPosterior Expected Loss for choosing A over B:\n\n$Probability\n[1] 0.5346835\n\n\nCode\ndon_ss_by_treat_AB_lift_int80 <- don_ss_by_treat_AB %>% summary(credInt=0.8)\n\n\ndon_ss_by_treat_AB_lift_int80_empir <- don_ss_by_treat_AB_empir %>% summary(credInt=0.8)\n\n\n80% credible intervals with the uniform prior for the ‘lift’ of Impact relative to Emotion are\n-0.583, 0.383\nand for the empirically informed (but symmetric prior):\n-0.367, 0.304\n(Hard-coded) Again, even our 80% bounds are very wide.\n\n\nFinally, we consider the above as a share of total emails sent, allowing that ‘opens’ is non-random,\n… and also implicitly assuming that the only impact of these treatments could be on the Squarespace donations made by someone who did open the email.\n\n\nCode\n(\n  don_ss_by_treat_opened_fit_all <- bayes.prop.test(oc_mat_r$tot_d_don_ss, assigned_emails,\n    cred.mass = 0.80) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_don_ss out of assigned_emails\nnumber of successes:     8,    9\nnumber of trials:     2000, 2000\nEstimated relative frequency of success [80% credible interval]:\n  Group 1: 0.0043 [0.0025, 0.0062]\n  Group 2: 0.0049 [0.0029, 0.0067]\nEstimated group difference (Group 1 - Group 2):\n  0 [-0.0033, 0.0022]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.405 and larger for Group 2 by a probability of 0.595 .\n\n\nCode\n# \n#same with AB package\n\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_don_ss), 'beta' = sum(assigned_emails))\n\n\n# Fit Bernoulli test\ndon_ss_by_treat_all_AB <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_don_ss[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_don_ss[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_ss_by_treat_all_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_don_ss[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_don_ss[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(don_ss_by_treat_all_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_ss_by_treat_all_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\ndon_ss_by_treat_all_AB %>% summary(credInt=0.9)\n\n\nQuantiles of posteriors for A and B:\n\n$Probability\n$Probability$A\n          0%          25%          50%          75%         100% \n0.0006591401 0.0034229384 0.0043367467 0.0053948239 0.0139389081 \n\n$Probability$B\n          0%          25%          50%          75%         100% \n0.0008503472 0.0038633646 0.0048302873 0.0059443205 0.0137935894 \n\n\n--------------------------------------------\n\nP(A > B) by (0)%: \n\n$Probability\n[1] 0.4076\n\n--------------------------------------------\n\nCredible Interval on (A - B) / B for interval length(s) (0.9) : \n\n$Probability\n        5%        95% \n-0.5874267  0.9235146 \n\n--------------------------------------------\n\nPosterior Expected Loss for choosing A over B:\n\n$Probability\n[1] 0.353655\n\n\nCode\ndon_ss_by_treat_all_AB_lift_int80 <- don_ss_by_treat_all_AB %>% summary(credInt=0.8)\n\n\ndon_ss_by_treat_all_AB_lift_int80_empir <- don_ss_by_treat_all_AB_empir %>% summary(credInt=0.8)\n\n\n80% credible intervals with the uniform prior for the ‘lift’ of Impact relative to Emotion are\n\n\nCode\n op(don_ss_by_treat_all_AB_lift_int80$interval$Probability)\n\n\n     10%      90% \n\"-0.507\" \" 0.621\" \n\n\nand for the empirically informed (but symmetric prior):\n\n\nCode\nop(don_ss_by_treat_all_AB_lift_int80_empir$interval$Probability)\n\n\n     10%      90% \n\"-0.329\" \" 0.379\" \n\n\nHard-coded: Here there is almost no evidence in either direction. However, our 80% credible intervals remain wide.\n\n\nUnfortunately, this experiment proved to be underpowered, at least for the donation outcome.\nBut what about clicks on the ‘donation link’? This could arguably be seen as a measure of ‘desire and intention to donate’, and thus might be a more fine-grained and less noisy measure, improving our statistical power.\nSome quick crosstabs (here as a share of opens)\n\n\nCode\n(\n  donclick_by_treat <-  oftw_mc_db %>% \n  filter(!is.na(treat_emotion)) %>% \n  tabyl(treat_emotion, d_click_don_link) %>%\n    adorn_percentages(\"row\") %>%\n    adorn_pct_formatting() %>%\n    adorn_ns() %>%\n    adorn_title() %>% \n    kable(caption =\"Click on donation link by treatment; all opened emails\")  %>% \n  kable_styling(latex_options = \"scale_down\")\n)\n\n\n\nClick on donation link by treatment; all opened emails\n \n  \n     \n    d_click_don_link \n     \n     \n  \n \n\n  \n    treat_emotion \n    FALSE \n    TRUE \n    NA_ \n  \n  \n    0 \n    97.5% (1376) \n    2.1% (29) \n    0.5% (7) \n  \n  \n    1 \n    94.6% (1134) \n    4.7% (56) \n    0.8% (9) \n  \n\n\n\n\n\nIf this is our metric, it only seems fair to take into account ‘whether they opened the email’ as part of this effect. Thus, considering clicks as a share of total emails sent…\n\n\nCode\n(\n  click_don_by_treat_opened_fit <- bayes.prop.test(oc_mat_r$tot_d_click_don_link, assigned_emails,\n    cred.mass = 0.95) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_click_don_link out of assigned_emails\nnumber of successes:    29,   56\nnumber of trials:     2000, 2000\nEstimated relative frequency of success [95% credible interval]:\n  Group 1: 0.015 [0.0098, 0.020]\n  Group 2: 0.028 [0.021, 0.036]\nEstimated group difference (Group 1 - Group 2):\n  -0.01 [-0.023, -0.0046]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.002 and larger for Group 2 by a probability of 0.998 .\n\n\nCode\nplot(click_don_by_treat_opened_fit)\n\n\n\n\n\n\n\nCode\n#same with AB  package\n\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_click_don_link), 'beta' = sum(assigned_emails))\n\noftw_mc_db_assigned <- oftw_mc_db_assigned %>% dplyr::filter(!is.na(d_click_don_link))\n\n# Fit bernoulli test\ndon_click_by_treat_all_AB <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_click_don_link[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_click_don_link[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_click_by_treat_all_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_click_don_link[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_click_don_link[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(don_click_by_treat_all_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_click_by_treat_all_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\ndon_click_by_treat_all_AB %>% summary(credInt=0.9)\n\n\nQuantiles of posteriors for A and B:\n\n$Probability\n$Probability$A\n         0%         25%         50%         75%        100% \n0.005613925 0.013111564 0.014855512 0.016785020 0.030921759 \n\n$Probability$B\n        0%        25%        50%        75%       100% \n0.01457222 0.02602580 0.02846221 0.03102267 0.04764887 \n\n\n--------------------------------------------\n\nP(A > B) by (0)%: \n\n$Probability\n[1] 0.00155\n\n--------------------------------------------\n\nCredible Interval on (A - B) / B for interval length(s) (0.9) : \n\n$Probability\n        5%        95% \n-0.6412379 -0.2472723 \n\n--------------------------------------------\n\nPosterior Expected Loss for choosing A over B:\n\n$Probability\n[1] 0.9686057\n\n\nCode\ndon_click_by_treat_all_AB_lift_int80 <- don_click_by_treat_all_AB %>% summary(credInt=0.8)\n\ndon_click_by_treat_all_AB_lift_int80_empir <- don_click_by_treat_all_AB_empir %>% summary(credInt=0.8)\n\n\n80% credible intervals with the uniform prior for the ‘lift’ of Impact relative to Emotion are\n-0.610, -0.304\nand for the empirically informed (but symmetric prior):\n-0.3119, -0.0531\n(Hard-coded)\nThere is fairly strong evidence that the emotion email lead to a higher rate of clicks on the donation link; note that this even is in spite of the lower rate of email opens.\nThis suggests (IMO) it is worth testing this further.\n\n\n1.6.2 Redoing a bunch of stuff manually\nFirst, some building blocks;\nthe probability distribution over the absolute value of differences between two binomial random variables\nAdapting formulas from Stackexchange post discussion\nDefining their code for this function: ::: {.cell}\n\nCode\nmodBin <- dbinom #DR: I just do this renaming here for consistency with the rest ... but the modBin they defined was redundant as it's already built ins\n\ndiffBin <- function(z, n1, p1, n2, p2){\n\n  prob <- 0\n\n  if (z>=0){\n    for (i in 1:n1){\n      prob <- prob + modBin(i+z, n1, p1) * modBin(i, n2, p2)\n    }\n\n  }\n  else\n  {\n    for (i in 1:n2){\n      prob<-prob+modBin(i+z, n1, p1)*modBin(i, n2, p2)\n    }\n  }\n  return(prob)\n}\n\n:::\n\n\nWe generate an alternate version to cover ‘differences in one direction, i.e., but ’probability of observing (d1-d2)/(n1+n2) share more of d1 responses than d2 responses given sample sizes n1 and n2… over a range of true probabilities p1 and p2’\nthe probability distribution for differences between two binomial random variables in one direction\n\n\n\nFor the present case\nHard-coded notes…\n::: {.foldable}\n\n\n\nCode\nn1 <- oc_mat_r$tot_d_open[1]\nn2 <- oc_mat_r$tot_d_open[2]\nd1 <- oc_mat_r$tot_d_click_don_link[1]\nd2 <- oc_mat_r$tot_d_click_don_link[2]\nz <- d1-d2 #impact minus emotion\n\n\nComputation for a few ‘ad-hoc cases’ (later explore the space with vectors of values)\n\nSuppose truly equal incidence, at the mean level\n\n\n\nCode\np1 <- (d1+d2)/(n1+n2)\n\np2 <- p1\n\n(\n  db_0 <- diffBin(z, n1, p1, n2, p2)\n)\n\n\n[1] 3.963627e-05\n\n\nThis implies there is a 0.00396% chance of getting this exact difference of +-27 incidence(s) between the treatments (in one direction), if the true incidence rates were equal.\nLet’s plot this for a range of ‘incidence rate differences’ in this region. (Sorry, using the traditional plot, ggplot is better).\n\n\nCode\ns <- seq(-10*z, 10*z)\np<-sapply(s, function(z) diffBin(z, n1, p1, n2, p2))\nplot(s,p)\n\n\n\n\n\nWe see a large likelihood of values in the range of the +-27 difference observed, and a low likelihood of a difference of 10 or more in either direction.\n\n\n1.6.3 Adaptation: ‘of this magnitude or smaller’\n\n\nCode\nltmag_diffBin <- function(z, n1, p1, n2, p2){\n  prob <- 0\n  z_n <- -z #negative value\n\n  for (i in z_n:z){     #sum for all integer differences between observed value and its negative, inclusive\n    prob <- prob + diffBin(i, n1, p1, n2, p2)\n    }\n\n  return(prob)\n}\n\n\nNow, a similar computation as above, but for ‘a difference this big or smaller in magnitude’:\n\n\nCode\n  (\n    mag_db_0 <- ltmag_diffBin(z, n1, p1, n2, p2)\n  )\n\n\n[1] 0.9880585\n\n\nThis implies there is a 98.8% chance of getting a difference no larger than this one in magnitude of +/–27 incidences between the treatments if the true incidence rates were equal.\n\n\nAnd finally, what we were looking for: the chance of ‘a difference this small or smaller’ as a function of the true difference…\n(Think about: should we do this for ‘a difference in the same direction’ instead?)\nSet up an arbitrary vector of ‘true differences’ \nBelow, I plot\nY-axis: ’how likely would be a difference in donations ‘as small or smaller in magnitude’” than we see in the data against…\nX-axis: if the “true difference in incidence rates” were of these magnitudes\n(Note: this should cover ‘a difference in either direction’; the probability of a difference in the direction we do see is obviously somewhat smaller)\n\n\nCode\noptions(scipen=999)\n\nB <- c(1, 1.5, 2, 2.5, 3)\n\np1 <- rep((d1+d2)/(n1+n2), length(B))\np2 <- p1*B\n\n\nas.list(ltmag_diffBin(z, n1, p1, n2, p2)*100) %>% format(digits=3, scientific=FALSE)\n\n\n[1] \"98.8\"   \"93.2\"   \"33.6\"   \"1.81\"   \"0.0157\"\n\n\nCode\nprobmag <- ltmag_diffBin(z, n1, p1, n2, p2)\n\n\n#qplot(B, probmag, log  = \"x\", xlab = \"True relative incidence\", ylab =\"Prob. of difference this small\")\n\n(\n  probmag_plot <-\n    ggplot() +\n  aes(x=B, y=probmag) +\n  geom_point() +\n  scale_x_continuous(trans='log2') +\n    ylim(0,1) +\n    xlab(\"True relative incidence rate\") +\n    ylab(\"Prob. diff. as small as obsd\")\n\n)\n\n\n\n\n\nHard-coded takeaways 15 Dec 2021 :\nOur data is consistent with ‘no difference’ (of course) … but its also consistent with ‘a fairly large difference in incidence’\nE.g., even if one treatment truly lead to ‘twice as many donations as the other’, we still have a 20% chance of seeing a differences as small as the one we see (of 8 versus 6)\nWe can reasonably ‘rule out’ differences of maybe 2.5x or greater\nMain point: given the rareness of donations in this context, our sample size doesn’t let us make very strong conclusions in either directions … at least not yet. I hope that combined with other evidence, we will be able to infer more\n\n\n1.6.4 Quick redo assuming equal shares recieved each email, and treating ‘email reciepts as denom’\nApprox 4000 total emails sent?\nFor squarespace\n\n\nCode\nn1 <- 2000\nn2 <- 2000\nd1 <- 10\nd2 <- 9\nz <- d1-d2\n\nB <- c(1/3, 1/2.5, 1/2, 1/1.5, 1, 1.5, 2, 2.5, 3)\n\np1 <- rep((d1+d2)/(n1+n2), length(B))\np2 <- p1*B\n\n\n\n(\n    mag_db_0_ss <- ltmag_diffBin(z, n1, p1, n2, p2)\n  )\n\n\n[1] 0.071197896 0.100275616 0.147727269 0.220724651 0.272100392 0.154218060\n[7] 0.046306831 0.009174658 0.001345637\n\n\nCode\nprobmag_ss <- ltmag_diffBin(z, n1, p1, n2, p2)\n\n\n(\n  probmag_plot_ss <-\n    ggplot() +\n  aes(x=B, y=probmag_ss) +\n  geom_point() +\n  scale_x_continuous(trans='log2') +\n    ylim(0,.51) +\n    xlab(\"True relative incidence rate\") +\n    ylab(\"Prob. diff. as small as obsd\")\n\n)\n\n\n\n\n\nCode\n#note that it is not symmetric bc (I think) a very low incidence on one side makes particular large observed proportional differences more likely\n\n\nFor all one-time donations\n\n\nCode\nn1 <- 2000\nn2 <- 2000\nd1 <- 15\nd2 <- 12\nz <- d1-d2\n\nB <- c(1/3, 1/2.5, 1/2, 1/1.5, 1, 1.5, 2, 2.5, 3)\n\np1 <- rep((d1+d2)/(n1+n2), length(B))\np2 <- p1*B\n\n\n(\n    mag_db_0 <- ltmag_diffBin(z, n1, p1, n2, p2)\n  )\n\n\n[1] 0.0922168538 0.1395427545 0.2249330548 0.3745240308 0.5032003013\n[6] 0.2505329859 0.0521354769 0.0059810731 0.0004413855\n\n\n(the below halts on build, so I commented it out)\n\n\nCode\n(\n  probmag_plot_ot <-\n    ggplot() +\n  aes(x=B, y=probmag) +\n  geom_point() +\n  scale_x_continuous(trans='log2') +\n    ylim(0,.51) +\n    xlab(\"True relative incidence rate\") +\n    ylab(\"Prob. diff. as small as obsd\")\n\n)"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#demographics-and-interactions-to-do",
    "href": "chapters/oftw_upsell_input_first_analysis.html#demographics-and-interactions-to-do",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.7 Demographics and interactions (to do)",
    "text": "1.7 Demographics and interactions (to do)"
  },
  {
    "objectID": "chapters/tlycs_placeholder.html",
    "href": "chapters/tlycs_placeholder.html",
    "title": "2  The Life You Can Save trial: redacted (empty)",
    "section": "",
    "text": "As we have not (yet) been given explicit permission to share the details of the trial with The Life You Can Save, we are not hosting it in the public version"
  },
  {
    "objectID": "chapters/gwwc_gg.html",
    "href": "chapters/gwwc_gg.html",
    "title": "1  Giving What We Can: Giving guides",
    "section": "",
    "text": "Note\n\n\n\nThis chapter should align with a (forthcoming) EA Forum post, which will be linked here (and vice-versa)."
  },
  {
    "objectID": "chapters/gwwc_gg.html#capturing-data",
    "href": "chapters/gwwc_gg.html#capturing-data",
    "title": "3  Giving What We Can: Giving guides",
    "section": "3.2 Capturing data",
    "text": "3.2 Capturing data"
  },
  {
    "objectID": "chapters/gwwc_fb.html",
    "href": "chapters/gwwc_fb.html",
    "title": "4  Giving What We Can: Feb 22 Facebook Message Test",
    "section": "",
    "text": "Details in Gitbook HERE and Gdoc here\n\n\nCode\nknitr::include_url(\"https://effective-giving-marketing.gitbook.io/untitled/partner-organizations-and-trials/gwwc/feb-22-message-test\")"
  },
  {
    "objectID": "chapters/gwwc_fb.html#capturing-data",
    "href": "chapters/gwwc_fb.html#capturing-data",
    "title": "4  Giving What We Can: Feb 22 Facebook Message Test",
    "section": "4.2 Capturing data",
    "text": "4.2 Capturing data\n\n\n\n\n\n\nBringing in the data Erin coded\n\n\n\n\n\nAs a start, I source build work (Erin’s work, which I edited a bit) to bring in (and store) the data. I would do the coding a bit differently (more ‘tidyverse’ and less repetition), but it may not be worth redoing at this point.\n\n\n\n\n\nCode\n#this seems to be what Erin used ... but what is \n\nsource(here(\"gwwc\", \"build_GWWC_Feb_22_Message_test.R\"))"
  },
  {
    "objectID": "chapters/gwwc_gg.html#build-source-data-input-and-cleaning-code",
    "href": "chapters/gwwc_gg.html#build-source-data-input-and-cleaning-code",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.3 Build: Source data input and cleaning code",
    "text": "1.3 Build: Source data input and cleaning code\n\n\n\n\n\n\nAccessing, downloading, inputting data\n\n\n\n\n\nSee:\nAccessing and bringing down simple results HERE; (Public access version here)\nWe import the exported ‘pivot table’ gg_campaign_by_ad_by_text below, as well as the more detailed version, broken down by age range and gender: gg-campaign-by-ad-set-text-age-gender.csv.2\n\n\n\n\n\n\n\n\n\n\nData structure\n\n\n\n\n\nThe data frame gg_campaign_by_ad_by_text_age_gender has one row per combination of ‘campaign, ad, text, age group, gender’.\nEach row represents a combination of the below (with different numbers of ‘impressions’ for each row)3\n\ncampaign_name: When and and with what funds the ad was launched, I think (?)\nad_set: An ad set can specifically tie an ad_name to an audience (I think)\nad_name: Which video/media (or collection of optimized videos/media) was shown; note this is paired with ‘which audience’ in it’s label, as there were specific ‘global poverty’, ‘animal welfare’, ‘climate change’, ‘philanthropy’ and ‘retargeting’ audiences\n\nCaveat: The ad_name seems to select from a different set of media for optimization depending on which ad_set it is in.4\n\ntext: Which text was shown along with the video\nage (a range of ages)\ngender (female, male, unknown)\n\n\n\n\n\n\nCode\nraw_data_path <- list(\"gwwc\", \"gg_raw_data_shareable\")\n\n#already input above: gg_campaign_by_ad_by_text\n\n#Version allowing demographic breakdown:\ngg_campaign_by_ad_by_text_age_gender <- read_csv(here(raw_data_path, \"gg-campaign-by-ad-set-text-age-gender.csv\"), show_col_types=FALSE) %>%\n  #dplyr::select(-\"Campaign name...4\") %>% #duplicate columns?\n mini_clean()\n\n#Version with information on cause videos shown (even to those in 'general' groups):\n\ngg_video_breakdowns <- read_csv(here(raw_data_path, \"gg-image-video-breakdowns.csv\"), show_col_types=FALSE)\n\n#capture and remove columns that are the same everywhere\nattribution_setting_c <- gg_campaign_by_ad_by_text_age_gender$attribution_setting %>% .[1]\nreporting_starts_c <- gg_campaign_by_ad_by_text_age_gender$reporting_starts %>% .[1]\nreporting_ends_c <- gg_campaign_by_ad_by_text_age_gender$reporting_ends %>% .[1]\n\n\ngg_campaign_by_ad_by_text_age_gender  %<>% mini_clean()\ngg_video_breakdowns  %<>% mini_clean()\n\n#functions to clean these specific data sets 'gg_campaign_by_ad_by_text_age_gender' and 'gg_campaign_by_ad_by_text':\nsource(here(\"gwwc\", \"giving_guides\", \"clean_gg_raw_data.R\")) \n\n#Many cleaning steps: audience, video_theme, campaign_theme, agetrin; releveling\ngg_campaign_by_ad_by_text_age_gender %<>%\n  rename_gg() %>%\ngg_make_cols() %>% \n  text_clean() %>%  # Shorter 'text treatment' column\n  dplyr::select(campaign_name, everything(), -campaign_name_1, -campaign_name_7) #campaign_name_7 was the same as campaign_name_1\n\ngg_video_breakdowns %<>%\n  rename_gg() %>%\ngg_make_cols() \n\n#gg_campaign_by_ad_by_text_age_gender %>% collapse::descr()\n\n\n\n\nCode\ngg_video_breakdowns %<>%\n  mutate(\n    video_theme = case_when(\n      str_det(image_video_and_slideshow, \"set_1|Animals\") ~ \"Animal\",\n      str_det(image_video_and_slideshow, \"set_2|Climate\") ~ \"Climate\",\n      str_det(image_video_and_slideshow, \"set_3|Poverty|Free Effective\") ~ \"Poverty\",\n      str_det(image_video_and_slideshow, \"factual_short|Factual Short\") ~ \"Factual short\",\n    TRUE ~   video_theme\n    ),\n    video_theme =  factor(video_theme), \n    video_theme = fct_relevel(video_theme, c(\"Animal\", \"Climate\", \"Poverty\", \"Factual short\", \"Factual long\", \"Hypercube (factual)\")) \n  )\n\n\n\n\n\n\n\n\nThis data should be publicly shareable.\n\n\n\n\n\nThis data is clearly not identifying individuals; it involves aggregates based on real or assumed characteristics … there is likely nothing that needs to be hidden here. We aim to share and integrate all the data in this repo, for a complete pipeline.\n\n\n\n\n\n\n\n\n\nPrevious version of data used … (updating)\n\n\n\n\n\nWe previously used data collapsed (breakdowns) by demography and ad set, into 2 files, which duplicated rows to represent the number of impressions: video breakdown, and text breakdown.csv. We now use the more ‘raw’ minimal version of the data, avoiding duplicating rows where possible.\nBelow, we also input the ‘old version’ of the data, with the duplicated rows, to accommodate the old-format of analysis. The code above inputs and builds 2-4 related data frames (tibbles), which were constructed from the collapsed (aggregated) data by multiplying rows according to observation counts. I am not sure where this was done. Once we update the rest we will get rid of this.\ngwwc_text_clicks: Observations of link clicks … by texts above video gwwc_vid_clicks: … by video content\n(We focus on the email results because we expect the ‘clicks’ are less meaningful.)\ngwwc_text_results: Observations of emails provided … by texts above video gwwc_vid_results: … by video content\nThe files:\ntextdata_dv_linkclicks.csv, videodata_dv_results.csv, textdata_dv_results.csv , and videodata_dv_linkclicks.csv\nare gitignored because of size.\n\n\n\n\n\nCode\nsource(here(\"gwwc\", \"giving_guides\", \"input_build_gwwc_gg_data_results.R\"))\n\n#source(here(\"gwwc\", \"giving_guides\", \"input_build_gwwc_gg_data_clicks.R\"))"
  },
  {
    "objectID": "chapters/gwwc_gg.html#asking-and-answering-questions",
    "href": "chapters/gwwc_gg.html#asking-and-answering-questions",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.5 Asking and answering questions",
    "text": "1.5 Asking and answering questions\n\n\n\n\n\n\nThis dynamic document format allows us to ask and answer a series of questions\n\n\n\n\n\n\nUsing the data, with all coding steps shown\nIdeally, following a pre-defined (pre-analysis) plan\nUsing the data and statistics directly and automatically in the narrative\n\nAnd everything will be automatically adjusted if we bring in new data or adjust/correct features\n\n\n\n\n\n\nIn this context, how much does it cost to get a ’Result”, i.e., to get a person to give their email to receive a Giving Guide?\n\n\n\n\n\n\nCost per result (CpR) as the result of several processes…\n\n\n\n\n\nHow should we consider this outcome? At the base level the Cost per Result (‘CpR’) for a ‘segment’ (a particular ad version, audience, campaign, etc), comes from several interrelated processes:\n\nHow much FB charges us for this segment\nWho FB serves this segment to (what types of people, how many)\nHow many people in that segment click and then ‘convert’, yielding a result\n\nWe could try to model each of these processes, but it could be very involved, and we don’t fully observe or understand the second step, FB’s optimization algorithm.\n\n\n\n\n\n\n\n\n\nRambling about the unit of observation, and a possible multi-equation model\n\n\n\n\n\nI still want to model “cost per result” (or perhaps better “results per cost”) as a function of the different levers we can pull (audience filters, video content, message content, etc.). But I’m not quite sure how to model it, in particular, how to think about the unit of observation and the outcome variability, for statistical inference.\nFundamentally, the data represents a lot of rows of mostly 0’s (no result, no email left) with a few 1’s. Each of these rows has a set of design features; the ‘levers’ above, as well as some other features like demographics and calendar date (although FB makes it difficult/impossible to view everything together.)\nWe could examine the relationship between the features and the ‘probability an individual yields a result’. I guess ‘cost’ could be one of those features, in something like a logit model. A transformation of the function $p(result) = a + b_1 cost (b_2 AdVersion +b_3 audience + b_4 AdVersion*audience +… ), perhaps.\nBut cost (cost per impression) is also a function of some of these characteristics. We could examine the relationship between cost and these features in a separate equation and somehow try to simultaneously estimate these … but it’s challenging.\n\n\n\n\n\n\n\n\n\nCpR as a black box…\n\n\n\n\n\nAlternatively, we could think of the CpR for a segment as just a ‘base outcome to model’, and treat it as a sort of black box. This would suggests we have ‘only one CpR coutcome per segment’, and each segment has different characteristics (‘features’ or ‘variables’), some in common. But that discards some important information: the mean values for segments with more observations (here, ‘impressions’) can be expected to have less variance (lower standard error), all else equal.\n\n\n\n\n\n\n\n\n\nCpR as the average of a lot of black boxes…\n\n\n\n\n\nWe can do something intermediate – taking the aggregation into account, without fully building a structural model of the factors above. Within each segment, we can consider the ‘average cost per result’ outcome for each individual as the expected value of a random draw. Each individual has some ‘cost per impression’, and some ‘probability of a result’. The ratio of these is the individual’s ‘expected cost per result … which we can also abstract as just some random draw. This may be considered as a function of ’all the characteristics of the segment the individual is in’. The CpR for the segment is thus an average of the CpR for all the individuals in the segment, and we can use ‘regression weights’ (technically ‘inverse variance weights’; see discussion in Huntington-Klein’s book here) in our model to reflect this."
  },
  {
    "objectID": "chapters/gwwc_gg.html#analysis-and-visuals-moved-from-erins-work",
    "href": "chapters/gwwc_gg.html#analysis-and-visuals-moved-from-erins-work",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.4 Analysis and visuals (moved from Erin’s work)",
    "text": "1.4 Analysis and visuals (moved from Erin’s work)\n\n\nCode\n#summary(gwwc_vid_results$DV_costadj)\n#summary(gwwc_vid_results$DV)\n#summary(gwwc_vid_results$ave.cost.impr)\n\n\nData summary\n\nBelow, a few data summary bits (from Erin). I commented most of it out and will redo it using an automated and formatted ‘key summary statistics’ package.\n\n\n\nCode\ngwwc_vid_results %>% group_by(Age) %>% summarise(n=n()) %>% .kable()\n\n\n\n \n  \n    Age \n    n \n  \n \n\n  \n    25-34 \n    287,682 \n  \n  \n    13-17 \n    444 \n  \n  \n    18-24 \n    147,805 \n  \n  \n    35-44 \n    158,352 \n  \n  \n    45-54 \n    48,728 \n  \n  \n    55-64 \n    60,904 \n  \n  \n    65+ \n    66,198 \n  \n\n\n\n\n\nCode\ngwwc_vid_results %>% group_by(Gender) %>% summarise(n=n())  %>% .kable()\n\n\n\n \n  \n    Gender \n    n \n  \n \n\n  \n    female \n    573,705 \n  \n  \n    male \n    178,321 \n  \n  \n    unknown \n    18,087 \n  \n\n\n\n\n\nCode\n#print(gwwc_vid_results %>% group_by(Gender,Age) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=40)\n#print(gwwc_vid_results %>% group_by(Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=41)\n#print(gwwc_vid_results %>% group_by(Campaign.name,Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=100)\ngwwc_vid_results %>% group_by(audience) %>% summarise(n=n(),cost=mean(ave.cost.impr)*100) %>% .kable(digits=2)\n\n\n\n \n  \n    audience \n    n \n    cost \n  \n \n\n  \n    philanthropy \n    248,852 \n    2.20 \n  \n  \n    animal \n    187,212 \n    2.22 \n  \n  \n    climate \n    139,824 \n    1.81 \n  \n  \n    general \n    57,012 \n    1.30 \n  \n  \n    lookalike \n    67,359 \n    2.66 \n  \n  \n    poverty \n    69,404 \n    1.82 \n  \n  \n    retargeting \n    450 \n    2.50 \n  \n\n\n\n\n\nCode\ngwwc_vid_results %>% group_by(message) %>% summarise(n=n(),cost=mean(ave.cost.impr)*100) %>% .kable(digits=2)\n\n\n\n \n  \n    message \n    n \n    cost \n  \n \n\n  \n    Factual \n    291,027 \n    2.24 \n  \n  \n    Emotional \n    274,718 \n    2.37 \n  \n  \n    Hypercube \n    75,790 \n    1.76 \n  \n  \n    PPCo \n    128,578 \n    1.25 \n  \n\n\n\n\n\n### CHART DATA\n\n\nCode\n#print(gwwc_vid_results %>% group_by(audience,media) %>% #summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)"
  },
  {
    "objectID": "chapters/gwwc_gg.html#plots",
    "href": "chapters/gwwc_gg.html#plots",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.8 PLOTS",
    "text": "1.8 PLOTS\n\n1.8.1 PLOT: Cost adjusted DV (results) by video\n\n\n1.8.2 PLOT: DV (Results) by video\n\n\nCode\ngwwc_vid_results %>%\n   grpsumgg(media, DV, .1) %>%\n  ggplot(aes(x=media, y=mean_dv)) +\n  geom_bar(stat='identity', fill=\"#0072B2\",position=dodge) +\n  ylab('Results (%)')+\n  xlab('Video')+\n  ggtitle('Results by Video')+\n  scale_x_discrete(labels=vid_types)\n\n\n\n\n\n\n\n1.8.3 PLOT: Cost adjusted DV (results) by video and audience\n14\n\n\nCode\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>% group_by(media,audience) %>% #summarise(results=mean(DV_costadj),SE=std.error(DV_costadj),n=n()),n=50) %>% .kable(digits=2)\n\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>%\n  group_by(media, audience) %>%\n  summarise(mean_dv = mean(DV_costadj, na.rm=TRUE),\n            se_dv = sd(DV_costadj, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=audience, y=mean_dv, group=media, fill=media)) +\n  gg_gg_options +\n  labs(fill=\"Video\")+\n  scale_fill_brewer(palette=\"RdBu\")+\n  ylab('Results/$ spent')+\n  xlab('Audience')+\n  ggtitle('Results/$ spent by Video and Audience')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.25), oob = rescale_none, breaks=seq(0,.75, by=.25)) +\n  scale_x_discrete(labels=c(\"philanthropy\",\"animal\",\"climate\",\"general\",\"lookalike\",\"poverty\",\"retargeting\")) \n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\nCode\n#levels(gwwc_vid_results$audience)\n\n\n\n\n1.8.4 PLOT: DV (results) by video and audience\nQuestions/Notes: Removed the retargeting audience\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr > 0 &\n    audience != \"retargeting\") %>% group_by(media, audience) %>% summarise(\n      results = 100 * mean(DV),\n      SE = 100 * std.error(DV),\n      n = n()\n    ) %>% .kable(digits = 2) %>% .kable_styling()\n\n\n\n \n  \n    media \n    audience \n    results \n    SE \n    n \n  \n \n\n  \n    factual short \n    philanthropy \n    0.23 \n    0.02 \n    59,660 \n  \n  \n    factual short \n    animal \n    0.20 \n    0.01 \n    90,832 \n  \n  \n    factual short \n    climate \n    0.21 \n    0.01 \n    96,005 \n  \n  \n    factual short \n    general \n    0.10 \n    0.02 \n    15,559 \n  \n  \n    factual short \n    lookalike \n    0.39 \n    0.03 \n    34,207 \n  \n  \n    factual short \n    poverty \n    0.21 \n    0.02 \n    34,815 \n  \n  \n    animal \n    philanthropy \n    0.21 \n    0.02 \n    79,525 \n  \n  \n    animal \n    animal \n    0.28 \n    0.02 \n    80,642 \n  \n  \n    animal \n    general \n    0.14 \n    0.04 \n    10,542 \n  \n  \n    animal \n    lookalike \n    0.42 \n    0.07 \n    9,441 \n  \n  \n    climate \n    philanthropy \n    0.28 \n    0.04 \n    13,810 \n  \n  \n    climate \n    climate \n    0.11 \n    0.03 \n    14,083 \n  \n  \n    climate \n    general \n    0.16 \n    0.05 \n    7,445 \n  \n  \n    climate \n    lookalike \n    0.21 \n    0.08 \n    3,283 \n  \n  \n    factual long \n    philanthropy \n    0.16 \n    0.05 \n    6,923 \n  \n  \n    factual long \n    animal \n    0.15 \n    0.04 \n    8,729 \n  \n  \n    factual long \n    climate \n    0.19 \n    0.04 \n    9,542 \n  \n  \n    factual long \n    lookalike \n    0.72 \n    0.36 \n    557 \n  \n  \n    factual long \n    poverty \n    0.11 \n    0.05 \n    4,595 \n  \n  \n    hypercube \n    philanthropy \n    0.14 \n    0.03 \n    17,400 \n  \n  \n    hypercube \n    animal \n    0.07 \n    0.03 \n    6,988 \n  \n  \n    hypercube \n    climate \n    0.09 \n    0.02 \n    20,154 \n  \n  \n    hypercube \n    general \n    0.09 \n    0.02 \n    22,132 \n  \n  \n    hypercube \n    lookalike \n    0.25 \n    0.14 \n    1,194 \n  \n  \n    hypercube \n    poverty \n    0.08 \n    0.03 \n    7,835 \n  \n  \n    poverty \n    philanthropy \n    0.15 \n    0.01 \n    71,466 \n  \n  \n    poverty \n    general \n    0.08 \n    0.08 \n    1,327 \n  \n  \n    poverty \n    lookalike \n    0.24 \n    0.04 \n    18,652 \n  \n  \n    poverty \n    poverty \n    0.15 \n    0.03 \n    22,129 \n  \n\n\n\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>%\n  group_by(media, audience) %>%\n  summarise(mean_dv = 100*mean(DV, na.rm=TRUE),\n            se_dv = 100*sd(DV, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=audience, y=mean_dv, group=media, fill=media)) +\n  gg_gg_options +\n  labs(fill=\"Video\")+\n  scale_fill_brewer(palette=\"RdBu\")+\n  ylab('Results (%)')+\n  xlab('Audience')+\n  ggtitle('Results by Video and Audience')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,1.1),  oob = rescale_none,  breaks=seq(0,1.1, by=.1)) +\n  scale_x_discrete(labels=c(\"philanthropy\",\"animal\",\"climate\",\"general\",\"lookalike\",\"poverty\",\"retargeting\"))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\n\n\n1.8.5 PLOT: Cost adjusted DV (results) by audience\n\n\nCode\n#pirint(gwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>% group_by(audience) %>% summarise(results=mean(DV_costadj),SE=std.error(DV_costadj),n=n()),n=50)\n\n\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>%\n  group_by(audience) %>%\nsummarise(mean_dv = mean(DV_costadj, na.rm=TRUE),\n            se_dv = sd(DV_costadj, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=audience, y=mean_dv)) +\n  gg_gg_options +\n  ylab('Results/$ spent')+\n  xlab('Audience')+\n  ggtitle('Results/$ spent by Audience')+\n  scale_y_continuous(limits = c(0,.2),  breaks=seq(0,.2, by=.05)) +\n  scale_x_discrete(labels=c(\"philanthropy\",\"animal\"   ,\"climate\",\"general\",\"lookalike\",\"poverty\"))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\n\n\n1.8.6 PLOT: DV (Results) by audience\n\n\nCode\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>% group_by(audience) %>% summarise(results=100*mean(DV),SE=100*std.error(DV),n=n()),n=50)\n\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>%\n  group_by(audience) %>%\n  summarise(mean_dv = 100*mean(DV, na.rm=TRUE),\n            se_dv = 100*sd(DV, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=audience, y=mean_dv)) +\n  gg_gg_options +\n  ylab('Results (%)')+\n  xlab('Audience')+\n  ggtitle('Results by Audience')+\n  scale_y_continuous(limits = c(0,.4),  breaks=seq(0,.4, by=.05)) +\n  scale_x_discrete(labels=c(\"philanthropy\",\"animal\"   ,\"climate\",\"general\",\"lookalike\",\"poverty\"))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\n\n\n1.8.7 PLOT: Cost adjusted DV (results) by age and gender\n15\n\n\nCode\ngwwc_vid_results$Gender <- as.factor(gwwc_vid_results$Gender)\n#levels(gwwc_vid_results$Gender)\n\nclass(gwwc_vid_results$Age)\n\n\n[1] \"factor\"\n\n\nCode\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"18-24\")\n#levels(gwwc_vid_results$Age)\n\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0) %>% group_by(Age,Gender) %>% summarise(results=mean(DV_costadj),SE=std.error(DV_costadj),n=n()),n=50)\n\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & Age!=\"13-17\") %>%\n  group_by(Age, Gender) %>%\n  summarise(mean_dv = mean(DV_costadj, na.rm=TRUE),\n            se_dv = sd(DV_costadj, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=Age, y=mean_dv, group=Gender, fill=Gender)) +\n  gg_gg_options +\n  labs(fill=\"Gender\")+\n  scale_fill_brewer(palette=\"Paired\")+\n  ylab('Results/$ spent')+\n  xlab('Age')+\n  ggtitle('Results/$ spent by Age and Gender')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.35),  breaks=seq(0,.35, by=.1)) +\n  scale_x_discrete(labels=c(\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\" ))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\n\n\n1.8.8 PLOT: DV (results) by age and gender\n\n\nCode\ngwwc_vid_results$Gender <- as.factor(gwwc_vid_results$Gender)\n#levels(gwwc_vid_results$Gender)\n\n#class(gwwc_vid_results$Age)\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"18-24\")\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"13-17\")\n#levels(gwwc_vid_results$Age)\n\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0) %>% group_by(Age,Gender) %>% summarise(results=100*mean(DV),SE=std.error(100*DV),n=n()),n=50)\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & Age!=\"13-17\") %>%\n  group_by(Age, Gender) %>%\n  summarise(mean_dv = 100*mean(DV, na.rm=TRUE),\n            se_dv = 100*sd(DV, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=Age, y=mean_dv, group=Gender, fill=Gender)) +\n  gg_gg_options +\n  labs(fill=\"Gender\")+\n  scale_fill_brewer(palette=\"Paired\")+\n  ylab('Results (%)')+\n  xlab('Age')+\n  ggtitle('Results by Age and Gender')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.75),  breaks=seq(0,.75, by=.25)) +\n  scale_x_discrete(labels=c(\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\" ))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\n\n\n1.8.9 PLOT: Cost adjusted DV (results) by Video and Age\n\n\nCode\nclass(gwwc_vid_results$Age)\n\n\n[1] \"factor\"\n\n\nCode\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"18-24\")\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"13-17\")\nlevels(gwwc_vid_results$Age)\n\n\n[1] \"13-17\" \"18-24\" \"25-34\" \"35-44\" \"45-54\" \"55-64\" \"65+\"  \n\n\nCode\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0) %>% group_by(Age,media) %>% summarise(results=mean(DV_costadj),SE=std.error(DV_costadj),n=n()),n=50)\n\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & Age!=\"13-17\") %>%\n  group_by(media, Age) %>%\n  summarise(mean_dv = mean(DV_costadj, na.rm=TRUE),\n            se_dv = sd(DV_costadj, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=Age, y=mean_dv, group=media, fill=media)) +\n  gg_gg_options +\n  labs(fill=\"Video\")+\n  scale_fill_brewer(palette=\"RdBu\")+\n  ylab('Results/$ spent')+\n  xlab('Age')+\n  ggtitle('Results/$ spent by Video and Age')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.2),  breaks=seq(0,.2, by=.05)) +\n  scale_x_discrete(labels=c(\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\"))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\n\n\n1.8.10 PLOT: DV (results) by video and age\n\n\nCode\nclass(gwwc_vid_results$Age)\n\n\n[1] \"factor\"\n\n\nCode\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"18-24\")\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"13-17\")\n#levels(gwwc_vid_results$Age)\n\ngwwc_vid_results %>% filter(ave.cost.impr>0) %>% group_by(Age,media) %>% summarise(results=100*mean(DV),SE=100*std.error(DV),n=n()) %>%\n  .kable(digits=2) %>%  .kable_styling()\n\n\n\n \n  \n    Age \n    media \n    results \n    SE \n    n \n  \n \n\n  \n    13-17 \n    factual short \n    0.00 \n    0.00 \n    176 \n  \n  \n    13-17 \n    animal \n    0.00 \n    0.00 \n    101 \n  \n  \n    13-17 \n    climate \n    0.00 \n    0.00 \n    20 \n  \n  \n    13-17 \n    factual long \n    0.00 \n    NA \n    1 \n  \n  \n    13-17 \n    hypercube \n    0.00 \n    0.00 \n    46 \n  \n  \n    13-17 \n    poverty \n    0.00 \n    0.00 \n    81 \n  \n  \n    18-24 \n    factual short \n    0.11 \n    0.01 \n    55,045 \n  \n  \n    18-24 \n    animal \n    0.12 \n    0.02 \n    35,453 \n  \n  \n    18-24 \n    climate \n    0.09 \n    0.03 \n    9,513 \n  \n  \n    18-24 \n    factual long \n    0.00 \n    0.00 \n    5,283 \n  \n  \n    18-24 \n    hypercube \n    0.12 \n    0.03 \n    18,632 \n  \n  \n    18-24 \n    poverty \n    0.14 \n    0.02 \n    23,823 \n  \n  \n    25-34 \n    factual short \n    0.15 \n    0.01 \n    124,020 \n  \n  \n    25-34 \n    animal \n    0.16 \n    0.02 \n    54,928 \n  \n  \n    25-34 \n    climate \n    0.17 \n    0.03 \n    17,904 \n  \n  \n    25-34 \n    factual long \n    0.08 \n    0.04 \n    5,161 \n  \n  \n    25-34 \n    hypercube \n    0.10 \n    0.02 \n    38,313 \n  \n  \n    25-34 \n    poverty \n    0.14 \n    0.02 \n    47,287 \n  \n  \n    35-44 \n    factual short \n    0.16 \n    0.02 \n    68,690 \n  \n  \n    35-44 \n    animal \n    0.23 \n    0.03 \n    34,263 \n  \n  \n    35-44 \n    climate \n    0.15 \n    0.05 \n    6,719 \n  \n  \n    35-44 \n    factual long \n    0.18 \n    0.07 \n    4,336 \n  \n  \n    35-44 \n    hypercube \n    0.09 \n    0.02 \n    18,794 \n  \n  \n    35-44 \n    poverty \n    0.20 \n    0.03 \n    25,492 \n  \n  \n    45-54 \n    factual short \n    0.26 \n    0.04 \n    17,482 \n  \n  \n    45-54 \n    animal \n    0.35 \n    0.04 \n    19,751 \n  \n  \n    45-54 \n    climate \n    0.24 \n    0.17 \n    851 \n  \n  \n    45-54 \n    factual long \n    0.15 \n    0.06 \n    4,548 \n  \n  \n    45-54 \n    poverty \n    0.30 \n    0.07 \n    6,090 \n  \n  \n    55-64 \n    factual short \n    0.35 \n    0.03 \n    28,557 \n  \n  \n    55-64 \n    animal \n    0.41 \n    0.04 \n    20,126 \n  \n  \n    55-64 \n    climate \n    0.33 \n    0.16 \n    1,221 \n  \n  \n    55-64 \n    factual long \n    0.17 \n    0.06 \n    4,848 \n  \n  \n    55-64 \n    poverty \n    0.20 \n    0.06 \n    6,150 \n  \n  \n    65+ \n    factual short \n    0.66 \n    0.04 \n    37,227 \n  \n  \n    65+ \n    animal \n    0.57 \n    0.06 \n    15,669 \n  \n  \n    65+ \n    climate \n    0.66 \n    0.16 \n    2,435 \n  \n  \n    65+ \n    factual long \n    0.40 \n    0.08 \n    6,179 \n  \n  \n    65+ \n    poverty \n    0.21 \n    0.07 \n    4,685 \n  \n\n\n\n\n\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr>0 & Age !=\"13-17\") %>%\n    group_by(media, Age) %>%\n  summarise(mean_dv = 100*mean(DV, na.rm=TRUE),\n            se_dv = 100*sd(DV, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=Age, y=mean_dv, group=media, fill=media)) +\n  gg_gg_options +\n  labs(fill=\"Video\")+\n  scale_fill_brewer(palette=\"RdBu\")+\n  ylab('Results (%)')+\n  xlab('Age')+\n  ggtitle('Results by Video and Age')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.85),  breaks=seq(0,.85, by=.25)) +\n  scale_x_discrete(labels=c(\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\"))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found"
  },
  {
    "objectID": "chapters/gwwc_gg.html#statistics-and-mi-needs-to-be-made-into-table",
    "href": "chapters/gwwc_gg.html#statistics-and-mi-needs-to-be-made-into-table",
    "title": "3  Giving What We Can: Giving guides",
    "section": "3.6 Statistics and mi– needs to be made into table",
    "text": "3.6 Statistics and mi– needs to be made into table\n\n3.6.1 Regressions with interactions\n\n\nCode\nsummary(lm(data = gwwc_vid_results, DV~Gender*Age+ave.cost.impr))\n\n\n\nCall:\nlm(formula = DV ~ Gender * Age + ave.cost.impr, data = gwwc_vid_results)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.04779 -0.00203 -0.00151 -0.00129  0.99914 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            -9.180e-04  3.006e-03  -0.305    0.760    \nGendermale              1.965e-04  4.810e-03   0.041    0.967    \nGenderunknown           4.097e-04  6.120e-03   0.067    0.947    \nAge18-24                1.497e-03  3.007e-03   0.498    0.619    \nAge25-34                1.799e-03  3.005e-03   0.599    0.549    \nAge35-44                1.874e-03  3.006e-03   0.623    0.533    \nAge45-54                2.607e-03  3.012e-03   0.865    0.387    \nAge55-64                2.712e-03  3.012e-03   0.900    0.368    \nAge65+                  4.702e-03  3.019e-03   1.557    0.119    \nave.cost.impr           4.306e-02  6.608e-03   6.516 7.25e-11 ***\nGendermale:Age18-24    -6.997e-05  4.817e-03  -0.015    0.988    \nGenderunknown:Age18-24 -4.670e-04  6.156e-03  -0.076    0.940    \nGendermale:Age25-34    -4.299e-04  4.814e-03  -0.089    0.929    \nGenderunknown:Age25-34 -7.873e-04  6.151e-03  -0.128    0.898    \nGendermale:Age35-44    -6.757e-06  4.818e-03  -0.001    0.999    \nGenderunknown:Age35-44 -8.994e-04  6.166e-03  -0.146    0.884    \nGendermale:Age45-54    -1.671e-03  4.845e-03  -0.345    0.730    \nGenderunknown:Age45-54  2.184e-03  6.270e-03   0.348    0.728    \nGendermale:Age55-64    -7.455e-04  4.836e-03  -0.154    0.877    \nGenderunknown:Age55-64  2.492e-04  6.247e-03   0.040    0.968    \nGendermale:Age65+      -1.479e-03  4.831e-03  -0.306    0.760    \nGenderunknown:Age65+   -9.135e-04  6.224e-03  -0.147    0.883    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04524 on 770091 degrees of freedom\nMultiple R-squared:  0.0009605, Adjusted R-squared:  0.0009332 \nF-statistic: 35.25 on 21 and 770091 DF,  p-value: < 2.2e-16\n\n\nCode\nsummary(lm(data = gwwc_vid_results,DV~Gender*Age))\n\n\n\nCall:\nlm(formula = DV ~ Gender * Age, data = gwwc_vid_results)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.00629 -0.00180 -0.00150 -0.00120  0.99895 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)  \n(Intercept)             3.049e-14  3.003e-03   0.000   1.0000  \nGendermale             -2.692e-14  4.810e-03   0.000   1.0000  \nGenderunknown           3.038e-14  6.119e-03   0.000   1.0000  \nAge18-24                1.132e-03  3.006e-03   0.376   0.7066  \nAge25-34                1.502e-03  3.004e-03   0.500   0.6172  \nAge35-44                1.706e-03  3.006e-03   0.568   0.5703  \nAge45-54                3.089e-03  3.011e-03   1.026   0.3050  \nAge55-64                3.507e-03  3.010e-03   1.165   0.2439  \nAge65+                  6.293e-03  3.010e-03   2.091   0.0365 *\nGendermale:Age18-24     6.977e-05  4.817e-03   0.014   0.9884  \nGenderunknown:Age18-24 -7.811e-05  6.156e-03  -0.013   0.9899  \nGendermale:Age25-34    -3.072e-04  4.814e-03  -0.064   0.9491  \nGenderunknown:Age25-34 -4.034e-04  6.151e-03  -0.066   0.9477  \nGendermale:Age35-44     9.669e-05  4.818e-03   0.020   0.9840  \nGenderunknown:Age35-44 -6.279e-04  6.166e-03  -0.102   0.9189  \nGendermale:Age45-54    -1.687e-03  4.845e-03  -0.348   0.7277  \nGenderunknown:Age45-54  2.235e-03  6.270e-03   0.356   0.7215  \nGendermale:Age55-64    -9.220e-04  4.836e-03  -0.191   0.8488  \nGenderunknown:Age55-64  2.439e-04  6.247e-03   0.039   0.9689  \nGendermale:Age65+      -2.110e-03  4.830e-03  -0.437   0.6623  \nGenderunknown:Age65+   -1.408e-03  6.224e-03  -0.226   0.8210  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04524 on 770092 degrees of freedom\nMultiple R-squared:  0.0009054, Adjusted R-squared:  0.0008794 \nF-statistic: 34.89 on 20 and 770092 DF,  p-value: < 2.2e-16\n\n\n\n\n3.6.2 Regressions with no interactions\njust demographics, not control\n\n\nCode\nsummary(data = lm(gwwc_vid_results,DV~Gender+Age))\n\n\nError in as.data.frame.default(data): cannot coerce class '\"formula\"' to a data.frame\n\n\njust demographic, controlling for cost\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nmeans and standard errors for age groups/gender\n\n\nCode\nprint(gwwc_vid_results %>% group_by(Gender,Age) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)\n\n\n# A tibble: 21 × 7\n# Groups:   Gender [3]\n   Gender  Age   results      SE      n   cost      CPR\n   <fct>   <fct>   <dbl>   <dbl>  <int>  <dbl>    <dbl>\n 1 female  13-17   0     0          227 0.0213 Inf     \n 2 female  18-24   0.113 0.0107   98953 0.0129   0.114 \n 3 female  25-34   0.150 0.00843 211071 0.0144   0.0960\n 4 female  35-44   0.171 0.0118  121915 0.0174   0.102 \n 5 female  45-54   0.309 0.0276   40467 0.0325   0.105 \n 6 female  55-64   0.351 0.0265   49900 0.0398   0.113 \n 7 female  65+     0.629 0.0350   51172 0.0583   0.0926\n 8 male    13-17   0     0          145 0.0168 Inf     \n 9 male    18-24   0.120 0.0165   44107 0.0115   0.0960\n10 male    25-34   0.119 0.0130   71149 0.0127   0.106 \n11 male    35-44   0.180 0.0234   32727 0.0153   0.0847\n12 male    45-54   0.140 0.0443    7134 0.0276   0.197 \n13 male    55-64   0.259 0.0516    9671 0.0311   0.120 \n14 male    65+     0.418 0.0558   13388 0.0390   0.0933\n15 unknown 13-17   0     0           72 0.0118 Inf     \n16 unknown 18-24   0.105 0.0471    4745 0.0124   0.117 \n17 unknown 25-34   0.110 0.0448    5462 0.0138   0.126 \n18 unknown 35-44   0.108 0.0539    3710 0.0142   0.132 \n19 unknown 45-54   0.532 0.217     1127 0.0242   0.0454\n20 unknown 55-64   0.375 0.167     1333 0.0302   0.0804\n21 unknown 65+     0.488 0.172     1638 0.0372   0.0763\n\n\n\n\nCode\nhist(gwwc_vid_results$DV_costadj[gwwc_vid_results$DV_costadj>0])\n\n\n\n\n\nCode\nhist(gwwc_vid_results$DV_costadj[gwwc_vid_results$DV_costadj>=0])\n\n\n\n\n\n\n\n3.6.3 DEMOGRAPHICS WITH CONTROLS FOR VIDEO AND COST\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\nsummary(lm(gwwc_vid_results, DV_costadj~Gender+Age))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\n\n3.6.3.1 AUDIENCES\nmain effects\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nNEW DV\n\n\nCode\nsummary(lm(gwwc_vid_results,DV_costadj~Gender+Age+audience))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #interactions\n  summary(lm(gwwc_vid_results,DV~Gender*audience+ave.cost.impr+Age))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n## NEW DV\n    summary(lm(gwwc_vid_results,DV_costadj~Gender*audience+Age))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  summary(lm(gwwc_vid_results,DV~Age*audience+ave.cost.impr+Gender))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #means for audience\n  print(gwwc_vid_results %>% group_by(audience) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)\n\n\n# A tibble: 7 × 6\n  audience     results      SE      n   cost    CPR\n  <fct>          <dbl>   <dbl>  <int>  <dbl>  <dbl>\n1 philanthropy   0.195 0.00885 248852 0.0220 0.112 \n2 animal         0.229 0.0110  187212 0.0222 0.0973\n3 climate        0.178 0.0113  139824 0.0181 0.102 \n4 general        0.112 0.0140   57012 0.0130 0.116 \n5 lookalike      0.344 0.0226   67359 0.0266 0.0773\n6 poverty        0.171 0.0157   69404 0.0182 0.106 \n7 retargeting    0.667 0.384      450 0.0250 0.0376\n\n\n\n\n3.6.3.2 MESSAGES\nno controls\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~message))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #control for cost only\n  summary(lm(gwwc_vid_results,DV~message+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #check results with campaign\n  summary(lm(gwwc_vid_results,DV~Campaign.name))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #check results with campaign and cost control\n  summary(lm(gwwc_vid_results,DV~Campaign.name+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nwith controls\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience+message))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #interactions\n  #with audience\n  summary(lm(gwwc_vid_results,DV~message*audience+ave.cost.impr+Age+Gender))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #with Gender\n  summary(lm(gwwc_vid_results,DV~message*Gender+ave.cost.impr+Age+audience))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #with Age (emotional much worse with ages 65+)\n  summary(lm(gwwc_vid_results,DV~message*Age+ave.cost.impr+Age+audience))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\ninteraction with age and campaign restriction\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~message*agetrin+message*restriction18_39+ave.cost.impr+Age+Gender))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~message*agetrin+message*restriction18_39+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nin just early campaigns\n\n\nCode\nsummary(lm(subset(data,restriction18_39==0),DV~message*agetrin+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': object 'restriction18_39' not found\n\n\n\n\n\n3.6.4 MEDIA\nno controls\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~media))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% group_by(media) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results)\n\n\n# A tibble: 6 × 6\n  media         results      SE      n   cost    CPR\n  <fct>           <dbl>   <dbl>  <int>  <dbl>  <dbl>\n1 factual short   0.223 0.00820 331287 0.0186 0.0834\n2 animal          0.250 0.0118  180327 0.0274 0.110 \n3 climate         0.186 0.0219   38703 0.0160 0.0862\n4 factual long    0.171 0.0237   30359 0.0378 0.221 \n5 hypercube       0.104 0.0117   75790 0.0176 0.169 \n6 poverty         0.165 0.0121  113647 0.0155 0.0939\n\n\ncontrol for cost only\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~media+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame"
  },
  {
    "objectID": "chapters/gwwc_gg.html#new-dv",
    "href": "chapters/gwwc_gg.html#new-dv",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.10 NEW DV",
    "text": "1.10 NEW DV\n\n\nCode\n#lm(gwwc_vid_results,DV_costadj~media))####THIS IS GOOD\n\n\nwith controls\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience+media)\n\n\n\n1.10.1 NEW DV\n\n\nCode\n#lm(gwwc_vid_results,DV_costadj~Gender+Age+audience+media)\n\n\ninteractions\n\n\nCode\n#lm(gwwc_vid_results,DV~media*Age+media*Gender+media*audience+ave.cost.impr)\n#lm(gwwc_vid_results,DV_costadj~media*Age+media*Gender+media*audience)\n#lm(gwwc_vid_results,DV~media*Age+media*Gender+media*audience)\n#lm(gwwc_vid_results,DV_costadj~Age+Gender+media*audience)\n\n\nwith audience\n\n\nCode\n#lm(gwwc_vid_results,DV~media*audience+ave.cost.impr+Age+Gender)\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% group_by(audience,media) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results) %>%\n.kable() %>% .kable_styling()\n\n\n\n \n  \n    audience \n    media \n    results \n    SE \n    n \n    cost \n    CPR \n  \n \n\n  \n    philanthropy \n    factual short \n    0.2278935 \n    0.0195196 \n    59,677 \n    0.0212306 \n    0.0931603 \n  \n  \n    philanthropy \n    animal \n    0.2124797 \n    0.0163273 \n    79,537 \n    0.0287906 \n    0.1354982 \n  \n  \n    philanthropy \n    climate \n    0.2748644 \n    0.0445292 \n    13,825 \n    0.0194358 \n    0.0707105 \n  \n  \n    philanthropy \n    factual long \n    0.1588907 \n    0.0478727 \n    6,923 \n    0.0442424 \n    0.2784455 \n  \n  \n    philanthropy \n    hypercube \n    0.1436699 \n    0.0287142 \n    17,401 \n    0.0165272 \n    0.1150360 \n  \n  \n    philanthropy \n    poverty \n    0.1496734 \n    0.0144587 \n    71,489 \n    0.0146207 \n    0.0976841 \n  \n  \n    animal \n    factual short \n    0.2025473 \n    0.0149169 \n    90,843 \n    0.0177818 \n    0.0877908 \n  \n  \n    animal \n    animal \n    0.2802197 \n    0.0186139 \n    80,651 \n    0.0264827 \n    0.0945071 \n  \n  \n    animal \n    factual long \n    0.1489118 \n    0.0412723 \n    8,730 \n    0.0331970 \n    0.2229308 \n  \n  \n    animal \n    hypercube \n    0.0715512 \n    0.0319895 \n    6,988 \n    0.0176674 \n    0.2469200 \n  \n  \n    climate \n    factual short \n    0.2051549 \n    0.0146018 \n    96,025 \n    0.0167376 \n    0.0815853 \n  \n  \n    climate \n    climate \n    0.1063830 \n    0.0274543 \n    14,100 \n    0.0135738 \n    0.1275933 \n  \n  \n    climate \n    factual long \n    0.1886397 \n    0.0444232 \n    9,542 \n    0.0362073 \n    0.1919389 \n  \n  \n    climate \n    hypercube \n    0.0942601 \n    0.0216151 \n    20,157 \n    0.0195252 \n    0.2071421 \n  \n  \n    general \n    factual short \n    0.0963824 \n    0.0248746 \n    15,563 \n    0.0096248 \n    0.0998600 \n  \n  \n    general \n    animal \n    0.1422880 \n    0.0367142 \n    10,542 \n    0.0134842 \n    0.0947667 \n  \n  \n    general \n    climate \n    0.1611171 \n    0.0464761 \n    7,448 \n    0.0100953 \n    0.0626583 \n  \n  \n    general \n    hypercube \n    0.0948852 \n    0.0206963 \n    22,132 \n    0.0162078 \n    0.1708143 \n  \n  \n    general \n    poverty \n    0.0753580 \n    0.0753580 \n    1,327 \n    0.0111831 \n    0.1484000 \n  \n  \n    lookalike \n    factual short \n    0.3886843 \n    0.0336381 \n    34,218 \n    0.0254869 \n    0.0655722 \n  \n  \n    lookalike \n    animal \n    0.4234148 \n    0.0668094 \n    9,447 \n    0.0398878 \n    0.0942050 \n  \n  \n    lookalike \n    climate \n    0.2129601 \n    0.0804179 \n    3,287 \n    0.0257438 \n    0.1208857 \n  \n  \n    lookalike \n    factual long \n    0.7181329 \n    0.3580964 \n    557 \n    0.0782406 \n    0.1089500 \n  \n  \n    lookalike \n    hypercube \n    0.2512563 \n    0.1449412 \n    1,194 \n    0.0249665 \n    0.0993667 \n  \n  \n    lookalike \n    poverty \n    0.2412093 \n    0.0359149 \n    18,656 \n    0.0206915 \n    0.0857822 \n  \n  \n    poverty \n    factual short \n    0.2124178 \n    0.0246672 \n    34,837 \n    0.0185498 \n    0.0873270 \n  \n  \n    poverty \n    factual long \n    0.1088139 \n    0.0486419 \n    4,595 \n    0.0349859 \n    0.3215200 \n  \n  \n    poverty \n    hypercube \n    0.0765697 \n    0.0312495 \n    7,836 \n    0.0180028 \n    0.2351167 \n  \n  \n    poverty \n    poverty \n    0.1535960 \n    0.0263218 \n    22,136 \n    0.0143694 \n    0.0935529 \n  \n  \n    retargeting \n    factual short \n    0.0000000 \n    0.0000000 \n    124 \n    0.0254032 \n    Inf \n  \n  \n    retargeting \n    animal \n    0.6666667 \n    0.6666667 \n    150 \n    0.0304000 \n    0.0456000 \n  \n  \n    retargeting \n    climate \n    0.0000000 \n    0.0000000 \n    43 \n    0.0200000 \n    Inf \n  \n  \n    retargeting \n    factual long \n    8.3333333 \n    8.3333333 \n    12 \n    0.0933333 \n    0.0112000 \n  \n  \n    retargeting \n    hypercube \n    0.0000000 \n    0.0000000 \n    82 \n    0.0131707 \n    Inf \n  \n  \n    retargeting \n    poverty \n    2.5641026 \n    2.5641026 \n    39 \n    0.0128205 \n    0.0050000 \n  \n\n\n\n\n\nwith Gender\n\n\nCode\n#lm(gwwc_vid_results,DV~media*Gender+ave.cost.impr+Age+audience)\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% group_by(Gender, media) %>% summarise(\n  results = mean(DV) * 100,\n  SE = std.error(DV) * 100,\n  n = n(),\n  cost = mean(ave.cost.impr),\n  CPR = cost / results\n)\n\n\n\ninteraction with age and campaign restriction - old people really hated factual long\n\n\nCode\n#lm(gwwc_vid_results,DV~media*agetrin+media*restriction18_39+ave.cost.impr+Age+Gender))\n#lm(gwwc_vid_results,DV~media*agetrin+media*restriction18_39+ave.cost.impr))\n\n\nin just early campaigns\n\n\nCode\n#subset(gwwc_vid_results,restriction18_39==0),DV~media*agetrin+ave.cost.impr))\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% filter(restriction18_39 == 0) %>% group_by(Age, media) %>% summarise(\n  results = mean(DV) * 100,\n  SE = std.error(DV) * 100,\n  n = n(),\n  cost = mean(ave.cost.impr),\n  CPR = cost / results\n)"
  },
  {
    "objectID": "chapters/gwwc_gg.html#statistics-and-models-needs-to-be-made-into-tables",
    "href": "chapters/gwwc_gg.html#statistics-and-models-needs-to-be-made-into-tables",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.9 Statistics and models – needs to be made into tables",
    "text": "1.9 Statistics and models – needs to be made into tables\n\n1.9.1 Regressions with interactions\n\n\nCode\n#lm(data = gwwc_vid_results, DV~Gender*Age+ave.cost.impr)\n#lm(data = gwwc_vid_results,DV~Gender*Age))\n\n\n\n\n1.9.2 Regressions with no interactions\njust demographics, not control\n\n\nCode\n#data = lm(gwwc_vid_results,DV~Gender+Age)\n\n\njust demographic, controlling for cost\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr)\n\n\nmeans and standard errors for age groups/gender\n\n\nCode\ngwwc_vid_results %>% group_by(Gender,Age) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results) %>%\n  .kable() %>% .kable_styling()\n\n\n\n \n  \n    Gender \n    Age \n    results \n    SE \n    n \n    cost \n    CPR \n  \n \n\n  \n    female \n    13-17 \n    0.0000000 \n    0.0000000 \n    227 \n    0.0213216 \n    Inf \n  \n  \n    female \n    18-24 \n    0.1131850 \n    0.0106890 \n    98,953 \n    0.0128517 \n    0.1135455 \n  \n  \n    female \n    25-34 \n    0.1501864 \n    0.0084290 \n    211,071 \n    0.0144178 \n    0.0959994 \n  \n  \n    female \n    35-44 \n    0.1706107 \n    0.0118197 \n    121,915 \n    0.0174212 \n    0.1021111 \n  \n  \n    female \n    45-54 \n    0.3088937 \n    0.0275859 \n    40,467 \n    0.0325183 \n    0.1052736 \n  \n  \n    female \n    55-64 \n    0.3507014 \n    0.0264643 \n    49,900 \n    0.0397964 \n    0.1134766 \n  \n  \n    female \n    65+ \n    0.6292504 \n    0.0349566 \n    51,172 \n    0.0582582 \n    0.0925835 \n  \n  \n    male \n    13-17 \n    0.0000000 \n    0.0000000 \n    145 \n    0.0167586 \n    Inf \n  \n  \n    male \n    18-24 \n    0.1201623 \n    0.0164958 \n    44,107 \n    0.0115342 \n    0.0959887 \n  \n  \n    male \n    25-34 \n    0.1194676 \n    0.0129504 \n    71,149 \n    0.0127057 \n    0.1063529 \n  \n  \n    male \n    35-44 \n    0.1802793 \n    0.0234496 \n    32,727 \n    0.0152608 \n    0.0846508 \n  \n  \n    male \n    45-54 \n    0.1401738 \n    0.0442989 \n    7,134 \n    0.0275820 \n    0.1967700 \n  \n  \n    male \n    55-64 \n    0.2585048 \n    0.0516368 \n    9,671 \n    0.0311354 \n    0.1204440 \n  \n  \n    male \n    65+ \n    0.4182850 \n    0.0557807 \n    13,388 \n    0.0390365 \n    0.0933250 \n  \n  \n    unknown \n    13-17 \n    0.0000000 \n    0.0000000 \n    72 \n    0.0118056 \n    Inf \n  \n  \n    unknown \n    18-24 \n    0.1053741 \n    0.0471048 \n    4,745 \n    0.0123688 \n    0.1173800 \n  \n  \n    unknown \n    25-34 \n    0.1098499 \n    0.0448255 \n    5,462 \n    0.0138191 \n    0.1258000 \n  \n  \n    unknown \n    35-44 \n    0.1078167 \n    0.0538865 \n    3,710 \n    0.0142102 \n    0.1318000 \n  \n  \n    unknown \n    45-54 \n    0.5323869 \n    0.2168629 \n    1,127 \n    0.0241792 \n    0.0454167 \n  \n  \n    unknown \n    55-64 \n    0.3750938 \n    0.1674950 \n    1,333 \n    0.0301575 \n    0.0804000 \n  \n  \n    unknown \n    65+ \n    0.4884005 \n    0.1723061 \n    1,638 \n    0.0372466 \n    0.0762625 \n  \n\n\n\n\n\n\n\nCode\nhist(gwwc_vid_results$DV_costadj[gwwc_vid_results$DV_costadj>0])\n\n\n\n\n\nCode\nhist(gwwc_vid_results$DV_costadj[gwwc_vid_results$DV_costadj>=0])\n\n\n\n\n\n\n\n1.9.3 DEMOGRAPHICS WITH CONTROLS FOR VIDEO AND COST\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr)\n#lm(gwwc_vid_results, DV_costadj~Gender+Age)\n\n\n\n1.9.3.1 AUDIENCES\nmain effects\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience)\n\n\nNEW DV\n\n\nCode\n#lm(gwwc_vid_results,DV_costadj~Gender+Age+audience)\n\n  #interactions\n  #lm(gwwc_vid_results,DV~Gender*audience+ave.cost.impr+Age)\n\n## NEW DV\n    #lm(gwwc_vid_results,DV_costadj~Gender*audience+Age)\n  #lm(gwwc_vid_results,DV~Age*audience+ave.cost.impr+Gender)\n\n  #means for audience\ngwwc_vid_results %>%\n  group_by(audience) %>%\n  summarise(\n    results=mean(DV)*100,\n    SE=std.error(DV)*100,\n    n=n(),\n    cost=mean(ave.cost.impr),\n    CPR=cost/results) %>%\n    .kable %>%\n      .kable_styling()\n\n\n\n \n  \n    audience \n    results \n    SE \n    n \n    cost \n    CPR \n  \n \n\n  \n    philanthropy \n    0.1952968 \n    0.0088502 \n    248,852 \n    0.0219596 \n    0.1124424 \n  \n  \n    animal \n    0.2286178 \n    0.0110380 \n    187,212 \n    0.0222447 \n    0.0973009 \n  \n  \n    climate \n    0.1780810 \n    0.0112754 \n    139,824 \n    0.0181491 \n    0.1019149 \n  \n  \n    general \n    0.1122571 \n    0.0140244 \n    57,012 \n    0.0129917 \n    0.1157312 \n  \n  \n    lookalike \n    0.3444232 \n    0.0225737 \n    67,359 \n    0.0266180 \n    0.0772828 \n  \n  \n    poverty \n    0.1714599 \n    0.0157043 \n    69,404 \n    0.0182429 \n    0.1063975 \n  \n  \n    retargeting \n    0.6666667 \n    0.3840420 \n    450 \n    0.0250444 \n    0.0375667 \n  \n\n\n\n\n\n\n\n1.9.3.2 MESSAGES\nno controls\n\n\nCode\n#lm(gwwc_vid_results,DV~message\n  #control for cost only\n  #lm(gwwc_vid_results,DV~message+ave.cost.impr)\n  #check results with campaign\n  #lm(gwwc_vid_results,DV~Campaign.name)\n  #check results with campaign and cost control\n  #lm(gwwc_vid_results,DV~Campaign.name+ave.cost.impr)\n\n\nwith controls\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience+message)\n\n#interactions\n#with audience\n#lm(gwwc_vid_results,DV~message*audience+ave.cost.impr+Age+Gender)\n#with Gender\n#lm(gwwc_vid_results,DV~message*Gender+ave.cost.impr+Age+audience)\n#with Age (emotional much worse with ages 65+)\n#lm(gwwc_vid_results,DV~message*Age+ave.cost.impr+Age+audience)\n\n\ninteraction with age and campaign restriction\n\n\nCode\n#lm(gwwc_vid_results,DV~message*agetrin+message*restriction18_39+ave.cost.impr+Age+Gender)\n#lm(gwwc_vid_results,DV~message*agetrin+message*restriction18_39+ave.cost.impr)\n\n\nin just early campaigns\n\n\nCode\n#lm(subset(data,restriction18_39==0),DV~message*agetrin+ave.cost.impr)\n\n\n\n\n\n1.9.4 MEDIA\nno controls\n\n\nCode\n#lm(gwwc_vid_results,DV~media)\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% group_by(media) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results)\n\n\n# A tibble: 6 × 6\n  media         results      SE      n   cost    CPR\n  <fct>           <dbl>   <dbl>  <int>  <dbl>  <dbl>\n1 factual short   0.223 0.00820 331287 0.0186 0.0834\n2 animal          0.250 0.0118  180327 0.0274 0.110 \n3 climate         0.186 0.0219   38703 0.0160 0.0862\n4 factual long    0.171 0.0237   30359 0.0378 0.221 \n5 hypercube       0.104 0.0117   75790 0.0176 0.169 \n6 poverty         0.165 0.0121  113647 0.0155 0.0939\n\n\ncontrol for cost only\n\n\nCode\n#lm(gwwc_vid_results,DV~media+ave.cost.impr)"
  },
  {
    "objectID": "chapters/gwwc_gg.html#analysis-and-visuals",
    "href": "chapters/gwwc_gg.html#analysis-and-visuals",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.7 Analysis and visuals",
    "text": "1.7 Analysis and visuals\n13\n\n\nCode\n##gwwc_vid_results$DV_costadj)\n##gwwc_vid_results$DV)\n##gwwc_vid_results$ave.cost.impr)\n\n\nData summary\n\nBelow, a few data summary bits (from Erin). I commented most of it out and will redo it using an automated and formatted ‘key summary statistics’ package.\nI may also present the data in a dashboard for self-service.\n\n\n\nCode\n#datatable(gwwc_vid_results)\n\n\n\n\nCode\n#gwwc_vid_results %>% group_by(Age) %>% summarise(n=n()) %>% .kable() %>%  .kable_styling()\n#gwwc_vid_results %>% group_by(Gender) %>% summarise(n=n())  %>% .kable() %>%  .kable_styling()\n\n#print(gwwc_vid_results %>% group_by(Gender,Age) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=40)\n#print(gwwc_vid_results %>% group_by(Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=41)\n#print(gwwc_vid_results %>% group_by(Campaign.name,Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=100)\n\n#gwwc_vid_results %>% group_by(audience) %>% summarise(n=n(), cost=mean(ave.cost.impr)*100) %>% .kable(digits=2, caption=\"Average cost per impression (in pennies)\") %>%  .kable_styling()\n\n#gwwc_vid_results %>% group_by(message) %>% summarise(n=n(),cost=mean(ave.cost.impr)*100) %>% .kable(digits=2, caption=\"Average cost per impression (in pennies)\") %>%  .kable_styling()\n\n\n\n\nCode\n### CHART DATA\n\n#print(gwwc_vid_results %>% group_by(audience,media) %>% #summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)"
  },
  {
    "objectID": "chapters/gwwc_gg.html#notes-from-the-trial-description",
    "href": "chapters/gwwc_gg.html#notes-from-the-trial-description",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.2 Notes from the trial description",
    "text": "1.2 Notes from the trial description\n“In the original version of our test, we had 1 video for the factual appeal and 3 videos for the cause led approach - 1 for global health and development, 1 for animal welfare and 1 for climate change.”\n“We targeted our ads to audiences we thought were likely to engage based on their interests and demographics, and targeted the cause led videos to a relevant audience, i.e. climate change message to climate change audience.”\n“We also had various text above the videos that were displayed and optimised.”\nDetails in Gitbook HERE and Gdoc here\n\n\nCode\nknitr::include_url(\"https://effective-giving-marketing.gitbook.io/untitled/partner-organizations-and-trials/gwwc/giving-guides-+\")"
  },
  {
    "objectID": "chapters/gwwc_gg.html#the-trial",
    "href": "chapters/gwwc_gg.html#the-trial",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.1 The trial",
    "text": "1.1 The trial\nSee full description in the gitbook here.\nContext: Facebook advertisements on a range of audiences\n\nEffective Giving Guide Lead Generation campaign … ran late November 2021 - January 2022. The objective of this campaign was to see whether a factual [‘who researches giving’ or ‘magnitude of impact differences’] or cause-led approach was more cost-effective at getting people to fill out a form and give us their email in order to download our Effective Giving Guide.\n\n\n1.1.1 Treatments (text \\(\\times\\) video)\nThere were two dimensions of treatment content:\n\nThe texts displayed above the videos\n\n\n\n\n\n\n\nTexts\n\n\n\n\n\nBigger difference next year: Want to make a bigger difference next year? Start with our Effective Giving Guide and learn how to make a remarkable impact just by carefully choosing the charities you give to.\n100x impact: Did you know that the best charities can have a 100x greater impact? Download our free Effective Giving Guide for the best tips on doing the most good this holiday season.\n6000 people: Giving What We Can has helped 6,000+ people make a bigger impact on the causes they care about most. Download our free guide and learn how you can do the same.\nCause list: Whether we’re moved by animal welfare, the climate crisis, or worldwide humanitarian efforts, our community is united by one thing: making the biggest impact we can. Make a bigger difference in the world through charitable giving. Start by downloading our Effective Giving Guide. You’ll learn how to approach charity research and smart giving. And be sure to share it with others who care about making a greater impact on the causes closest to their hearts.\nLearn: Use our free guide to learn how to make a bigger impact on the causes you care about most.\nOnly 3% research: Only 3% of donors give based on charity effectiveness yet the best charities can be 100x more impactful. That’s incredible! Check out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes.\nOverwhelming: It can be overwhelming with so many problems in the world. Fortunately, we can do a lot to help, if we give effectively. Check out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes.\n\n\n\n\n\n\n\n\n\nCheck against data export of texts\n\n\n\n\n\nGiving What We Can has helped 6,000+ people make a bigger impact on the causes they care about most. Download our free guide and learn how you can do the same., It can be overwhelming with so many problems in the world. Fortunately, we can do a lot to help, if we give effectively.\nCheck out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes., Use our free guide to learn how to make a bigger impact on the causes you care about most., Want to make a bigger difference next year? Start with our Effective Giving Guide and learn how to make a remarkable impact just by carefully choosing the charities you give to., Whether we’re moved by animal welfare, the climate crisis, or worldwide humanitarian efforts, our community is united by one thing: making the biggest impact we can.\nMake a bigger difference in the world through charitable giving. Start by downloading our Effective Giving Guide. You’ll learn how to approach charity research and smart giving. And be sure to share it with others who care about making a greater impact on the causes closest to their hearts., Did you know that the best charities can have a 100x greater impact? Download our free Effective Giving Guide for the best tips on doing the most good this holiday season., Only 3% of donors give based on charity effectiveness yet the best charities can be 100x more impactful. That’s incredible!\nCheck out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes.\n\n\n\n\nThe Video ads theme and content\n\n\n\n\n\n\n\n“Facts”\n\n\n\n\n\n\nCharity research facts short video (8 seconds): Only 3% of donors research charity effectiveness, yet the best charities can 100x your impact, learn how to give effectively \nCharity research facts long video (22 seconds): Trivial things we search (shows someone searching how to do Gangnam style), things we should research (shows someone searching how to donate effectively), only 3% of donors research charity effectiveness, yet the best charities can 100x your impact, learn how to give effectively. Slower paced music compared to the short video and cause videos.  \n\n\n\n\n\n\n\n\n\n\n“Cause focus”\n\n\n\n\n\n\nClimate change (15 seconds): Care about climate change? You don’t have to renounce all your possessions, But you could give to effective environmental charities, Learn how to maximize your charitable impact, Download the Effective Giving Guide \nAnimal welfare (16 seconds): Care about animals? You don’t have to adopt 100 cats, But you could give to effective animal charities, Learn how to maximize your charitable impact, Download the Effective Giving Guide \nPoverty (16 seconds): Want to help reduce global poverty? You don’t have to build a village, But you could give to effective global development charities, Learn how to maximize your charitable impact, Download the Effective Giving Guide \n\n\n\n\n\n\n\n\n\n\nArguments, rich content from “Hypercube”\n\n\n\n\n\n\nHypercube (1 min 22 seconds): Animated and voiceover video that explains how GWWC can help maximize charitable impact (support, community, and information) and the problems GWWC addresses (good intentions don’t always produce the desired outcomes, there are millions of charities that have varying degrees of impact and some can even cause harm). CTA: Check out givingwhatwecan.org to learn how you can become an effective giver.\n\n\n\n\n\n\nFurther detail, links\n\n\n\n\n\n\nNotes from the trial description\n\n\n\n\n\n“In the original version of our test, we had 1 video for the factual appeal and 3 videos for the cause led approach - 1 for global health and development, 1 for animal welfare and 1 for climate change.”\n“We targeted our ads to audiences we thought were likely to engage based on their interests and demographics, and targeted the cause led videos to a relevant audience, i.e. climate change message to climate change audience.”\n“We also had various text above the videos that were displayed and optimized.”\n\n\n\nDetails in Gitbook HERE (and embedded below) and Gdoc here\n\n\nCode\nknitr::include_url(\"https://effective-giving-marketing.gitbook.io/untitled/partner-organizations-and-trials/gwwc/giving-guides-+\")"
  },
  {
    "objectID": "chapters/gwwc_gg.html#implementation-and-treatment-assignment-key-details",
    "href": "chapters/gwwc_gg.html#implementation-and-treatment-assignment-key-details",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.2 Implementation and treatment assignment: key details",
    "text": "1.2 Implementation and treatment assignment: key details\n\n\n\n\n\n\nTreatment assignment order, dates\n\n\n\n\n\nThe treatment assignment was determined by Facebook’s algorithm. Video content was manipulated across three split tests.\nTest 1 (Nov 30, 2021 – Dec 8, 2021) displayed either the long factual video or a cause focus video. In the cause focus condition, cause-specific audiences for animal rights, climate change, and poverty (based on their behavior on Facebook) were shown the relevant cause video.\nTest 2 (add dates) was the same as Test 1 but used the short factual video instead of the cause-focus videos.\nTest 3 (add dates) was the same as Test 2 but had a new version of the videos (with Luke just holding up signs with the words). This test was also restricted to 18-35 year olds.\nTest 4: The Hypercube video was displayed in a separate “Hypercube” campaign which was tested against another campaign that allowed the algorithm to optimize between the ‘short factual’ and ‘cause focus’ videos (although not allowing each cause-specific audience to see the ads for other cause areas).\nIn all tests, the text content displayed above the video was determined by Facebook’s algorithm. Balance across variations was determined to equate budgets across split tests; otherwise, according to Facebook’s algorithm. All variation was done at the level of the impression.\nThe videos were adapted across the trials as we learned. First, we updated the factual video to be shorter for Trial 2, and then we tried videos of Luke holding up signs spelling out the voiceover in Trial 3 for all videos."
  },
  {
    "objectID": "chapters/gwwc_gg.html#descriptives",
    "href": "chapters/gwwc_gg.html#descriptives",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.4 Descriptives",
    "text": "1.4 Descriptives\n\n1.4.1 Implemented treatments, impressions\nFirst we illustrate ‘where, when, and to whom’ the different campaigns and treatments were shown (Facebook ‘impressions’).\nThe sequential campaigns involved different sets of videos, and these videos had different versions:\n\n\nCode\n(\n  impressions_campaign_theme <- gg_video_breakdowns %>%\n  dplyr::select(campaign_name, video_theme, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n   tabyl(campaign_name, video_theme) %>%\n    dplyr::select(campaign_name, Animal, Climate, Poverty, everything()) %>% \n  .kable(caption = \"Campaign names and video themes: Impressions\") %>%\n  .kable_styling()\n)\n\n\n\nCampaign names and video themes: Impressions\n \n  \n    campaign_name \n    Animal \n    Climate \n    Poverty \n    Factual short \n    Factual long \n    Hypercube (factual) \n  \n \n\n  \n    Giving Guide 2021 - Cause-led \n    106,870 \n    6,494 \n    36,306 \n    0 \n    0 \n    0 \n  \n  \n    Giving Guide 2021 – Cause-led V3 \n    45,856 \n    4,478 \n    74,714 \n    0 \n    0 \n    0 \n  \n  \n    Giving Guide 2021 – Factual \n    0 \n    0 \n    0 \n    2,459 \n    30,359 \n    0 \n  \n  \n    Giving Guide 2021 – Factual V2 \n    0 \n    0 \n    0 \n    120,530 \n    0 \n    0 \n  \n  \n    Giving Guide 2021 – Factual V3 \n    0 \n    0 \n    0 \n    137,679 \n    0 \n    0 \n  \n  \n    Giving Guide 2021 – Hypercube Brand Video \n    0 \n    0 \n    1,571 \n    0 \n    0 \n    74,219 \n  \n  \n    Giving Guide 2021 – PPCo Creatives \n    27,595 \n    27,735 \n    2,629 \n    70,619 \n    0 \n    0 \n  \n\n\n\n\n\nCode\nimpressions_campaign_audience <- gg_campaign_by_ad_by_text_age_gender %>% #created but not shown for now\n  dplyr::select(campaign_name, audience, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n   tabyl(campaign_name, audience) %>%\n  .kable(caption = \"Campaign names and audiences: Impressions\") %>%\n  .kable_styling()\n\n\n\n\n\n\n\n\nVersions of videos: impressions\n\n\n\n\n\n\n\nCode\n(\n  versions_of_videos <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(video_theme, version, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n   table %>%\n  .kable(caption = \"Versions of videos: Impressions\") %>%\n  .kable_styling()\n)\n\n\n\nVersions of videos: Impressions\n \n  \n      \n    V1 \n    V2 - factual shortened \n    V3 - sometimes Luke \n    Video/creatives \n  \n \n\n  \n    Animal \n    48,494 \n    0 \n    23,796 \n    0 \n  \n  \n    Cause-led (any) \n    90,897 \n    0 \n    87,338 \n    128,578 \n  \n  \n    Climate \n    2,059 \n    0 \n    346 \n    0 \n  \n  \n    Factual long \n    32,818 \n    0 \n    0 \n    0 \n  \n  \n    Factual short \n    0 \n    120,530 \n    137,679 \n    0 \n  \n  \n    Hypercube (factual) \n    0 \n    0 \n    0 \n    75,790 \n  \n  \n    Poverty \n    8,220 \n    0 \n    13,568 \n    0 \n  \n\n\n\n\n\n\n\n\nSome audiences were profiled as associated with a certain cause (through their Facebook interests or activities): in ‘cause-focused’ campaigns they were shown videos for their profiled cause. In campaigns that were not cause-focused, they were shown general interest videos. However, those associated with one cause were never shown videos for other causes.\nAudiences not associated with a cause included the ‘General’ audience, the Philanthropy (interested in charity) audience, a GWWC ‘Lookalike’ audience, and a Retargeted (?) audience: these were shown either the more general-interest videos or particular cause videos. 5. This is illustrated in the table below.\n\n\n\nCode\nvideo_levels <- c(\"Animal\", \"Climate\", \"Poverty\", \"Factual short\",  \"Factual long\", \"Hypercube (factual)\", \"Total\")\n  \n(\nimpressions_video_audience <- gg_video_breakdowns %>%\n    dplyr::select(video_theme, audience, impressions) %>%\n    uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n    tabyl(video_theme, audience) %>% \n    adorn_percentages(\"all\") %>%\n    adorn_totals(where = c(\"row\", \"col\")) %>% \n    adorn_pct_formatting(digits = 2) %>% \n    dplyr::select(video_theme, Animal, Climate, `Global Poverty`, everything()) %>% \n   mutate(video_theme =  factor(video_theme, levels = video_levels)) %>%\n  arrange(video_theme)  %>% \n    .kable(caption = \"Video themes by audience: share of impressions\", digits=3) %>%\n  .kable_styling()\n)\n\n\n\nVideo themes by audience: share of impressions\n \n  \n    video_theme \n    Animal \n    Climate \n    Global Poverty \n    General audience \n    Lookalikes \n    Philanthropy \n    Retargeting \n    Total \n  \n \n\n  \n    Animal \n    10.47% \n    0.00% \n    0.00% \n    1.37% \n    1.23% \n    10.33% \n    0.02% \n    23.41% \n  \n  \n    Climate \n    0.00% \n    1.83% \n    0.00% \n    0.97% \n    0.43% \n    1.80% \n    0.01% \n    5.03% \n  \n  \n    Poverty \n    0.01% \n    0.05% \n    2.88% \n    0.22% \n    2.43% \n    9.36% \n    0.01% \n    14.96% \n  \n  \n    Factual short \n    11.80% \n    12.47% \n    4.52% \n    2.02% \n    4.44% \n    7.75% \n    0.02% \n    43.02% \n  \n  \n    Factual long \n    1.13% \n    1.24% \n    0.60% \n    0.00% \n    0.07% \n    0.90% \n    0.00% \n    3.94% \n  \n  \n    Hypercube (factual) \n    0.90% \n    2.57% \n    1.01% \n    2.83% \n    0.15% \n    2.18% \n    0.01% \n    9.64% \n  \n  \n    Total \n    24.31% \n    18.16% \n    9.01% \n    7.40% \n    8.75% \n    32.31% \n    0.06% \n    100.00% \n  \n\n\n\n\n\n\n\nBelow, we see that the second treatment dimension – text presented along with the video – was allowed to vary independently of the video (but these are probably not ‘statistically independent’).\n\n\nCode\nvideo_levels_gg <- c(\"Animal\", \"Climate\", \"Poverty\", \"Cause-led (any)\", \"Factual short\",  \"Factual long\", \"Hypercube (factual)\", \"Total\")\n\n(\n  impressions_video_text <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(video_theme, text_treat, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n        tabyl(video_theme, text_treat) %>% \n    adorn_percentages(\"all\") %>%\n    adorn_totals(where = c(\"row\", \"col\")) %>% \n    adorn_pct_formatting(digits = 2) %>% \n   mutate(video_theme =  factor(video_theme, levels = video_levels_gg)) %>%\n  arrange(video_theme)  %>% \n  .kable(caption = \"Video themes by text treatment: Impressions\", digits=3) %>%\n  .kable_styling()\n)\n\n\n\nVideo themes by text treatment: Impressions\n \n  \n    video_theme \n    100x impact \n    6000+ people \n    Bigger difference \n    Cause list \n    Learn \n    Only 3% research \n    Overwhelming \n    Total \n  \n \n\n  \n    Animal \n    0.00% \n    2.23% \n    3.72% \n    1.05% \n    1.22% \n    0.00% \n    1.16% \n    9.39% \n  \n  \n    Climate \n    0.00% \n    0.04% \n    0.05% \n    0.04% \n    0.14% \n    0.00% \n    0.05% \n    0.31% \n  \n  \n    Poverty \n    0.00% \n    0.37% \n    0.78% \n    1.04% \n    0.35% \n    0.00% \n    0.30% \n    2.83% \n  \n  \n    Cause-led (any) \n    4.61% \n    8.73% \n    5.67% \n    3.42% \n    6.63% \n    3.30% \n    7.47% \n    39.84% \n  \n  \n    Factual short \n    9.91% \n    5.23% \n    7.43% \n    0.00% \n    4.50% \n    6.45% \n    0.00% \n    33.53% \n  \n  \n    Factual long \n    0.57% \n    0.80% \n    0.94% \n    0.00% \n    1.28% \n    0.67% \n    0.00% \n    4.26% \n  \n  \n    Hypercube (factual) \n    2.87% \n    1.37% \n    1.65% \n    0.00% \n    1.55% \n    2.40% \n    0.00% \n    9.84% \n  \n  \n    Total \n    17.96% \n    18.78% \n    20.24% \n    5.56% \n    15.67% \n    12.83% \n    8.97% \n    100.00% \n  \n\n\n\n\n\n\n6\nHowever, note that treatment shares are not equal. In fact, as the first table in this section shows, they are not even equal within each campaign. This is because Facebook optimizes to show videos and text more, the more successful they are.7\nAs shown in the fold below, the set of text treatments varied across campaigns:\n\n\n\n\n\n\nText treatments by campaign\n\n\n\n\n\n\n\nCode\n(\n  impressions_text_campaign <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(campaign_name, text_treat, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n   table %>%\n        prop.table() %>% \n        addmargins() %>% \n  .kable(caption = \"Text treatments by campaign: Impressions\", digits=3) %>%\n  .kable_styling()\n)\n\n\n\nText treatments by campaign: Impressions\n \n  \n      \n    100x impact \n    6000+ people \n    Bigger difference \n    Cause list \n    Learn \n    Only 3% research \n    Overwhelming \n    Sum \n  \n \n\n  \n    Cause-led \n    0.000 \n    0.050 \n    0.056 \n    0.029 \n    0.025 \n    0.000 \n    0.035 \n    0.194 \n  \n  \n    Cause-led V3 \n    0.000 \n    0.040 \n    0.017 \n    0.027 \n    0.024 \n    0.000 \n    0.055 \n    0.162 \n  \n  \n    Factual \n    0.006 \n    0.008 \n    0.009 \n    0.000 \n    0.013 \n    0.007 \n    0.000 \n    0.043 \n  \n  \n    Factual V2 \n    0.046 \n    0.015 \n    0.034 \n    0.000 \n    0.018 \n    0.044 \n    0.000 \n    0.157 \n  \n  \n    Factual V3 \n    0.053 \n    0.037 \n    0.041 \n    0.000 \n    0.028 \n    0.020 \n    0.000 \n    0.179 \n  \n  \n    Hypercube Brand Video \n    0.029 \n    0.014 \n    0.017 \n    0.000 \n    0.015 \n    0.024 \n    0.000 \n    0.098 \n  \n  \n    PPCo Creatives \n    0.046 \n    0.024 \n    0.029 \n    0.000 \n    0.034 \n    0.033 \n    0.000 \n    0.167 \n  \n  \n    Sum \n    0.180 \n    0.188 \n    0.202 \n    0.056 \n    0.157 \n    0.128 \n    0.090 \n    1.000 \n  \n\n\n\n\n\n\n\n\n\n\n1.4.2 Demographics\n\n\nCode\n(\n  impressions_age_gender <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(age, gender, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n   table %>%\n    prop.table() %>% \n    addmargins() %>% \n  .kable(caption = \"Impressions by Age and Gender\", digits=2) %>%\n  .kable_styling()\n)\n\n\n\nImpressions by Age and Gender\n \n  \n      \n    female \n    male \n    unknown \n    Sum \n  \n \n\n  \n    13-17 \n    0.00 \n    0.00 \n    0.00 \n    0.00 \n  \n  \n    18-24 \n    0.13 \n    0.06 \n    0.01 \n    0.19 \n  \n  \n    25-34 \n    0.27 \n    0.09 \n    0.01 \n    0.37 \n  \n  \n    35-44 \n    0.16 \n    0.04 \n    0.00 \n    0.21 \n  \n  \n    45-54 \n    0.05 \n    0.01 \n    0.00 \n    0.06 \n  \n  \n    55-64 \n    0.06 \n    0.01 \n    0.00 \n    0.08 \n  \n  \n    65+ \n    0.07 \n    0.02 \n    0.00 \n    0.09 \n  \n  \n    Sum \n    0.74 \n    0.23 \n    0.02 \n    1.00 \n  \n\n\n\n\n\nAs can be clearly seen above, within all age groups, the ad was disproportionally shown to women. Relative to the overall Facebook population our data skews very slightly younger.8\n\n\n1.4.3 Outcomes\nBelow, we present the dates of each campaign, along with start dates and results:\n\n\n\nCode\nbase_results_sum <- function(df) {\n    df %>%\n     dplyr::summarize(\n  Cost = sum(round(amount_spent_usd,0)),\n      `Impressions`=sum(impressions),\n      `Link clicks`=sum(link_clicks, na.rm = TRUE),\n      Results=sum(results, na.rm = TRUE),\n      `$/ impr.` = round(Cost/Impressions,3),\n      `$/ click` = round(Cost/ `Link clicks`,1),\n      `$/ result` = round(Cost/Results,1),\n      `Results/ 1k impr.` = round(Results*1000/Impressions,1)\n)\n     }\n\n(\n  campaign_date_outcomes <-  gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(campaign_name, starts) %>%\n    rename('Campaign' = campaign_name) %>%\n    filter(impressions>200) %>%\n    base_results_sum %>%\n    arrange(starts) %>%\n    .kable(caption = \"Results by Campaign and start date\") %>%\n    .kable_styling() %>%\n    add_footnote(\"'False start' campaign dates with less than 200 impressions are excluded\")\n)\n\n\n\nResults by Campaign and start date\n \n  \n    Campaign \n    starts \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    Cause-led \n    2021-11-30 \n    4,502 \n    133,035 \n    1,119 \n    410 \n    0.034 \n    4.0 \n    11.0 \n    3.1 \n  \n  \n    Factual \n    2021-11-30 \n    494 \n    12,917 \n    95 \n    20 \n    0.038 \n    5.2 \n    24.7 \n    1.5 \n  \n  \n    Factual V2 \n    2021-12-08 \n    3,414 \n    105,062 \n    1,368 \n    420 \n    0.032 \n    2.5 \n    8.1 \n    4.0 \n  \n  \n    Cause-led V3 \n    2021-12-23 \n    1,438 \n    118,942 \n    416 \n    167 \n    0.012 \n    3.5 \n    8.6 \n    1.4 \n  \n  \n    Factual V3 \n    2021-12-23 \n    1,424 \n    129,666 \n    498 \n    176 \n    0.011 \n    2.9 \n    8.1 \n    1.4 \n  \n  \n    Hypercube Brand Video \n    2022-01-07 \n    1,030 \n    60,845 \n    207 \n    65 \n    0.017 \n    5.0 \n    15.8 \n    1.1 \n  \n  \n    PPCo Creatives \n    2022-01-07 \n    1,397 \n    113,374 \n    428 \n    137 \n    0.012 \n    3.3 \n    10.2 \n    1.2 \n  \n\n\n\na 'False start' campaign dates with less than 200 impressions are excluded\n\n\n\n\n\n\n\nNext, the results by age and gender. As our age filters changed over time, we do this first for the earlier trials, when all age groups were included:\n\n\nCode\n(\n  age_outcomes_pre_12_09 <- gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(age) %>%\n        filter(impressions>500, starts<= \"2021-12-08\") %>%\n    base_results_sum() %>%\n    .kable(caption = \"Results by Age: Campaigns starting on or before Dec 8 2021\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Age: Campaigns starting on or before Dec 8 2021\n \n  \n    age \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    18-24 \n    283 \n    16,767 \n    50 \n    21 \n    0.017 \n    5.7 \n    13.5 \n    1.3 \n  \n  \n    25-34 \n    604 \n    31,184 \n    164 \n    76 \n    0.019 \n    3.7 \n    7.9 \n    2.4 \n  \n  \n    35-44 \n    635 \n    26,965 \n    158 \n    64 \n    0.024 \n    4.0 \n    9.9 \n    2.4 \n  \n  \n    45-54 \n    984 \n    30,399 \n    253 \n    101 \n    0.032 \n    3.9 \n    9.7 \n    3.3 \n  \n  \n    55-64 \n    1,677 \n    43,354 \n    498 \n    153 \n    0.039 \n    3.4 \n    11.0 \n    3.5 \n  \n  \n    65+ \n    2,812 \n    51,897 \n    1,122 \n    321 \n    0.054 \n    2.5 \n    8.8 \n    6.2 \n  \n\n\n\n\n\nWhile 9 older age groups yield more results per impression, they are also more expensive. This approximately balances out, although the age 18-24 group are particular costly per result!\nIn later trials we only targeted the younger age groups; the cost per results were similar to earlier trials , and fairly clsoe among the younger age groups (see fold).\n\n\n\n\n\n\nBy age, later trials\n\n\n\n\n\n\n\nCode\n(\n  age_outcomes_post_12_09 <- gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(age) %>%\n        filter(impressions>500, starts > \"2021-12-08\") %>%\n    base_results_sum() %>%\n    .kable(caption = \"Results by Age: Campaigns starting on or after Dec 23 2021\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Age: Campaigns starting on or after Dec 23 2021\n \n  \n    age \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    18-24 \n    864 \n    81,818 \n    238 \n    93 \n    0.011 \n    3.6 \n    9.3 \n    1.1 \n  \n  \n    25-34 \n    2,542 \n    203,584 \n    764 \n    274 \n    0.012 \n    3.3 \n    9.3 \n    1.3 \n  \n  \n    35-44 \n    1,059 \n    77,381 \n    333 \n    112 \n    0.014 \n    3.2 \n    9.5 \n    1.4 \n  \n\n\n\n\n\n\n\n\nResults were similar by gender. Women converted at a somewhat higher rate overall, but their impressions were a bit more costly, thus cost per result roughly balanced out. Nonetheless, this might be somewhat informative for other contexts; women might be a particular promising audience, all else equal.\n\n\nCode\n(\n  gender_outcomes <- gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(gender) %>%\n    base_results_sum() %>%\n    .kable(caption = \"Results by Gender\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Gender\n \n  \n    gender \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    female \n    12,699 \n    573,727 \n    3,754 \n    1,259 \n    0.022 \n    3.4 \n    10.1 \n    2.2 \n  \n  \n    male \n    2,930 \n    178,313 \n    834 \n    288 \n    0.016 \n    3.5 \n    10.2 \n    1.6 \n  \n  \n    unknown \n    241 \n    18,073 \n    116 \n    34 \n    0.013 \n    2.1 \n    7.1 \n    1.9 \n  \n\n\n\n\n\nNext we describe the outcomes by our ‘video’ treatments, focusing on the ‘Philanthropy-interested’ audience only, for comparability:\n\n\nCode\n(\n  video_outcomes_phil <- gg_video_breakdowns %>%\n    filter(audience==\"Philanthropy\") %>%\n    group_by(video_theme) %>% \n    base_results_sum() %>%\n    arrange(video_theme) %>% \n    .kable(caption = \"Results by Video theme for 'Philanthropy' audience\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Video theme for 'Philanthropy' audience\n \n  \n    video_theme \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    Animal \n    2,288 \n    79,531 \n    516 \n    169 \n    0.029 \n    4.4 \n    13.5 \n    2.1 \n  \n  \n    Climate \n    267 \n    13,829 \n    97 \n    38 \n    0.019 \n    2.8 \n    7.0 \n    2.7 \n  \n  \n    Poverty \n    1,056 \n    72,115 \n    298 \n    109 \n    0.015 \n    3.5 \n    9.7 \n    1.5 \n  \n  \n    Factual short \n    1,265 \n    59,677 \n    423 \n    136 \n    0.021 \n    3.0 \n    9.3 \n    2.3 \n  \n  \n    Factual long \n    306 \n    6,923 \n    45 \n    11 \n    0.044 \n    6.8 \n    27.8 \n    1.6 \n  \n  \n    Hypercube (factual) \n    278 \n    16,777 \n    65 \n    23 \n    0.017 \n    4.3 \n    12.1 \n    1.4 \n  \n\n\n\n\n\nCode\n(\n  outcomes_by_text <- gg_campaign_by_ad_by_text_age_gender %>%\n    filter(str_det(campaign_name, \"factual|hyper\")) %>%\n    group_by(text_treat) %>% \n    base_results_sum() %>%\n    .kable(caption = \"Results by text; later campaigns\") %>%\n    .kable_styling()\n)\n\n\n\nResults by text; later campaigns\n \n  \n    text_treat \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    100x impact \n    2,149 \n    102,849 \n    695 \n    225 \n    0.021 \n    3.1 \n    9.6 \n    2.2 \n  \n  \n    6000+ people \n    1,089 \n    56,979 \n    276 \n    74 \n    0.019 \n    3.9 \n    14.7 \n    1.3 \n  \n  \n    Bigger difference \n    1,561 \n    77,172 \n    450 \n    155 \n    0.020 \n    3.5 \n    10.1 \n    2.0 \n  \n  \n    Learn \n    1,240 \n    56,489 \n    325 \n    91 \n    0.022 \n    3.8 \n    13.6 \n    1.6 \n  \n  \n    Only 3% research \n    1,734 \n    73,328 \n    745 \n    246 \n    0.024 \n    2.3 \n    7.0 \n    3.4 \n  \n\n\n\n\n\nAbove, we compare the text treatments for the later campaigns only. The earlier and later campaigns had a slightly different set of texts; combining across these risks confounding. By ad text and by video:\nWe next consider results by audience, focusing on non-cause treatments for comparability. The overall (across all treatments, not fully comparable) by audience is given in the right margin.\n\n\n\nCode\n(\n  audience_outcomes <- gg_video_breakdowns %>%\n    group_by(audience) %>%\n    filter(str_det(video_theme, \"Factual|factual\")) %>%\n    base_results_sum() %>%\n    DT::datatable(caption = \"Results by audience for non-cause videos\") \n)\n\n\n\n\n\n\n\nAbove, we look at the performance of different audiences. As cause-specific audiences tend to be presented particular cause videos, we focus only on non-cause-related videos here for greater comparability across audiences.\nFormat note: The final table above is presented with the Datatables package/function. This allows sorting, filtering, etc. We can present more tables in this format if it is preferable."
  },
  {
    "objectID": "chapters/gwwc_gg.html#implementation-treatment-assignment-key-details",
    "href": "chapters/gwwc_gg.html#implementation-treatment-assignment-key-details",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.2 Implementation & treatment assignment: key details",
    "text": "1.2 Implementation & treatment assignment: key details\n\n\n\n\n\n\nTreatment assignment order, dates\n\n\n\n\n\nThe treatment assignment was determined by Facebook’s algorithm. Video content was manipulated across three split tests.\nTest 1 (Nov 30, 2021 – Dec 8, 2021, campaigns: “Cause-Led” and “Factual”) displayed either the long factual video or a cause focus video. In the cause focus condition, cause-specific audiences for animal rights, climate change, and poverty (based on their behavior on Facebook) were shown the relevant cause video.\nTest 2 (Starting December 8, campaign “Factual V2”?) was the same as Test 1 but used the short factual video instead of the cause-focus videos.\nTest 3 (Starting December 23, campaign “Cause-led V3” and “Factual V3” (?)): was the same as Test 2 but had a new version of the videos (with Luke just holding up signs with the words). This test was also restricted to 18-35 (or 18-44) year olds.1\nTest 4: (Starting December 23, “Hypercube” and “PPCo”) The Hypercube video was displayed in a separate “Hypercube” campaign which was tested against another campaign that allowed the algorithm to optimize between the ‘short factual’ and ‘cause focus’ videos (although not allowing each cause-specific audience to see the ads for other cause areas).\nIn all tests, the text content displayed above the video was determined by Facebook’s algorithm. Balance across variations was determined to equate budgets across split tests; otherwise, according to Facebook’s algorithm. All variation was done at the level of the impression.\nThe videos were adapted across the trials as we learned. First, we updated the factual video to be shorter for Trial 2, and then we tried videos of Luke holding up signs spelling out the voiceover in Trial 3 for all videos."
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html",
    "href": "chapters/testformat_gwwc_gg.html",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "",
    "text": "Note\n\n\n\nThis chapter should align with a (forthcoming) EA Forum post, which will be linked here (and vice-versa)."
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#the-trial",
    "href": "chapters/testformat_gwwc_gg.html#the-trial",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.1 The trial",
    "text": "2.1 The trial\nSee full description in the gitbook here.\nContext: Facebook advertisements on a range of audiences\n\nEffective Giving Guide Lead Generation campaign … ran late November 2021 - January 2022. The objective of this campaign was to see whether a factual [‘who researches giving’ or ‘magnitude of impact differences’] or cause-led approach was more cost-effective at getting people to fill out a form and give us their email in order to download our Effective Giving Guide.\n\n\n2.1.1 Treatments (text \\(\\times\\) video)\nThere were two dimensions of treatment content:\n\nThe texts displayed above the videos\n\n\n\n\n\n\n\nTexts\n\n\n\n\n\nBigger difference next year: Want to make a bigger difference next year? Start with our Effective Giving Guide and learn how to make a remarkable impact just by carefully choosing the charities you give to.\n100x impact: Did you know that the best charities can have a 100x greater impact? Download our free Effective Giving Guide for the best tips on doing the most good this holiday season.\n6000 people: Giving What We Can has helped 6,000+ people make a bigger impact on the causes they care about most. Download our free guide and learn how you can do the same.\nCause list: Whether we’re moved by animal welfare, the climate crisis, or worldwide humanitarian efforts, our community is united by one thing: making the biggest impact we can. Make a bigger difference in the world through charitable giving. Start by downloading our Effective Giving Guide. You’ll learn how to approach charity research and smart giving. And be sure to share it with others who care about making a greater impact on the causes closest to their hearts.\nLearn: Use our free guide to learn how to make a bigger impact on the causes you care about most.\nOnly 3% research: Only 3% of donors give based on charity effectiveness yet the best charities can be 100x more impactful. That’s incredible! Check out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes.\nOverwhelming: It can be overwhelming with so many problems in the world. Fortunately, we can do a lot to help, if we give effectively. Check out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes.\n\n\n\n\n\n\n\n\n\nArguments, rich content from “Hypercube”\n\n\n\n\n\n\nHypercube (1 min 22 seconds): Animated and voiceover video that explains how GWWC can help maximize charitable impact (support, community, and information) and the problems GWWC addresses (good intentions don’t always produce the desired outcomes, there are millions of charities that have varying degrees of impact and some can even cause harm). CTA: Check out givingwhatwecan.org to learn how you can become an effective giver.\n\n\n\n\n\n\nFurther detail, links\n\n\n\n\n\n\nNotes from the trial description\n\n\n\n\n\n“In the original version of our test, we had 1 video for the factual appeal and 3 videos for the cause led approach - 1 for global health and development, 1 for animal welfare and 1 for climate change.”\n“We targeted our ads to audiences we thought were likely to engage based on their interests and demographics, and targeted the cause led videos to a relevant audience, i.e. climate change message to climate change audience.”\n“We also had various text above the videos that were displayed and optimized.”\n\n\n\nDetails in Gitbook HERE (and embedded below) and Gdoc here\n\n\nCode\nknitr::include_url(\"https://effective-giving-marketing.gitbook.io/untitled/partner-organizations-and-trials/gwwc/giving-guides-+\")"
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#implementation-treatment-assignment-key-details",
    "href": "chapters/testformat_gwwc_gg.html#implementation-treatment-assignment-key-details",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.2 Implementation & treatment assignment: key details",
    "text": "2.2 Implementation & treatment assignment: key details\n\n\n\n\n\n\nTreatment assignment order, dates\n\n\n\n\n\nThe treatment assignment was determined by Facebook’s algorithm. Video content was manipulated across three split tests.\nTest 1 (Nov 30, 2021 – Dec 8, 2021, campaigns: “Cause-Led” and “Factual”) displayed either the long factual video or a cause focus video. In the cause focus condition, cause-specific audiences for animal rights, climate change, and poverty (based on their behavior on Facebook) were shown the relevant cause video.\nTest 2 (add dates) was the same as Test 1 but used the short factual video instead of the cause-focus videos.\nTest 3 (add dates) was the same as Test 2 but had a new version of the videos (with Luke just holding up signs with the words). This test was also restricted to 18-35 year olds.\nTest 4: The Hypercube video was displayed in a separate “Hypercube” campaign which was tested against another campaign that allowed the algorithm to optimize between the ‘short factual’ and ‘cause focus’ videos (although not allowing each cause-specific audience to see the ads for other cause areas).\nIn all tests, the text content displayed above the video was determined by Facebook’s algorithm. Balance across variations was determined to equate budgets across split tests; otherwise, according to Facebook’s algorithm. All variation was done at the level of the impression.\nThe videos were adapted across the trials as we learned. First, we updated the factual video to be shorter for Trial 2, and then we tried videos of Luke holding up signs spelling out the voiceover in Trial 3 for all videos."
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#build-source-data-input-and-cleaning-code",
    "href": "chapters/testformat_gwwc_gg.html#build-source-data-input-and-cleaning-code",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.3 Build: Source data input and cleaning code",
    "text": "2.3 Build: Source data input and cleaning code\n\n\n\n\n\n\nAccessing, downloading, inputting data\n\n\n\n\n\nSee:\nAccessing and bringing down simple results HERE; (Public access version here)\n\n\n\n\n\n\n\n\n\n\nData structure\n\n\n\n\n\n\ntext: Which text was shown along with the video\nage (a range of ages)\ngender (female, male, unknown)\n\n\n\n\n\n\nCode\nraw_data_path <- list(\"gwwc\", \"gg_raw_data_shareable\")\n\n#already input above: gg_campaign_by_ad_by_text\n\n#Version allowing demographic breakdown:\ngg_campaign_by_ad_by_text_age_gender <- read_csv(here(raw_data_path, \"gg-campaign-by-ad-set-text-age-gender.csv\"), show_col_types=FALSE) %>%\n  #dplyr::select(-\"Campaign name...4\") %>% #duplicate columns?\n mini_clean()\n\n#Version with information on cause videos shown (even to those in 'general' groups):\n\ngg_video_breakdowns <- read_csv(here(raw_data_path, \"gg-image-video-breakdowns.csv\"), show_col_types=FALSE)\n\n#capture and remove columns that are the same everywhere\nattribution_setting_c <- gg_campaign_by_ad_by_text_age_gender$attribution_setting %>% .[1]\nreporting_starts_c <- gg_campaign_by_ad_by_text_age_gender$reporting_starts %>% .[1]\nreporting_ends_c <- gg_campaign_by_ad_by_text_age_gender$reporting_ends %>% .[1]\n\n\ngg_campaign_by_ad_by_text_age_gender  %<>% mini_clean()\ngg_video_breakdowns  %<>% mini_clean()\n\n#functions to clean these specific data sets 'gg_campaign_by_ad_by_text_age_gender' and 'gg_campaign_by_ad_by_text':\nsource(here(\"gwwc\", \"giving_guides\", \"clean_gg_raw_data.R\")) \n\n#Many cleaning steps: audience, video_theme, campaign_theme, agetrin; releveling\ngg_campaign_by_ad_by_text_age_gender %<>%\n  rename_gg() %>%\ngg_make_cols() %>% \n  vid_clean() %>%  # Video rename and stuff\n  text_clean() %>%  # Shorter 'text treatment' column\n  relevel_gwwc_gg_raw() %>% \n  dplyr::select(campaign_name, everything(), -campaign_name_1, -campaign_name_7) #campaign_name_7 was the same as campaign_name_1\n\ngg_video_breakdowns %<>%\n  rename_gg() %>%\ngg_make_cols()  %>% \n    vid_clean()  # Video rename and stuff\n\n\n#gg_campaign_by_ad_by_text_age_gender %>% collapse::descr()\n\n\n\n\nCode\ngg_video_breakdowns %<>%\n  mutate(\n    video_theme = case_when(\n      str_det(image_video_and_slideshow, \"set_1|Animals\") ~ \"Animal\",\n      str_det(image_video_and_slideshow, \"set_2|Climate\") ~ \"Climate\",\n      str_det(image_video_and_slideshow, \"set_3|Poverty|Free Effective\") ~ \"Poverty\",\n      str_det(image_video_and_slideshow, \"factual\") ~ \"Factual\",\n      TRUE ~ video_theme\n    ),\n    video_theme =  factor(video_theme), \n    video_theme = fct_relevel(video_theme, c(\"Animal\", \"Climate\", \"Poverty\", \"Factual\", \"Factual or optimized mix\")) \n  )\n\n\n\n\n\n\n\n\nThis data should be publicly shareable.\n\n\n\n\n\nThis data is clearly not identifying individuals; it involves aggregates based on real or assumed characteristics … there is likely nothing that needs to be hidden here. We aim to share and integrate all the data in this repo, for a complete pipeline.\n\n\n\n\n\n\n\n\n\nPrevious version of data used … (updating)\n\n\n\n\n\nWe previously used data collapsed (breakdowns) by demography and ad set, into 2 files, which duplicated rows to represent the number of impressions: video breakdown, and text breakdown.csv. We now use the more ‘raw’ minimal version of the data, avoiding duplicating rows where possible.\nBelow, we also input the ‘old version’ of the data, with the duplicated rows, to accommodate the old-format of analysis. The code above inputs and builds 2-4 related data frames (tibbles), which were constructed from the collapsed (aggregated) data by multiplying rows according to observation counts. I am not sure where this was done. Once we update the rest we will get rid of this.\ngwwc_text_clicks: Observations of link clicks … by texts above video gwwc_vid_clicks: … by video content\n(We focus on the email results because we expect the ‘clicks’ are less meaningful.)\ngwwc_text_results: Observations of emails provided … by texts above video gwwc_vid_results: … by video content\nThe files:\ntextdata_dv_linkclicks.csv, videodata_dv_results.csv, textdata_dv_results.csv , and videodata_dv_linkclicks.csv\nare gitignored because of size."
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#descriptives",
    "href": "chapters/testformat_gwwc_gg.html#descriptives",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.4 Descriptives",
    "text": "2.4 Descriptives\n\n2.4.1 Implemented treatments, impressions\nFirst we illustrate ‘where, when, and to whom’ the different campaigns and treatments were shown (Facebook ‘impressions’).\nThe sequential campaigns involved different sets of videos, and these videos had different versions:\n\n\nCode\n(\n  impressions_campaign_theme <- gg_video_breakdowns %>%\n  dplyr::select(campaign_name, video_theme, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n   tabyl(campaign_name, video_theme) %>%\n    dplyr::select(campaign_name, Animal, Climate, Poverty, everything()) %>% \n  .kable(caption = \"Campaign names and video themes: Impressions\") %>%\n  .kable_styling()\n)\n\n\n\nCampaign names and video themes: Impressions\n \n  \n    campaign_name \n    Animal \n    Climate \n    Poverty \n    Factual \n    Factual or optimized mix \n  \n \n\n  \n    Giving Guide 2021 - Cause-led \n    106,870 \n    6,494 \n    36,306 \n    0 \n    0 \n  \n  \n    Giving Guide 2021 – Cause-led V3 \n    45,856 \n    4,478 \n    74,714 \n    0 \n    0 \n  \n  \n    Giving Guide 2021 – Factual \n    0 \n    0 \n    0 \n    32,818 \n    0 \n  \n  \n    Giving Guide 2021 – Factual V2 \n    0 \n    0 \n    0 \n    120,530 \n    0 \n  \n  \n    Giving Guide 2021 – Factual V3 \n    0 \n    0 \n    0 \n    137,679 \n    0 \n  \n  \n    Giving Guide 2021 – Hypercube Brand Video \n    0 \n    0 \n    1,571 \n    0 \n    74,219 \n  \n  \n    Giving Guide 2021 – PPCo Creatives \n    27,595 \n    27,735 \n    2,629 \n    70,619 \n    0 \n  \n\n\n\n\n\nSome audiences were profiled as associated with a certain cause (through their Facebook interests or activities): in ‘cause-focused’ campaigns they were shown videos for their profiled cause. In campaigns that were not cause-focused, they were shown general interest videos. However, those associated with one cause were never shown videos for other causes.\nAudience not åssociated with a cause included the ‘General’ audience, the Philanthropy (interested in charity) audience, a GWWC ‘Lookalike’ audience, and a Retargeted (?) audience: these were shown either the more general-interest videos or particular cause videos. Unfortunately, for these groups, when they were shown a cause-related video, we have not been able to extract the data on which cause-specific video they saw. This is illustrated in the table below.\n\nOutset content…\n\n\nCode\nvideo_levels <- c(\"Animal\", \"Climate\", \"Poverty\", \"Cause-led (any)\", \"Factual\", \"Factual or optimized mix\", \"Total\")\n  \n(\nimpressions_video_audience <- gg_video_breakdowns %>%\n    dplyr::select(video_theme, audience, impressions) %>%\n    uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n    tabyl(video_theme, audience) %>% \n    adorn_percentages(\"all\") %>%\n    adorn_totals(where = c(\"row\", \"col\")) %>% \n    adorn_pct_formatting(digits = 2) %>% \n    dplyr::select(video_theme, Animal, Climate, `Global Poverty`, `Philanthropy`, everything()) %>% \n   mutate(video_theme =  factor(video_theme, levels = video_levels)) %>%\n  arrange(video_theme)  %>% \n    .kable(caption = \"Video themes by audience: share of impressions\", digits=3) %>%\n  .kable_styling()\n)\n\n\n\nVideo themes by audience: share of impressions\n \n  \n    video_theme \n    Animal \n    Climate \n    Global Poverty \n    Philanthropy \n    General audience \n    Lookalikes \n    Retargeting \n    Total \n  \n \n\n  \n    Animal \n    10.47% \n    0.00% \n    0.00% \n    10.33% \n    1.37% \n    1.23% \n    0.02% \n    23.41% \n  \n  \n    Climate \n    0.00% \n    1.83% \n    0.00% \n    1.80% \n    0.97% \n    0.43% \n    0.01% \n    5.03% \n  \n  \n    Poverty \n    0.01% \n    0.05% \n    2.88% \n    9.36% \n    0.22% \n    2.43% \n    0.01% \n    14.96% \n  \n  \n    Factual \n    12.93% \n    13.71% \n    5.12% \n    8.65% \n    2.02% \n    4.52% \n    0.02% \n    46.96% \n  \n  \n    Factual or optimized mix \n    0.90% \n    2.57% \n    1.01% \n    2.18% \n    2.83% \n    0.15% \n    0.01% \n    9.64% \n  \n  \n    Total \n    24.31% \n    18.16% \n    9.01% \n    32.31% \n    7.40% \n    8.75% \n    0.06% \n    100.00% \n  \n\n\n\n\n\n\nThe second treatment dimension – text presented along with the video – was allowed to vary independently of the video:\n\n\nCode\n(\n  impressions_video_text <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(video_theme, text_treat, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n   table %>%\n        prop.table() %>% \n        addmargins() %>% \n  .kable(caption = \"Video themes by text treatment: Impressions\", digits=3) %>%\n  .kable_styling()\n)\n\n\n\nVideo themes by text treatment: Impressions\n \n  \n      \n    100x impact \n    6000+ people \n    Bigger difference \n    Cause list \n    Learn \n    Only 3% research \n    Overwhelming \n    Sum \n  \n \n\n  \n    Animal \n    0.000 \n    0.022 \n    0.037 \n    0.011 \n    0.012 \n    0.000 \n    0.012 \n    0.094 \n  \n  \n    Cause-led (any) \n    0.046 \n    0.087 \n    0.057 \n    0.034 \n    0.066 \n    0.033 \n    0.075 \n    0.398 \n  \n  \n    Climate \n    0.000 \n    0.000 \n    0.000 \n    0.000 \n    0.001 \n    0.000 \n    0.000 \n    0.003 \n  \n  \n    Factual \n    0.105 \n    0.060 \n    0.084 \n    0.000 \n    0.058 \n    0.071 \n    0.000 \n    0.378 \n  \n  \n    Factual or optimized mix \n    0.029 \n    0.014 \n    0.017 \n    0.000 \n    0.015 \n    0.024 \n    0.000 \n    0.098 \n  \n  \n    Poverty \n    0.000 \n    0.004 \n    0.008 \n    0.010 \n    0.003 \n    0.000 \n    0.003 \n    0.028 \n  \n  \n    Sum \n    0.180 \n    0.188 \n    0.202 \n    0.056 \n    0.157 \n    0.128 \n    0.090 \n    1.000 \n  \n\n\n\n\n\nCode\n(\n  impressions_video_text <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(campaign_name, text_treat, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n   table %>%\n        prop.table() %>% \n        addmargins() %>% \n  .kable(caption = \"Text treatments by campaign: Impressions\", digits=3) %>%\n  .kable_styling()\n)\n\n\n\nText treatments by campaign: Impressions\n \n  \n      \n    100x impact \n    6000+ people \n    Bigger difference \n    Cause list \n    Learn \n    Only 3% research \n    Overwhelming \n    Sum \n  \n \n\n  \n    Cause-led \n    0.000 \n    0.050 \n    0.056 \n    0.029 \n    0.025 \n    0.000 \n    0.035 \n    0.194 \n  \n  \n    Cause-led V3 \n    0.000 \n    0.040 \n    0.017 \n    0.027 \n    0.024 \n    0.000 \n    0.055 \n    0.162 \n  \n  \n    Factual \n    0.006 \n    0.008 \n    0.009 \n    0.000 \n    0.013 \n    0.007 \n    0.000 \n    0.043 \n  \n  \n    Factual V2 \n    0.046 \n    0.015 \n    0.034 \n    0.000 \n    0.018 \n    0.044 \n    0.000 \n    0.157 \n  \n  \n    Factual V3 \n    0.053 \n    0.037 \n    0.041 \n    0.000 \n    0.028 \n    0.020 \n    0.000 \n    0.179 \n  \n  \n    Hypercube Brand Video \n    0.029 \n    0.014 \n    0.017 \n    0.000 \n    0.015 \n    0.024 \n    0.000 \n    0.098 \n  \n  \n    PPCo Creatives \n    0.046 \n    0.024 \n    0.029 \n    0.000 \n    0.034 \n    0.033 \n    0.000 \n    0.167 \n  \n  \n    Sum \n    0.180 \n    0.188 \n    0.202 \n    0.056 \n    0.157 \n    0.128 \n    0.090 \n    1.000 \n  \n\n\n\n\n\n(Note, above that we cannot identify all of the video treatments in the same dataset with text treatments; this is a limitation of the Facebook interface)\nHowever, note that treatment shares are not equal. In fact, as the second table above shows, they are not even equal within each campaign. This is because Facebook optimizes to show videos and text more, the more successful they are.1\n\n\n2.4.2 Demographics\n\n\nCode\n(\n  impressions_age_gender <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(age, gender, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n   table %>%\n    prop.table() %>% \n    addmargins() %>% \n  .kable(caption = \"Impressions by Age and Gender\", digits=2) %>%\n  .kable_styling()\n)\n\n\n\nImpressions by Age and Gender\n \n  \n      \n    female \n    male \n    unknown \n    Sum \n  \n \n\n  \n    25-34 \n    0.27 \n    0.09 \n    0.01 \n    0.37 \n  \n  \n    13-17 \n    0.00 \n    0.00 \n    0.00 \n    0.00 \n  \n  \n    18-24 \n    0.13 \n    0.06 \n    0.01 \n    0.19 \n  \n  \n    35-44 \n    0.16 \n    0.04 \n    0.00 \n    0.21 \n  \n  \n    45-54 \n    0.05 \n    0.01 \n    0.00 \n    0.06 \n  \n  \n    55-64 \n    0.06 \n    0.01 \n    0.00 \n    0.08 \n  \n  \n    65+ \n    0.07 \n    0.02 \n    0.00 \n    0.09 \n  \n  \n    Unknown \n    0.00 \n    0.00 \n    0.00 \n    0.00 \n  \n  \n    Sum \n    0.74 \n    0.23 \n    0.02 \n    1.00 \n  \n\n\n\n\n\nAs can be clearly seen above, within all age groups, the ad was disproportionally shown to women. Relative to the overall Facebook population our data skews very slightly younger.2\nTEST MARGIN CONTENT\n\n\nCode\nknitr::kable(\n  mtcars[1:6, 1:3]\n)\n\n\n\n\n \n  \n      \n    mpg \n    cyl \n    disp \n  \n \n\n  \n    Mazda RX4 \n    21.0 \n    6 \n    160 \n  \n  \n    Mazda RX4 Wag \n    21.0 \n    6 \n    160 \n  \n  \n    Datsun 710 \n    22.8 \n    4 \n    108 \n  \n  \n    Hornet 4 Drive \n    21.4 \n    6 \n    258 \n  \n  \n    Hornet Sportabout \n    18.7 \n    8 \n    360 \n  \n  \n    Valiant \n    18.1 \n    6 \n    225 \n  \n\n\n\n\n\n\n2.4.3 Outcomes\n\n\nCode\nbase_results_sum <- function(df) {\n    df %>%\n     dplyr::summarize(\n  Cost = sum(round(amount_spent_usd,0)),\n      Impressions=sum(impressions),\n      `Link clicks`=sum(link_clicks, na.rm = TRUE),\n      Results=sum(results, na.rm = TRUE),\n      `$/impr.` = round(Cost/Impressions,3),\n      `$/click` = round(Cost/ `Link clicks`,1),\n      `$/result` = round(Cost/Results,1),\n      `Results/1k impr.` = round(Results*1000/Impressions,1)\n)\n     }\n\n(\n  campaign_date_outcomes <-  gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(campaign_name, starts) %>%\n    rename('Campaign' = campaign_name) %>%\n    filter(impressions>200) %>%\n    base_results_sum %>%\n    arrange(starts) %>%\n    .kable(caption = \"Results by Campaign and start date\") %>%\n    .kable_styling() %>%\n    add_footnote(\"'False start' campaign dates with less than 200 impressions are excluded\")\n)\n\n\n\nResults by Campaign and start date\n \n  \n    Campaign \n    starts \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/impr. \n    $/click \n    $/result \n    Results/1k impr. \n  \n \n\n  \n    Cause-led \n    2021-11-30 \n    4,502 \n    133,035 \n    1,119 \n    410 \n    0.034 \n    4.0 \n    11.0 \n    3.1 \n  \n  \n    Factual \n    2021-11-30 \n    494 \n    12,917 \n    95 \n    20 \n    0.038 \n    5.2 \n    24.7 \n    1.5 \n  \n  \n    Factual V2 \n    2021-12-08 \n    3,414 \n    105,062 \n    1,368 \n    420 \n    0.032 \n    2.5 \n    8.1 \n    4.0 \n  \n  \n    Cause-led V3 \n    2021-12-23 \n    1,438 \n    118,942 \n    416 \n    167 \n    0.012 \n    3.5 \n    8.6 \n    1.4 \n  \n  \n    Factual V3 \n    2021-12-23 \n    1,424 \n    129,666 \n    498 \n    176 \n    0.011 \n    2.9 \n    8.1 \n    1.4 \n  \n  \n    Hypercube Brand Video \n    2022-01-07 \n    1,030 \n    60,845 \n    207 \n    65 \n    0.017 \n    5.0 \n    15.8 \n    1.1 \n  \n  \n    PPCo Creatives \n    2022-01-07 \n    1,397 \n    113,374 \n    428 \n    137 \n    0.012 \n    3.3 \n    10.2 \n    1.2 \n  \n\n\n\na 'False start' campaign dates with less than 200 impressions are excluded\n\n\n\n\n\n\n\n\nCode\n(\n  age_outcomes <- gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(age) %>%\n        filter(impressions>500) %>%\n    base_results_sum() %>%\n    .kable(caption = \"Results by Age\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Age\n \n  \n    age \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/impr. \n    $/click \n    $/result \n    Results/1k impr. \n  \n \n\n  \n    25-34 \n    3,146 \n    234,768 \n    928 \n    350 \n    0.013 \n    3.4 \n    9.0 \n    1.5 \n  \n  \n    18-24 \n    1,147 \n    98,585 \n    288 \n    114 \n    0.012 \n    4.0 \n    10.1 \n    1.2 \n  \n  \n    35-44 \n    1,694 \n    104,346 \n    491 \n    176 \n    0.016 \n    3.5 \n    9.6 \n    1.7 \n  \n  \n    45-54 \n    984 \n    30,399 \n    253 \n    101 \n    0.032 \n    3.9 \n    9.7 \n    3.3 \n  \n  \n    55-64 \n    1,677 \n    43,354 \n    498 \n    153 \n    0.039 \n    3.4 \n    11.0 \n    3.5 \n  \n  \n    65+ \n    2,812 \n    51,897 \n    1,122 \n    321 \n    0.054 \n    2.5 \n    8.8 \n    6.2 \n  \n\n\n\n\n\nCode\n(\n  gender_outcomes <- gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(gender) %>%\n    base_results_sum() %>%\n    .kable(caption = \"Results by Gender\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Gender\n \n  \n    gender \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/impr. \n    $/click \n    $/result \n    Results/1k impr. \n  \n \n\n  \n    female \n    12,699 \n    573,727 \n    3,754 \n    1,259 \n    0.022 \n    3.4 \n    10.1 \n    2.2 \n  \n  \n    male \n    2,930 \n    178,313 \n    834 \n    288 \n    0.016 \n    3.5 \n    10.2 \n    1.6 \n  \n  \n    unknown \n    241 \n    18,073 \n    116 \n    34 \n    0.013 \n    2.1 \n    7.1 \n    1.9 \n  \n\n\n\n\n\nCost per click by audience (non-cause treatments):\n\n\nCode\n(\n  video_outcomes_phil <- gg_video_breakdowns %>%\n    filter(audience==\"Philanthropy\") %>%\n    group_by(video_theme) %>% \n    base_results_sum() %>%\n    arrange(video_theme) %>% \n    .kable(caption = \"Results by Video theme for 'Philanthropy' audience\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Video theme for 'Philanthropy' audience\n \n  \n    video_theme \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/impr. \n    $/click \n    $/result \n    Results/1k impr. \n  \n \n\n  \n    Animal \n    2,288 \n    79,531 \n    516 \n    169 \n    0.029 \n    4.4 \n    13.5 \n    2.1 \n  \n  \n    Climate \n    267 \n    13,829 \n    97 \n    38 \n    0.019 \n    2.8 \n    7.0 \n    2.7 \n  \n  \n    Poverty \n    1,056 \n    72,115 \n    298 \n    109 \n    0.015 \n    3.5 \n    9.7 \n    1.5 \n  \n  \n    Factual \n    1,571 \n    66,600 \n    468 \n    147 \n    0.024 \n    3.4 \n    10.7 \n    2.2 \n  \n  \n    Factual or optimized mix \n    278 \n    16,777 \n    65 \n    23 \n    0.017 \n    4.3 \n    12.1 \n    1.4 \n  \n\n\n\n\n\nAbove, we compare the text treatments for the later campaigns only. The earlier and later campaigns had a slightly different set of texts; combining across these risks confounding. By ad text and by video:\n\n\nCode\n(\n  audience_outcomes <- gg_video_breakdowns %>%\n    group_by(audience) %>%\n    filter(video_theme== \"Animated\" | video_theme== \"Factual\" ) %>%\n    base_results_sum() %>%\n    DT::datatable(caption = \"Results by audience for non-cause videos\") \n)\n\n\n\n\n\n\nAbove, we look at the performance of different audiences. As cause-specific audiences tend to be presented particular cause videos, we focus only on non-cause-related videos here for greater comparability.\nFormat note: The table above is presented with the Datatables package/function. This allows sorting, filtering, etc. We can present more tables in this format if it is preferrable."
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#asking-and-answering-questions",
    "href": "chapters/testformat_gwwc_gg.html#asking-and-answering-questions",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.5 Asking and answering questions",
    "text": "2.5 Asking and answering questions\n\n\n\n\n\n\nThis dynamic document format allows us to ask and answer a series of questions\n\n\n\n\n\n\nUsing the data, with all coding steps shown\nIdeally, following a pre-defined (pre-analysis) plan\nUsing the data and statistics directly and automatically in the narrative\n\nAnd everything will be automatically adjusted if we bring in new data or adjust/correct features\n\n\n\n\n\n\nIn this context, how much does it cost to get a ’Result”, i.e., to get a person to give their email to receive a Giving Guide?\n\n\n\n\n\n\nCost per result (CpR) as the result of several processes…\n\n\n\n\n\nHow should we consider this outcome? At the base level the Cost per Result (‘CpR’) for a ‘segment’ (a particular ad version, audience, campaign, etc), comes from several interrelated processes:\n\nHow much FB charges us for this segment\nWho FB serves this segment to (what types of people, how many)\nHow many people in that segment click and then ‘convert’, yielding a result\n\nWe could try to model each of these processes, but it could be very involved, and we don’t fully observe or understand the second step, FB’s optimization algorithm.\n\n\n\n\n\n\n\n\n\nCpR as a black box…\n\n\n\n\n\nAlternatively, we could think of the CpR for a segment as just a ‘base outcome to model’, and treat it as a sort of black box. This would suggests we have ‘only one CpR coutcome per segment’, and each segment has different characteristics (‘features’ or ‘variables’), some in common. But that discards some important information: the mean values for segments with more observations (here, ‘impressions’) can be expected to have less variance (lower standard error), all else equal.\n\n\n\n\n\n\n\n\n\nCpR as the average of a lot of black boxes…\n\n\n\n\n\nWe can do something intermediate – taking the aggregation into account, without fully building a structural model of the factors above. Within each segment, we can consider the ‘average cost per result’ outcome for each individual as the expected value of a random draw. Each individual has some ‘cost per impression’, and some ‘probability of a result’. The ratio of these is the individual’s ‘expected cost per result … which we can also abstract as just some random draw. This may be considered as a function of ’all the characteristics of the segment the individual is in’. The CpR for the segment is thus an average of the CpR for all the individuals in the segment, and we can use ‘regression weights’ (technically ‘inverse variance weights’; see discussion in Huntington-Klein’s book here) in our model to reflect this.\n\n\n\n\n\n\n\n\n\n\nModeling goals/discussion/todo\n\n\n\n\n\n\nPresent mean/Bayesian updating:\n\n\nOverall cost/result\n\nand for different audiences\nrandom effects?\n\npresent posterior distribution and intervals\n\n\nModel (multivariable regression):\n\nCost/result as a function of\n\ncampaign (i.e., time of launch)\nmessage\nvideo\naudience\ngender\nage\n\nLinear and log-linear\nRandom effects (how?)\nPresent a set of estimates for the mean and 80% CI for cost/result for key groups\n\n\n\n\n\nCode\nsummarise_stuff <- function(df) {\n  df %>%\n     summarise(\n      amount_spent_usd = sum(amount_spent_usd), \n      impressions=sum(impressions),\n      link_clicks = sum(link_clicks, na.rm = TRUE),\n      results = sum(results, na.rm = TRUE),\n      cost_per_impression = amount_spent_usd/impressions,\n      cost_per_click = amount_spent_usd/link_clicks,\n      results = ifelse(is.na(results), 0, results ),\n      results_per_100usd = results/(amount_spent_usd/100),\n      results_per_1k_impressions = results*1000/impressions) \n}\n\nmodel_data_0 <- gg_campaign_by_ad_by_text_age_gender %>%\n  filter(audience!=\"Retargeting\") %>%\n  ungroup() %>%\n    group_by(video_theme, text_treat, audience) %>% #starts, \n    #filter(impressions>200) %>%\n    summarise_stuff() %>%\n  ungroup() %>% \n  as.tibble() %>% \n  mutate(\n    across(c(video_theme, text_treat, audience), #starts, \n      as.factor )\n    )\n\nmodel_data_start <- gg_campaign_by_ad_by_text_age_gender %>%\n  filter(audience!=\"Retargeting\") %>%\n  ungroup() %>%\n    group_by(video_theme, text_treat, audience, starts) %>% #starts, \n    #filter(impressions>200) %>%\n        summarise_stuff() %>%\n  ungroup() %>% \n  as.tibble() %>% \n  mutate(\n    across(c(video_theme, text_treat, audience, starts), #starts, \n      as.factor )\n    )\n\nmodel_data <- gg_campaign_by_ad_by_text_age_gender %>%\n    filter(audience!=\"Retargeting\") %>%\n  ungroup() %>%\n    group_by(video_theme, text_treat, audience, gender, agetrin) %>% #starts, \n    #filter(impressions>200) %>%\n        summarise_stuff() %>%\n  ungroup() %>% \n  as.tibble() %>% \n  mutate(\n    across(c(video_theme, text_treat, audience, gender, agetrin), #starts, \n      as.factor )\n    )\n\nRp100usd_vid_text_audience0 <- model_data_0 %>%  \n  lm(\n    results_per_100usd ~ 1 + video_theme + text_treat + audience,\n    data = ., \n    weights = impressions) \n  \n\nRp100usd_vid_text_audience_starts <- model_data_start %>%  \n  lm(\n    results_per_100usd ~ 1 + starts + video_theme + text_treat + audience,\n    data = ., \n    weights = impressions) \n  \n\nRp100usd_vid_text_audience_demo <- model_data %>%  \n  lm(\n    results_per_100usd ~ 1 + video_theme + text_treat + audience + gender + agetrin,\n    data = ., \n    weights = impressions) \n\n#Do NOT do this: Rp100usd_vid_text_audience0$df.residual <- sum(model_data_0$impressions) - length(coef(Rp100usd_vid_text_audience0))\n\nhuxtable::huxreg(Rp100usd_vid_text_audience0, Rp100usd_vid_text_audience_starts, Rp100usd_vid_text_audience_demo)\n\n\n\n\n(1)(2)(3)\n\n(Intercept)12.999 ***10.438 ***12.217 ***\n\n(1.748)   (1.949)   (1.720)   \n\nvideo_themeCause-led (any)-2.266    -1.302    -2.528    \n\n(1.366)   (1.659)   (1.345)   \n\nvideo_themeClimate-1.582    1.839    -0.790    \n\n(5.148)   (5.627)   (4.989)   \n\nvideo_themeFactual-1.500    -3.165 *  -1.285    \n\n(1.268)   (1.485)   (1.232)   \n\nvideo_themeFactual or optimized mix-6.514 ***-5.123 *  -7.076 ***\n\n(1.598)   (2.068)   (1.580)   \n\nvideo_themePoverty0.496    1.269    0.916    \n\n(2.350)   (2.600)   (2.288)   \n\ntext_treat6000+ people-3.546 ***-3.060 ** -2.934 ** \n\n(0.991)   (1.122)   (0.960)   \n\ntext_treatBigger difference-1.250    0.007    -0.754    \n\n(0.960)   (1.070)   (0.931)   \n\ntext_treatCause list-1.190    -1.769    -1.505    \n\n(1.509)   (1.745)   (1.462)   \n\ntext_treatLearn-2.340 *  -1.553    -2.068 *  \n\n(1.002)   (1.109)   (0.971)   \n\ntext_treatOnly 3% research2.144 *  2.692 *  2.581 *  \n\n(1.040)   (1.138)   (1.008)   \n\ntext_treatOverwhelming-1.632    -1.794    -0.600    \n\n(1.297)   (1.561)   (1.256)   \n\naudienceAnimal-0.365    0.336    -0.563    \n\n(1.021)   (1.170)   (1.000)   \n\naudienceClimate-0.377    0.126    -0.940    \n\n(0.902)   (1.071)   (0.882)   \n\naudienceGeneral audience0.690    1.319    0.624    \n\n(1.215)   (1.452)   (1.186)   \n\naudienceGlobal Poverty-0.621    -0.497    -1.366    \n\n(1.303)   (1.472)   (1.265)   \n\naudienceLookalikes2.579 *  1.197    2.080 *  \n\n(1.085)   (1.191)   (1.052)   \n\nstarts2021-12-08        4.718 ***        \n\n        (1.259)           \n\nstarts2021-12-23        4.790 ***        \n\n        (0.888)           \n\nstarts2022-01-07        0.262            \n\n        (1.384)           \n\ngendermale                0.209    \n\n                (0.645)   \n\ngenderunknown                -0.312    \n\n                (1.779)   \n\nagetrin0                1.048    \n\n                (0.842)   \n\nagetrin1                1.351    \n\n                (0.707)   \n\nN104        185        772        \n\nR20.445    0.355    0.092    \n\nlogLik-282.883    -576.659    -3209.739    \n\nAIC601.767    1195.318    6463.478    \n\n *** p < 0.001;  ** p < 0.01;  * p < 0.05.\n\n\n\n\nNote: the N (and R-sq?) values above are incorrect; these are the number of groups not the number of baseline observations.\n3\n\n\nWhich pre-defined audience yields a Result at the lowest cost? How does this cost vary by audience?\n\nRefer to models/estimates above\n\n\n\nWhich pre-defined audience yields the highest ‘rate of Result’? How does this vary by audience?\nNote, this is not the same as the previous question because some audiences are more costly to target on Facebook.\n\nRe-run above models for ‘results per impression’\n\nImportant caveat: this does not tell us the effect ‘on a particular group’, because of FB’s optimization algorithms.\nInteractions/separate models for ‘vary by audience’.\n\n\nWhich video yields a Result at the highest rate/lowest cost?\n\nRefer to models/estimates above, coefficient on ‘video’\n\n4\n\nHow does the ‘best video’ vary by audience?\n\nInclude interactions in above model\nRun model separately for each group (or allowing everything to interact) for robustness\nAlso consider ‘what did FB serve to each group’, assuming it is optimizing.\n\n\n\nAggregating: Which category of videos yields a result at the highest rate/lowest cost? (“Facts”, “Cause focus”, or “Arguments, rich content”)\n\nAbove, pooling videos of similar type. (Random effects models?)\n\n\n\n\nWhich message yields a Result at the highest rate/lowest cost?\n5\nSub-questions\n\nHow does the ‘best message’ vary by audience?\n\n\n\n\n\n\nOther questions (less interest or less feasible)\n\n\n\n\n\n\nDo the message treatments ‘interact’ with the video treatments (i.e., are their synergies and better pairings)?\nDo some videos lead to higher click rates?\nDo some videos lead to higher watch rates?\n\n\n\n\n\n\n\n2.5.1 Defining the ‘outcomes of interest’ (as objects)\n\n\n\nNext, we define the ‘features of interest’ and the ‘controls’\n\n\nCode\n#features and controls\n#geog <- c(\"where_live_cat\", \"city_cat\")\n#key_demog <- c(\"ln_age\", \"not_male_cat\", \"student_cat\", \"race_cat\", geog)\n#key_demog_n <- c(\"age_d2sd\", \"not_male_cat\", \"student_cat\", \"race_cat\", geog)"
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#analysis-and-visuals",
    "href": "chapters/testformat_gwwc_gg.html#analysis-and-visuals",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.6 Analysis and visuals",
    "text": "2.6 Analysis and visuals\n6\n\n\nCode\n##gwwc_vid_results$DV_costadj)\n##gwwc_vid_results$DV)\n##gwwc_vid_results$ave.cost.impr)\n\n\nData summary\n\nBelow, a few data summary bits (from Erin). I commented most of it out and will redo it using an automated and formatted ‘key summary statistics’ package.\nI may also present the data in a dashboard for self-service.\n\n\n\nCode\n#datatable(gwwc_vid_results)\n\n\n\n\nCode\ngwwc_vid_results %>% group_by(Age) %>% summarise(n=n()) %>% .kable() %>%  .kable_styling()\n\n\nError in group_by(., Age): object 'gwwc_vid_results' not found\n\n\nCode\ngwwc_vid_results %>% group_by(Gender) %>% summarise(n=n())  %>% .kable() %>%  .kable_styling()\n\n\nError in group_by(., Gender): object 'gwwc_vid_results' not found\n\n\nCode\n#print(gwwc_vid_results %>% group_by(Gender,Age) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=40)\n#print(gwwc_vid_results %>% group_by(Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=41)\n#print(gwwc_vid_results %>% group_by(Campaign.name,Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=100)\n\n\n\n\nCode\n### CHART DATA\n\n#print(gwwc_vid_results %>% group_by(audience,media) %>% #summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)"
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#plots",
    "href": "chapters/testformat_gwwc_gg.html#plots",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.7 PLOTS",
    "text": "2.7 PLOTS\n\n\nCode\n#Plot options in common\n\nlimits <- aes(ymax = mean_dv + (se_dv), ymin = mean_dv - (se_dv))\ndodge <- position_dodge(width = 0.9)\n\nvid_types <-\n  c(\"factual short\",\n    \"animal\",\n    \"climate\",\n    \"factual long\",\n    \"hypercube\",\n    \"poverty\")\n\ngg_gg_options <- list(geom_bar(stat = 'identity', position=dodge),\n  geom_errorbar(limits, position=dodge,  width=0.05),\n  jtools::theme_apa(),\n  theme(legend.position=\"none\"),\n  geom_text(aes(label = paste(\"$\",mean_dv %>% round(.,2)), y=5), position = position_dodge(.9), size=4, color=\"white\"),\n  theme(text=element_text(size=10))\n)\n\ngrpsumgg <- function(df, gvar, var) {\n  df %>%\n  group_by({{gvar}}) %>%\n  summarise(mean_dv = mean({{var}}, na.rm=TRUE),\n            se_dv = sd({{var}}, na.rm=TRUE)/sqrt(n()))\n}\n\n\n\n2.7.1 PLOT: Cost adjusted DV (results) by video\n\n\nCode\ngwwc_vid_results %>%\n    filter(ave.cost.impr > 0) %>%\n    group_by(media) %>%\n    summarise(\n    `Results per $ (adjusted)` = mean(DV_costadj),\n    SE = std.error(DV_costadj),\n    n = n()\n  ) %>%\n  arrange(-`Results per $ (adjusted)`) %>%\n  .kable(digits = 3) %>%\n  .kable_styling()\n\n\nError in filter(., ave.cost.impr > 0): object 'gwwc_vid_results' not found\n\n\n\n\nCode\ngwwc_vid_results %>%\n  grpsumgg(media, DV_costadj) %>%\n  ggplot(aes(x=media, y=mean_dv)) +\n  gg_gg_options +\n  geom_bar(stat='identity',fill=\"#0072B2\", position=dodge) +\n  ylab('Results/$ spent') +\n  xlab('Video') +\n  ggtitle('Results/$ spent by Video') +\n  scale_y_continuous(limits = c(0,.2),  breaks=seq(0,.2, by=.05)) +\n  scale_x_discrete(labels=vid_types)\n\n\nError in group_by(., {: object 'gwwc_vid_results' not found\n\n\n\n\n2.7.2 PLOT: DV (Results) by video\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr > 0) %>%\n  group_by(media) %>%\n  summarise(\n  results = 100 * mean(DV),\n  SE = 100 * std.error(DV),\n  n = n()\n) %>%\n  .kable(digits = 2) %>%\n  .kable_styling()\n\n\nError in filter(., ave.cost.impr > 0): object 'gwwc_vid_results' not found\n\n\nCode\ngwwc_vid_results %>%\n   grpsumgg(media, DV) %>%\n  ggplot(aes(x=media, y=mean_dv)) +\n  geom_bar(stat='identity', fill=\"#0072B2\",position=dodge) +\n  ylab('Results (%)')+\n  xlab('Video')+\n  ggtitle('Results by Video')+\n  scale_x_discrete(labels=vid_types)\n\n\nError in group_by(., {: object 'gwwc_vid_results' not found"
  },
  {
    "objectID": "chapters/gwwc_gg.html#modeling-cost-per-result-and-results-per-dollar-possible-reference-literature",
    "href": "chapters/gwwc_gg.html#modeling-cost-per-result-and-results-per-dollar-possible-reference-literature",
    "title": "1  Giving What We Can: Giving guides",
    "section": "2.2 Modeling ‘cost per result’ and ‘results per dollar’: possible reference literature",
    "text": "2.2 Modeling ‘cost per result’ and ‘results per dollar’: possible reference literature\nSodomka, Eric, Sébastien Lahaie, and Dustin Hillard. “A predictive model for advertiser value-per-click in sponsored search.” Proceedings of the 22nd international conference on World Wide Web. 2013."
  },
  {
    "objectID": "chapters/gwwc_gg.html#building-a-set-of-models-to-do",
    "href": "chapters/gwwc_gg.html#building-a-set-of-models-to-do",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.6 Building a set of models (to do)",
    "text": "1.6 Building a set of models (to do)\n\n\nCode\n#targets:\nbin_out <- c(\"d_don_1k\", \"d_don_10pct\")\n\nnum_out <- c('donation_usd', 'don_av2_yr', 'l_don_usd', \"l_don_av_2yr\", \"don_share_inc_imp_bc5k\", \"donation_plan_usd\")\ntargets <- c(bin_out, num_out)\ntargets_short <- c(\"don_av2_yr\", \"don_share_inc_imp_bc5k\", \"d_don_1k\") \n\n#Note -- don_av2_yr is the right one for qpoisson as it already expresses things in exponents. l_don_av2_yr was the one to use in the loglinear model, which we are not emphasizing\n\ntargets_short_names <- c(\"Log (Avg don +1)\", \"Don/Income\", \"Donated 1k+\")\n\n\n\n\nCode\n#imputing and normalization\n\n\n\n\nCode\n#labeling for model output \n\nkey_eas_all_labels <- c( #note these are converted to a list with as.list before assigning them\n    donation_usd = \"Donation (USD)\",\n    l_don_usd = \"Log Don. (USD)\",\n    l_don_av_2yr = \"Log Don. 'avg.'\",\n    ln_age = \"Log age\",\n    don_av2_yr = \"Don. 'avg'\",\n    donation_plan_usd = \"Don. plan (USD)\")\n\n\n\n\nCode\nfeat_list = list(\n  c(key_demog, feat_income_employ, controls),\n  c(key_demog, feat_income_employ, controls, robust_controls),\n  c(key_demog, feat_income_employ, feat_gwwc_etg, controls) )\n\nfeat_names = c(\"Baseline\", \"Robust controls\",  \"Base + EtG & GWWC\")\n\n\n\n\nCode\nrhs_vars_list <- rep(feat_list, length(targets_short))\n  \noutcome_vars_list <- rep(as.list(targets_short), each=length(feat_list))\n\ndfs <- rep(list(eas_all_s_rl_imp), length(outcome_vars_list))\n\n\n\n\nCode\n## Create dataframe for modeling\n(linear_models <- make_model_df(rhs_vars_list, outcome_vars_list, dfs))\n\n\n\n\nCode\nlinear_models <- linear_models %>%\n  mutate(\n    lm_fit = fit_models(\n      linear_models, \"formulas\", \"dfs\", fun = fit_lm)\n    )\n\n# Extract coefficients, fitted and residuals\nmodel_feat_names <- rep(c(feat_names), times= length(targets_short))\nmodel_oc_names <- rep(c(targets_short_names), each= length(feat_names))\nmodel_names <- paste(model_oc_names, model_feat_names, sep = \": \")\n\n\n\n\n\n\n\n\nModeling goals/discussion/todo\n\n\n\n\n\n*Rethinking (5 Aug 2022): Cost per result may not be the best outcome to model as a first pass. We might better model results per impression and put in a cost adjustment later. See\n\nPresent mean/Bayesian updating:\n\n\nOverall cost/result\n\nand for different audiences\nrandom effects?\n\npresent posterior distribution and intervals\n\nOr a stripped down ‘simulation approach’?\n\nModel (multivariable regression):\n\nCost/result as a function of\n\ncampaign (i.e., time of launch)\nmessage\nvideo\naudience\ngender\nage\n\nLinear and log-linear\nRandom effects (how?)\nPresent a set of estimates for the mean and 80% CI for cost/result for key groups\n\n\n\n\n\nCode\n#set base levels before doing modeling\n\ngg_campaign_by_ad_by_text_age_gender$age <- factor( gg_campaign_by_ad_by_text_age_gender$age,\n  ordered = FALSE )\n\ngg_campaign_by_ad_by_text_age_gender$age <- relevel( gg_campaign_by_ad_by_text_age_gender$age,\n  ref=\"18-24\") \n\ngg_campaign_by_ad_by_text_age_gender$audience <- factor( gg_campaign_by_ad_by_text_age_gender$audience,\n  ordered = FALSE )\n\ngg_campaign_by_ad_by_text_age_gender$audience <- relevel( gg_campaign_by_ad_by_text_age_gender$audience,\n  ref=\"Philanthropy\")\n\n\n\n\nCode\nsummarise_stuff <- function(df) {\n  df %>%\n     summarise(\n      amount_spent_usd = sum(amount_spent_usd), \n      impressions=sum(impressions),\n      link_clicks = sum(link_clicks, na.rm = TRUE),\n      results = sum(results, na.rm = TRUE),\n      cost_per_impression = amount_spent_usd/impressions,\n      cost_per_click = amount_spent_usd/link_clicks,\n      results = ifelse(is.na(results), 0, results ),\n      results_per_100usd = results/(amount_spent_usd/100),\n      results_per_1k_impressions = results*1000/impressions) \n}\n\nmodel_data_0 <- gg_campaign_by_ad_by_text_age_gender %>%\n  filter(audience!=\"Retargeting\") %>%\n  ungroup() %>%\n    group_by(video_theme, text_treat, audience) %>% #starts, \n    #filter(impressions>200) %>%\n    summarise_stuff() %>%\n  ungroup() %>% \n  as.tibble() %>% \n  mutate(\n    across(c(video_theme, text_treat, audience), #starts, \n      as.factor )\n    )\n\nmodel_data_start <- gg_campaign_by_ad_by_text_age_gender %>%\n  filter(audience!=\"Retargeting\") %>%\n  ungroup() %>%\n    group_by(video_theme, text_treat, audience, starts) %>% #starts, \n    #filter(impressions>200) %>%\n        summarise_stuff() %>%\n  ungroup() %>% \n  as.tibble() %>% \n  mutate(\n    across(c(video_theme, text_treat, audience, starts), #starts, \n      as.factor )\n    )\n\nmodel_data <- gg_campaign_by_ad_by_text_age_gender %>%\n    filter(audience!=\"Retargeting\") %>%\n  ungroup() %>%\n    group_by(video_theme, text_treat, audience, gender, agetrin) %>% #starts, \n    #filter(impressions>200) %>%\n        summarise_stuff() %>%\n  ungroup() %>% \n  as.tibble() %>% \n  mutate(\n    across(c(video_theme, text_treat, audience, gender, agetrin), #starts, \n      as.factor )\n    )\n\nRp100usd_vid_text_audience0 <- model_data_0 %>%  \n  lm(\n    results_per_100usd ~ 1 + video_theme + text_treat + audience,\n    data = ., \n    weights = impressions) \n  \n\nRp100usd_vid_text_audience_starts <- model_data_start %>%  \n  lm(\n    results_per_100usd ~ 1 + starts + video_theme + text_treat + audience,\n    data = ., \n    weights = impressions) \n  \n\nRp100usd_vid_text_audience_demo <- model_data %>%  \n  lm(\n    results_per_100usd ~ 1 + video_theme + text_treat + audience + gender + agetrin,\n    data = ., \n    weights = impressions) \n\n#Do NOT do this: Rp100usd_vid_text_audience0$df.residual <- sum(model_data_0$impressions) - length(coef(Rp100usd_vid_text_audience0))\n\nhuxtable::huxreg(Rp100usd_vid_text_audience0, Rp100usd_vid_text_audience_starts, Rp100usd_vid_text_audience_demo)\n\n\n\n\n(1)(2)(3)\n\n(Intercept)12.420 ***10.844 ***11.859 ***\n\n(1.573)   (1.932)   (1.593)   \n\nvideo_themeCause-led (any)-2.273    -1.264    -2.479 *  \n\n(1.228)   (1.637)   (1.246)   \n\nvideo_themeClimate-2.052    1.396    -1.282    \n\n(4.629)   (5.557)   (4.622)   \n\nvideo_themeFactual long-7.275 ***-6.179 ** -7.675 ***\n\n(1.603)   (1.961)   (1.605)   \n\nvideo_themeFactual short-0.002    -1.704    0.121    \n\n(1.153)   (1.596)   (1.154)   \n\nvideo_themeHypercube (factual)-6.471 ***-5.091 *  -6.955 ***\n\n(1.437)   (2.042)   (1.464)   \n\nvideo_themePoverty0.037    1.406    0.733    \n\n(2.113)   (2.567)   (2.119)   \n\ntext_treat6000+ people-2.816 ** -2.958 ** -2.346 ** \n\n(0.893)   (1.108)   (0.892)   \n\ntext_treatBigger difference-0.684    0.012    -0.250    \n\n(0.865)   (1.056)   (0.863)   \n\ntext_treatCause list-0.462    -1.574    -0.880    \n\n(1.359)   (1.724)   (1.357)   \n\ntext_treatLearn-1.524    -1.312    -1.293    \n\n(0.908)   (1.100)   (0.906)   \n\ntext_treatOnly 3% research2.404 *  2.810 *  2.832 ** \n\n(0.936)   (1.125)   (0.935)   \n\ntext_treatOverwhelming-0.956    -1.416    -0.023    \n\n(1.168)   (1.550)   (1.166)   \n\naudienceAnimal-0.455    0.233    -0.627    \n\n(0.918)   (1.156)   (0.927)   \n\naudienceClimate-0.064    0.147    -0.735    \n\n(0.811)   (1.057)   (0.817)   \n\naudienceGeneral audience0.846    1.305    0.727    \n\n(1.093)   (1.433)   (1.099)   \n\naudienceGlobal Poverty-0.273    -0.384    -1.252    \n\n(1.172)   (1.453)   (1.172)   \n\naudienceLookalikes2.031 *  1.090    1.506    \n\n(0.979)   (1.176)   (0.977)   \n\nstarts2021-12-08        2.792            \n\n        (1.495)           \n\nstarts2021-12-23        3.486 **         \n\n        (1.042)           \n\nstarts2022-01-07        -0.261            \n\n        (1.385)           \n\ngendermale                0.596    \n\n                (0.599)   \n\ngenderunknown                -0.328    \n\n                (1.648)   \n\nagetrin0                0.806    \n\n                (0.783)   \n\nagetrin1                1.011    \n\n                (0.658)   \n\nN129        185        991        \n\nR20.518    0.376    0.117    \n\nlogLik-359.765    -573.684    -4245.601    \n\nAIC757.529    1191.368    8537.203    \n\n *** p < 0.001;  ** p < 0.01;  * p < 0.05.\n\n\n\n\nNote: the N (and R-sq?) values above are incorrect; these are the number of groups not the number of baseline observations.\n10\n\nWhich pre-defined audience yields a Result at the lowest cost? How does this cost vary by audience?\n\nRefer to models/estimates above\n\n\n\nWhich pre-defined audience yields the highest ‘rate of Result’? How does this vary by audience?\nNote, this is not the same as the previous question because some audiences are more costly to target on Facebook.\n\nRe-run above models for ‘results per impression’\n\nImportant caveat: this does not tell us the effect ‘on a particular group’, because of FB’s optimization algorithms; see discussion here.\nInteractions/separate models for ‘vary by audience’.\n\n\nWhich video yields a Result at the highest rate/lowest cost?\n\n\nCode\n#Plot options in common\n\nlimits <- aes(ymax = mean_dv + (ci_spread), ymin = mean_dv - (ci_spread))\ndodge <- position_dodge(width = 0.9)\n\nvid_types <-\n  c(\"factual short\",\n    \"animal\",\n    \"climate\",\n    \"factual long\",\n    \"hypercube\",\n    \"poverty\")\n\ngg_gg_options <- list(geom_bar(stat = 'identity', position=dodge),\n  geom_errorbar(limits, position=dodge,  width=0.25, color=\"red\"),\n  jtools::theme_apa(),\n  theme(legend.position=\"none\"),\n  geom_text(aes(label = paste(\"$\", mean_dv %>% round(.,2)), y=5), position = position_dodge(.9), size=4, color=\"white\"),\n  theme(text=element_text(size=10))\n)\n\ngrpsumgg <- function(df, gvar, var, ci_ends) {\n  df %>%\n  group_by({{gvar}}) %>%\n  summarise(mean_dv = mean({{var}}, na.rm=TRUE),\n            se_dv = sd({{var}}, na.rm=TRUE)/sqrt(n()),\n            ci_spread = qt(1 - (ci_ends / 2), n() - 1) * se_dv)\n}\n\n\n\n\nCode\ngg_video_breakdowns %>%\n        mutate(results_per_100usd = results/(amount_spent_usd/100)) %>% \n     uncount(weights = .$impressions) %>%\n  grpsumgg(video_theme, results_per_100usd, 0.1) %>%\n  ggplot(aes(x=video_theme, mean_dv)) +\n  geom_bar(stat='identity',fill=\"#0072B2\", position=dodge) +\n  gg_gg_options +\n  ylab('Results/$ spent') +\n  xlab('Video') +\n  ggtitle('Results/$ spent by Video, 90% CIs') +\n  scale_x_discrete(labels=vid_types)\n\n\n\n\n\nCode\ngwwc_vid_results %>%\n  grpsumgg(media, DV_costadj, 0.1) %>%\n  ggplot(aes(x=media, y=mean_dv)) +\n  geom_bar(stat='identity',fill=\"#0072B2\", position=dodge) +\n  gg_gg_options +\n  ylab('Results/$ spent') +\n  xlab('Video') +\n  ggtitle('Results/$ spent by Video, 90% CIs') +\n  scale_y_continuous(limits = c(0,.2),  breaks=seq(0,.2, by=.05)) +\n  scale_x_discrete(labels=vid_types)\n\n\n\n\n\n\nRefer to models/estimates above, coefficient on ‘video’\n\n11\n\nHow does the ‘best video’ vary by audience?\n\nInclude interactions in above model\nRun model separately for each group (or allowing everything to interact) for robustness\nAlso consider ‘what did FB serve to each group’, assuming it is optimizing.\n\n\n\nAggregating: Which category of videos yields a result at the highest rate/lowest cost? (“Facts”, “Cause focus”, or “Arguments, rich content”)\n\nAbove, pooling videos of similar type. (Random effects models?)\n\n\n\n\nWhich message yields a Result at the highest rate/lowest cost?\n12\nSub-questions\n\nHow does the ‘best message’ vary by audience?\n\n\n\n\n\n\nOther questions (less interest or less feasible)\n\n\n\n\n\n\nDo the message treatments ‘interact’ with the video treatments (i.e., are their synergies and better pairings)?\nDo some videos lead to higher click rates?\nDo some videos lead to higher watch rates?"
  },
  {
    "objectID": "chapters/gwwc_gg.html#modelingsimulating-cis-for-results-by-group",
    "href": "chapters/gwwc_gg.html#modelingsimulating-cis-for-results-by-group",
    "title": "1  Giving What We Can: Giving guides",
    "section": "2.1 Modeling/simulating CIs for results by group",
    "text": "2.1 Modeling/simulating CIs for results by group\nSketched proposal\n\nAssume the ‘cost per impression’ (CpI) is fixed for each group or segment – take that as exogenous and something we adjust for at the end16\nMake some assumptions about the distribution of the probability of a result from an impression for each individual in each group \\(g\\); call this \\(P_{ig}\\). E.g., each outcome \\(r_i \\in \\{0,1\\}\\) is drawn with probability \\(P_{ig}\\). We see the average of these draws.\n\nA close-to-correct simplification might yield that the group-specific results per impression (RpI) is the average value of \\(P_{ig}\\) for the group, call this \\(P_g\\). We can make some intuitive assumptions about the variance of \\(P_{ig}\\) around \\(P_g\\) within each group.\nSo we would have something like: \\(P_{ig} \\sim \\beta\\) distribution with a mean of RpI (results per impression for the group), and some reasonable variation.\n\nLet \\(N_g\\) be the number of impressions we see per group.\n\nIn each simulation replication, simulate \\(N_g\\) draws of \\(P_{ig}\\) for each individual in each group \\(g\\).\nNext ‘flip an unfair coin for each individual’, where the coin has probability \\(P_{ig}\\) of a result. This yields \\(N_g\\) draws of the 0/1 outcome \\(r_i(g)\\) for each group\n\nLook at the distribution of results for each group across many simulations. This can easily be converted to the distribution of RpI for each group, or, assuming CpI is fixed, the distribution of ‘cost per result’ (or results per cost) for each group.\n\nThis gives us our confidence intervals.\nThe above is a bit ad-hoc (but less than our previous work). I suspect the procedure comes close to something that could give us something Bayesian."
  }
]