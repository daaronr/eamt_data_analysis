---
execute:
    freeze: auto # re-render only when source changes
    warning: false
    message: false
    error: true
---

# FORMAT TESTING Giving What We Can: Giving guides {#gwwc_gg}

::: {.callout-note}

This chapter should align with a (forthcoming) EA Forum post, which will be linked here (and vice-versa).

:::


```{r, include=FALSE}
library(here)
source(here("code", "shared_packages_code.R"))
library(dplyr, janitor)
library(pacman)

library(GDAtools, include.only = 'wtable', 'dichotom')

```

```{r import_raw_0}
#importing for dynamic input of descriptions below

raw_data_path <- list("gwwc", "gg_raw_data_shareable")

mini_clean <- function(df){
  df %>%
    as_tibble() %>%
  janitor::clean_names() %>%
  janitor::remove_empty() %>% # removes empty rows and columns, here `unique_link_clicks`
    janitor::remove_constant()
    }


```


## The trial

See full description in the gitbook [here](https://effective-giving-marketing.gitbook.io/untitled/contexts-partner-organizations-trials/gwwc/giving-guides-+).

**Context**: Facebook advertisements on a range of audiences

> **Effective Giving Guide Lead Generation campaign** ... ran late November 2021 - January 2022. The objective of this campaign was to see whether a factual ['who researches giving' or 'magnitude of impact differences'] or cause-led approach was more cost-effective at getting people to fill out a form and give us their email in order to download our Effective Giving Guide.

### Treatments (text $\times$ video)

*There were two dimensions of treatment content:*

1.  **The texts displayed above the videos**

::: {.callout-note collapse="true"}
## Texts


**Bigger difference next year:** Want to make a bigger difference next year? Start with our Effective Giving Guide and learn how to make a remarkable impact just by carefully choosing the charities you give to.

**100x impact:** Did you know that the best charities can have a 100x greater impact? Download our free Effective Giving Guide for the best tips on doing the most good this holiday season.

**6000 people:** Giving What We Can has helped 6,000+ people make a bigger impact on the causes they care about most. Download our free guide and learn how you can do the same.

**Cause list**: Whether we're moved by animal welfare, the climate crisis, or worldwide humanitarian efforts, our community is united by one thing: making the biggest impact we can. Make a bigger difference in the world through charitable giving. Start by downloading our Effective Giving Guide. You'll learn how to approach charity research and smart giving. And be sure to share it with others who care about making a greater impact on the causes closest to their hearts.

**Learn:** Use our free guide to learn how to make a bigger impact on the causes you care about most.

**Only 3% research:** Only 3% of donors give based on charity effectiveness yet the best charities can be 100x more impactful. That's incredible! Check out the Effective Giving Guide 2021. It'll help you find the most impactful charities across a range of causes.

**Overwhelming**: It can be overwhelming with so many problems in the world. Fortunately, we can do *a lot* to help, if we give effectively. Check out the Effective Giving Guide 2021. It'll help you find the most impactful charities across a range of causes.
:::

::: {.callout-note collapse="true"}
## Arguments, rich content from "Hypercube"

6.  [Hypercube](https://www.youtube.com/watch?v=CiFoHm7HD94) (1 min 22 seconds): Animated and voiceover video that explains how GWWC can help maximize charitable impact (support, community, and information) and the problems GWWC addresses (good intentions don't always produce the desired outcomes, there are millions of charities that have varying degrees of impact and some can even cause harm). CTA: *Check out givingwhatwecan.org to learn how you can become an effective giver.*
:::


### Further detail, links {-}

::: {.callout-note collapse="true"}
## Notes from the trial description

"In the original version of our test, we had 1 video for the factual appeal and 3 videos for the cause led approach - 1 for global health and development, 1 for animal welfare and 1 for climate change."

"We targeted our ads to audiences we thought were likely to engage based on their interests and demographics, and targeted the cause led videos to a relevant audience, i.e. climate change message to climate change audience."

"We also had various text above the videos that were displayed and optimized."
:::

```{r, include=FALSE}
library(here)
source(here("code", "shared_packages_code.R"))
```

Details in Gitbook [HERE (and embedded below)](https://effective-giving-marketing.gitbook.io/untitled/partner-organizations-and-trials/gwwc/giving-guides-+) and Gdoc [here](https://docs.google.com/document/d/1FfrXhD1YAIjrATy9PR6ScP20NMQa82sd80YvMb62iUQ/edit)

```{r wppage}

knitr::include_url("https://effective-giving-marketing.gitbook.io/untitled/partner-organizations-and-trials/gwwc/giving-guides-+")
```

## Implementation & treatment assignment: key details


::: {.callout-note collapse="true"}
## Treatment assignment order, dates

The treatment assignment was determined by Facebook's algorithm. Video content was manipulated across three split tests.

Test 1 (Nov 30, 2021 – Dec 8, 2021, campaigns: "Cause-Led" and "Factual") displayed either the long factual video or a cause focus video. In the cause focus condition, cause-specific audiences for animal rights, climate change, and poverty (based on their behavior on Facebook) were shown the relevant cause video.

Test 2 (add dates) was the same as Test 1 but used the short factual video instead of the cause-focus videos.

Test 3 (add dates) was the same as Test 2 but had a new version of the videos (with Luke just holding up signs with the words). This test was also restricted to 18-35 year olds.

Test 4: The Hypercube video was displayed in a separate “Hypercube” campaign which was tested against another campaign that allowed the algorithm to optimize between the 'short factual' and 'cause focus' videos (although not allowing each cause-specific audience to see the ads for other cause areas).

In all tests, the text content displayed above the video was determined by Facebook’s algorithm. Balance across variations was determined to equate budgets across split tests; otherwise, according to Facebook’s algorithm. All variation was done at the level of the impression.

The videos were adapted across the trials as we learned. First, we updated the factual video to be shorter for Trial 2, and then we tried videos of Luke holding up signs spelling out the voiceover in Trial 3 for all videos.

:::

## Build: Source data input and cleaning code

::: {.callout-note collapse="true"}
## Accessing, downloading, inputting data


See:

[Accessing and bringing down simple results HERE](https://app.gitbook.com/o/-MfFk4CTSGwVOPkwnRgx/s/-Mf8cHxdwePMZXRTKnEE/core-knowledge-base/marketing-implementation-and-practical-tips/collecting-data-trial-outcomes/facebook-meta-ads-interface); (Public access version [here](https://effective-giving-marketing.gitbook.io/untitled/marketing-and-testing-opportunities-tools-tips/collecting-data-trial-outcomes/facebook-meta-ads-interface))


:::

<!-- [Most relevant breakdowns as pivot tables](https://app.gitbook.com/o/-MfFk4CTSGwVOPkwnRgx/s/-Mf8cHxdwePMZXRTKnEE/core-knowledge-base/marketing-implementation-and-practical-tips/collecting-data-trial-outcomes/facebook-meta-ads-interface/...-pivot-tables) -->

::: {.callout-note collapse="true"}
## Data structure


- `text`: Which text was shown along with the video

- `age` (a range of ages)

- `gender` (female, male, unknown)

:::

```{r import_real_raw_data}

raw_data_path <- list("gwwc", "gg_raw_data_shareable")

#already input above: gg_campaign_by_ad_by_text

#Version allowing demographic breakdown:
gg_campaign_by_ad_by_text_age_gender <- read_csv(here(raw_data_path, "gg-campaign-by-ad-set-text-age-gender.csv"), show_col_types=FALSE) %>%
  #dplyr::select(-"Campaign name...4") %>% #duplicate columns?
 mini_clean()

#Version with information on cause videos shown (even to those in 'general' groups):

gg_video_breakdowns <- read_csv(here(raw_data_path, "gg-image-video-breakdowns.csv"), show_col_types=FALSE)

#capture and remove columns that are the same everywhere
attribution_setting_c <- gg_campaign_by_ad_by_text_age_gender$attribution_setting %>% .[1]
reporting_starts_c <- gg_campaign_by_ad_by_text_age_gender$reporting_starts %>% .[1]
reporting_ends_c <- gg_campaign_by_ad_by_text_age_gender$reporting_ends %>% .[1]


gg_campaign_by_ad_by_text_age_gender  %<>% mini_clean()
gg_video_breakdowns  %<>% mini_clean()

#functions to clean these specific data sets 'gg_campaign_by_ad_by_text_age_gender' and 'gg_campaign_by_ad_by_text':
source(here("gwwc", "giving_guides", "clean_gg_raw_data.R")) 

#Many cleaning steps: audience, video_theme, campaign_theme, agetrin; releveling
gg_campaign_by_ad_by_text_age_gender %<>%
  rename_gg() %>%
gg_make_cols() %>% 
  vid_clean() %>%  # Video rename and stuff
  text_clean() %>%  # Shorter 'text treatment' column
  relevel_gwwc_gg_raw() %>% 
  dplyr::select(campaign_name, everything(), -campaign_name_1, -campaign_name_7) #campaign_name_7 was the same as campaign_name_1

gg_video_breakdowns %<>%
  rename_gg() %>%
gg_make_cols()  %>% 
    vid_clean()  # Video rename and stuff


#gg_campaign_by_ad_by_text_age_gender %>% collapse::descr()

```


```{r video_general_encoding}

gg_video_breakdowns %<>%
  mutate(
    video_theme = case_when(
      str_det(image_video_and_slideshow, "set_1|Animals") ~ "Animal",
      str_det(image_video_and_slideshow, "set_2|Climate") ~ "Climate",
      str_det(image_video_and_slideshow, "set_3|Poverty|Free Effective") ~ "Poverty",
      str_det(image_video_and_slideshow, "factual") ~ "Factual",
      TRUE ~ video_theme
    ),
    video_theme =  factor(video_theme), 
    video_theme = fct_relevel(video_theme, c("Animal", "Climate", "Poverty", "Factual", "Factual or optimized mix")) 
  )


```

::: {.callout-note collapse="true"}
## This data should be publicly shareable.

This data is clearly not identifying individuals; it involves aggregates based on real or assumed characteristics ... there is likely nothing that needs to be hidden here. We aim to share and integrate all the data in this repo, for a complete pipeline.

:::

::: {.callout-note collapse="true"}
## Previous version of data used ... (updating)

We previously used data collapsed (breakdowns) by demography and ad set, into 2 files, which duplicated rows to represent  the number of impressions:  `video breakdown`, and  `text breakdown.csv`. We now use the more 'raw' minimal version of the data, avoiding duplicating rows where possible.

Below, we also input the 'old version' of the data, with the duplicated rows, to accommodate the old-format of analysis.  The code above inputs and builds 2-4 related data frames (tibbles), which were constructed from the collapsed (aggregated) data by multiplying rows according to observation counts. I am not sure where this was done. Once we update the rest we will get rid of this.

`gwwc_text_clicks`: Observations of link clicks ... by texts above video `gwwc_vid_clicks`: ... by video content


(We focus on the email results because we expect the 'clicks' are less meaningful.)

`gwwc_text_results`: Observations of emails provided ... by texts above video `gwwc_vid_results`: ... by video content

The files:

`textdata_dv_linkclicks.csv`, `videodata_dv_results.csv`, `textdata_dv_results.csv` , and `videodata_dv_linkclicks.csv`

are gitignored because of size.
:::

## Descriptives

### Implemented treatments, impressions

First we illustrate 'where, when, and to whom' the different campaigns and treatments were shown (Facebook 'impressions').

The sequential campaigns involved different sets of videos, and these videos had different versions:

```{r impressions_count}

(
  impressions_campaign_theme <- gg_video_breakdowns %>%
  dplyr::select(campaign_name, video_theme, impressions) %>%
   uncount(weights = .$impressions) %>%
    dplyr::select(-impressions) %>%
   tabyl(campaign_name, video_theme) %>%
    dplyr::select(campaign_name, Animal, Climate, Poverty, everything()) %>% 
  .kable(caption = "Campaign names and video themes: Impressions") %>%
  .kable_styling()
)


```

Some audiences were profiled as associated with a certain cause (through their Facebook interests or activities): in 'cause-focused' campaigns they were shown videos  for their profiled cause. In campaigns that were not cause-focused, they were shown general interest videos. However, those associated with one cause were never shown videos for other causes.

Audience not åssociated with a cause included the 'General' audience, the Philanthropy (interested in charity) audience, a GWWC 'Lookalike' audience, and a Retargeted (?) audience: these were shown either the more general-interest videos or particular cause videos. Unfortunately, for these groups, when they were shown a cause-related video, we have not been able to extract the data on *which* cause-specific video they saw. This is illustrated in the table below.

:::{.column-body-outset}
Outset content...


```{r impressions_video_audience}

video_levels <- c("Animal", "Climate", "Poverty", "Cause-led (any)", "Factual", "Factual or optimized mix", "Total")
  
(
impressions_video_audience <- gg_video_breakdowns %>%
    dplyr::select(video_theme, audience, impressions) %>%
    uncount(weights = .$impressions) %>%
    dplyr::select(-impressions) %>%
    tabyl(video_theme, audience) %>% 
    adorn_percentages("all") %>%
    adorn_totals(where = c("row", "col")) %>% 
    adorn_pct_formatting(digits = 2) %>% 
    dplyr::select(video_theme, Animal, Climate, `Global Poverty`, `Philanthropy`, everything()) %>% 
   mutate(video_theme =  factor(video_theme, levels = video_levels)) %>%
  arrange(video_theme)  %>% 
    .kable(caption = "Video themes by audience: share of impressions", digits=3) %>%
  .kable_styling()
)

```
:::

The second treatment dimension -- text presented along with the video -- was allowed to vary independently of the video:

```{r impressions_video_text}

(
  impressions_video_text <- gg_campaign_by_ad_by_text_age_gender %>%
  dplyr::select(video_theme, text_treat, impressions) %>%
   uncount(weights = .$impressions) %>%
    dplyr::select(-impressions) %>%
   table %>%
        prop.table() %>% 
        addmargins() %>% 
  .kable(caption = "Video themes by text treatment: Impressions", digits=3) %>%
  .kable_styling()
)


(
  impressions_video_text <- gg_campaign_by_ad_by_text_age_gender %>%
  dplyr::select(campaign_name, text_treat, impressions) %>%
   uncount(weights = .$impressions) %>%
    dplyr::select(-impressions) %>%
   table %>%
        prop.table() %>% 
        addmargins() %>% 
  .kable(caption = "Text treatments by campaign: Impressions", digits=3) %>%
  .kable_styling()
)

```
(Note, above that we cannot identify all of the video treatments in the same dataset with text treatments; this is a limitation of the Facebook interface)

However, note that treatment shares are not equal.  In fact, as the second table above shows, they are not even equal within each campaign. This is because Facebook optimizes to show videos and text more, the more successful they are.^[This also may lead FB to particularly combine certain message presentations more with certain video presentations. However we cannot check this in our current setup: it is confounded with 'audience profile' (at least in the data we can observe).]


### Demographics 

```{r}

(
  impressions_age_gender <- gg_campaign_by_ad_by_text_age_gender %>%
  dplyr::select(age, gender, impressions) %>%
   uncount(weights = .$impressions) %>%
    dplyr::select(-impressions) %>%
   table %>%
    prop.table() %>% 
    addmargins() %>% 
  .kable(caption = "Impressions by Age and Gender", digits=2) %>%
  .kable_styling()
)

```
As can be clearly seen above, within all age groups, the ad was disproportionally shown to women. Relative to the [overall Facebook population](https://www.statista.com/statistics/187549/facebook-distribution-of-users-age-group-usa/#:~:text=As%20of%20June%202022%2C%2023.5,13%20to%2017%20years%20old) our data skews very slightly younger.^[But we essentially excluded the  13-17 age group.]


TEST MARGIN CONTENT

```{r}
#| column: margin

knitr::kable(
  mtcars[1:6, 1:3]
)
```


### Outcomes 

```{r campaign_date_outcomes}

base_results_sum <- function(df) {
    df %>%
     dplyr::summarize(
  Cost = sum(round(amount_spent_usd,0)),
      Impressions=sum(impressions),
      `Link clicks`=sum(link_clicks, na.rm = TRUE),
      Results=sum(results, na.rm = TRUE),
      `$/impr.` = round(Cost/Impressions,3),
      `$/click` = round(Cost/ `Link clicks`,1),
      `$/result` = round(Cost/Results,1),
      `Results/1k impr.` = round(Results*1000/Impressions,1)
)
     }

(
  campaign_date_outcomes <-  gg_campaign_by_ad_by_text_age_gender %>%
    group_by(campaign_name, starts) %>%
    rename('Campaign' = campaign_name) %>%
    filter(impressions>200) %>%
    base_results_sum %>%
    arrange(starts) %>%
    .kable(caption = "Results by Campaign and start date") %>%
    .kable_styling() %>%
    add_footnote("'False start' campaign dates with less than 200 impressions are excluded")
)

```



```{r age_gender_outcomes}
(
  age_outcomes <- gg_campaign_by_ad_by_text_age_gender %>%
    group_by(age) %>%
        filter(impressions>500) %>%
    base_results_sum() %>%
    .kable(caption = "Results by Age") %>%
    .kable_styling()
)

(
  gender_outcomes <- gg_campaign_by_ad_by_text_age_gender %>%
    group_by(gender) %>%
    base_results_sum() %>%
    .kable(caption = "Results by Gender") %>%
    .kable_styling()
)
```


Cost per click by audience (non-cause treatments):

```{r audience_outcomes}
(
  video_outcomes_phil <- gg_video_breakdowns %>%
    filter(audience=="Philanthropy") %>%
    group_by(video_theme) %>% 
    base_results_sum() %>%
    arrange(video_theme) %>% 
    .kable(caption = "Results by Video theme for 'Philanthropy' audience") %>%
    .kable_styling()
)




```
Above, we compare the text treatments for the later campaigns only. The earlier and later campaigns had a slightly different set of texts; combining across these risks confounding.
By ad text and by video:



```{r}

  
(
  audience_outcomes <- gg_video_breakdowns %>%
    group_by(audience) %>%
    filter(video_theme== "Animated" | video_theme== "Factual" ) %>%
    base_results_sum() %>%
    DT::datatable(caption = "Results by audience for non-cause videos") 
)

```

Above, we look at the performance of different audiences. As cause-specific audiences tend to be presented particular cause videos, we focus only on non-cause-related videos here for greater comparability. 

*Format note:* The table above is presented with the `Datatables` package/function. This allows sorting, filtering, etc. We can present more tables in this format if it is preferrable.

## Asking and answering questions

::: {.callout-note collapse="true"}
## This dynamic document format allows us to ask and answer a series of questions

-   Using the data, with all coding steps shown
-   Ideally, following a pre-defined (pre-analysis) plan
-   Using the data and statistics directly and automatically in the narrative
    -   And everything will be automatically adjusted if we bring in new data or adjust/correct features
:::

### In this context, how much does it cost to get a 'Result", i.e., to get a person to give their email to receive a Giving Guide? {.unnumbered}

::: {.callout-note collapse="true"}
## Cost per result (CpR) as the result of several processes...

How should we consider this outcome?    At the base level the Cost per Result ('CpR') for a 'segment' (a particular ad version, audience, campaign, etc), comes from several interrelated processes: 

1. How much FB charges us for this segment
2. Who FB serves this segment to (what types of people, how many)
3. How many people in that segment click and then 'convert', yielding a result

We could try to model each of these processes, but it could be very involved, and we don't fully observe or understand the second step, FB's optimization algorithm.

::: 

::: {.callout-note collapse="true"}
## CpR as a black box... 

Alternatively, we could think of the CpR for a segment as just a 'base outcome to model', and treat it as a sort of black box. This would suggests we have 'only one CpR coutcome per segment', and each segment has different characteristics ('features' or 'variables'), some in common. But that discards some important information: the mean values for segments with more observations (here, 'impressions') can be expected to have less variance (lower standard error), all else equal. 

:::

::: {.callout-note collapse="true"}

## CpR as the average of a lot of black boxes... 

We can do something intermediate -- taking the aggregation into account, without fully building a structural model of the factors above.  Within each segment, we can consider the 'average cost per result' outcome for each individual as the expected value of a random draw. Each individual has some 'cost per impression', and some 'probability of a result'. The ratio of these is the individual's 'expected cost per result ... which we can also abstract as just some random draw. This may be considered as a function of 'all the characteristics of the segment the individual is in'. The CpR for the segment is thus an average of the CpR for all the individuals in the segment, and we can use 'regression weights' (technically 'inverse variance weights'; see discussion in [Huntington-Klein's book here](https://theeffectbook.net/ch-StatisticalAdjustment.html#sample-weights)) in our model to reflect this.

:::

<!-- Each segment has different observable preset characteristics: a particular combination of ad features, audience filter, time the campaign started, etc.

Segments also have different unobserved features: FB selectively chooses how to present the ad features, and to whom, and to how many people,  to maximize some outcome (considering an explore/exploit tradeoff). This makes some inference difficult.

But what I want to know is basically “which observable preset characteristics (the things we can control) yield the lowest CpR?“, and “how confident can I be in the relative differences in the CpR between these features?“.

It’s ~OK that some ad features may be more easily matched to amenable audiences, and thus we are  not learning ‘which performs better on a single group’. I might ~expect that whatever works best now, for whatever reason, will work better in the future.

I am thinking something like a linear (or log-linear) regression where
the CpR for the segment is the outcome
this is seen as a mean across observations, thus ~weighted by the size of the segment (number of impressions)
possibly a mixed model, allowing for some random effects? (But I’m not great at that).

-->
::: {.callout-note collapse="true"}
## Modeling goals/discussion/todo

1. Present mean/Bayesian updating: 

- Overall cost/result 
   - and for different audiences
    - random effects?
- present posterior distribution and intervals 

2. Model (multivariable regression): 

Cost/result as a function of 

- campaign (i.e., time of launch)
- message
- video
- audience
- gender
- age

Linear and log-linear

Random effects (how?)

Present a set of estimates for the mean and 80% CI for cost/result for key groups

::: 


 
```{r}

summarise_stuff <- function(df) {
  df %>%
     summarise(
      amount_spent_usd = sum(amount_spent_usd), 
      impressions=sum(impressions),
      link_clicks = sum(link_clicks, na.rm = TRUE),
      results = sum(results, na.rm = TRUE),
      cost_per_impression = amount_spent_usd/impressions,
      cost_per_click = amount_spent_usd/link_clicks,
      results = ifelse(is.na(results), 0, results ),
      results_per_100usd = results/(amount_spent_usd/100),
      results_per_1k_impressions = results*1000/impressions) 
}

model_data_0 <- gg_campaign_by_ad_by_text_age_gender %>%
  filter(audience!="Retargeting") %>%
  ungroup() %>%
    group_by(video_theme, text_treat, audience) %>% #starts, 
    #filter(impressions>200) %>%
    summarise_stuff() %>%
  ungroup() %>% 
  as.tibble() %>% 
  mutate(
    across(c(video_theme, text_treat, audience), #starts, 
      as.factor )
    )

model_data_start <- gg_campaign_by_ad_by_text_age_gender %>%
  filter(audience!="Retargeting") %>%
  ungroup() %>%
    group_by(video_theme, text_treat, audience, starts) %>% #starts, 
    #filter(impressions>200) %>%
        summarise_stuff() %>%
  ungroup() %>% 
  as.tibble() %>% 
  mutate(
    across(c(video_theme, text_treat, audience, starts), #starts, 
      as.factor )
    )

model_data <- gg_campaign_by_ad_by_text_age_gender %>%
    filter(audience!="Retargeting") %>%
  ungroup() %>%
    group_by(video_theme, text_treat, audience, gender, agetrin) %>% #starts, 
    #filter(impressions>200) %>%
        summarise_stuff() %>%
  ungroup() %>% 
  as.tibble() %>% 
  mutate(
    across(c(video_theme, text_treat, audience, gender, agetrin), #starts, 
      as.factor )
    )

Rp100usd_vid_text_audience0 <- model_data_0 %>%  
  lm(
    results_per_100usd ~ 1 + video_theme + text_treat + audience,
    data = ., 
    weights = impressions) 
  

Rp100usd_vid_text_audience_starts <- model_data_start %>%  
  lm(
    results_per_100usd ~ 1 + starts + video_theme + text_treat + audience,
    data = ., 
    weights = impressions) 
  

Rp100usd_vid_text_audience_demo <- model_data %>%  
  lm(
    results_per_100usd ~ 1 + video_theme + text_treat + audience + gender + agetrin,
    data = ., 
    weights = impressions) 

#Do NOT do this: Rp100usd_vid_text_audience0$df.residual <- sum(model_data_0$impressions) - length(coef(Rp100usd_vid_text_audience0))

huxtable::huxreg(Rp100usd_vid_text_audience0, Rp100usd_vid_text_audience_starts, Rp100usd_vid_text_audience_demo)


```
 
 Note: the N (and R-sq?) values above are incorrect; these are the number of *groups* not the number of baseline observations.   
 
[^gwwc_gg-3]

[^gwwc_gg-3]: Followup of interest: What do the 'diminishing returns to scale' look like here? How to measure? Can we track results over time and see if the cost increased? (But targeting may also improve over time.) Roughly compare 'small' and 'large' campaigns? ... 

### Which pre-defined audience yields a Result at the lowest cost? How does this cost vary by audience? {.unnumbered}

- Refer to models/estimates above

### Which pre-defined audience yields the highest 'rate of Result'? How does this vary by audience? {.unnumbered}

Note, this is not the same as the previous question because some audiences are more *costly* to target on Facebook.

-  Re-run above models for 'results per impression' 

Important caveat: this does not tell us the effect 'on a particular group', because of FB's optimization algorithms.

Interactions/separate models for 'vary by audience'.


### Which *video* yields a Result at the highest rate/lowest cost? {.unnumbered}

- Refer to models/estimates above, coefficient on 'video'


[^gwwc_gg-4]

[^gwwc_gg-4]: Check: is this the same as 'which yields the highest rate of results, or is there a cost difference?'


#### How does the 'best video' vary by audience? {.unnumbered}

- Include interactions in above model
- Run model separately for each group (or allowing everything to interact) for robustness
- Also consider 'what did FB serve to each group', assuming it is optimizing.

#### Aggregating: Which *category* of videos yields a result at the highest rate/lowest cost? ("Facts", "Cause focus", or "Arguments, rich content") {.unnumbered}

- Above, pooling videos of similar type. (Random effects models?)

### Which *message* yields a Result at the highest rate/lowest cost? {.unnumbered}

[^gwwc_gg-5]

[^gwwc_gg-5]: Check: is this the same as 'which yields the highest rate of results, or is there a cost difference?'

**Sub-questions**

#### How does the 'best message' vary by audience? {.unnumbered}

::: {.callout-note collapse="true"}
## Other questions (less interest or less feasible)

-   Do the message treatments 'interact' with the video treatments (i.e., are their synergies and better pairings)?

-   Do some videos lead to higher click rates?

-   Do some videos lead to higher watch rates?
:::

### Defining the 'outcomes of interest' (as objects)

```{r targets, echo=FALSE, warning=FALSE}

#targets:
#bin_out <- c("d_don_1k", "d_don_10pct")

#num_out <- c('donation_c', 'don_av2_yr', 'l_don_c', "l_don_av_2yr", "don_share_inc_imp_bc5k", "donation_plan_c")
#targets <- c(bin_out, num_out)
#targets_short <- c("don_av2_yr", "don_share_inc_imp_bc5k", "d_don_1k")

#Note -- don_av2_yr is the right one for qpoisson as it already expresses things in exponents. l_don_av2_yr was the one to use in the loglinear model, which we are not emphasizing

#targets_short_names <- c("Log (Avg don +1)", "Don/Income", "Donated 1k+")
```

Next, we define the 'features of interest' and the 'controls'

```{r}

#features and controls
#geog <- c("where_live_cat", "city_cat")
#key_demog <- c("ln_age", "not_male_cat", "student_cat", "race_cat", geog)
#key_demog_n <- c("age_d2sd", "not_male_cat", "student_cat", "race_cat", geog)

```

## Analysis and visuals

[^gwwc_gg-6]

[^gwwc_gg-6]: Moved from Erin's work

```{r}

##gwwc_vid_results$DV_costadj)
##gwwc_vid_results$DV)
##gwwc_vid_results$ave.cost.impr)

```

Data summary

::: {.alert .alert-secondary}
Below, a few data summary bits (from Erin). I commented most of it out and will redo it using an automated and formatted 'key summary statistics' package.

I may also present the data in a dashboard for self-service.
:::

```{r}

#datatable(gwwc_vid_results)
```



```{r}

gwwc_vid_results %>% group_by(Age) %>% summarise(n=n()) %>% .kable() %>%  .kable_styling()
gwwc_vid_results %>% group_by(Gender) %>% summarise(n=n())  %>% .kable() %>%  .kable_styling()

#print(gwwc_vid_results %>% group_by(Gender,Age) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=40)
#print(gwwc_vid_results %>% group_by(Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=41)
#print(gwwc_vid_results %>% group_by(Campaign.name,Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=100)

```

```{r}

### CHART DATA

#print(gwwc_vid_results %>% group_by(audience,media) %>% #summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)

```

## PLOTS

```{r common_plot_options}

#Plot options in common

limits <- aes(ymax = mean_dv + (se_dv), ymin = mean_dv - (se_dv))
dodge <- position_dodge(width = 0.9)

vid_types <-
  c("factual short",
    "animal",
    "climate",
    "factual long",
    "hypercube",
    "poverty")

gg_gg_options <- list(geom_bar(stat = 'identity', position=dodge),
  geom_errorbar(limits, position=dodge,  width=0.05),
  jtools::theme_apa(),
  theme(legend.position="none"),
  geom_text(aes(label = paste("$",mean_dv %>% round(.,2)), y=5), position = position_dodge(.9), size=4, color="white"),
  theme(text=element_text(size=10))
)

grpsumgg <- function(df, gvar, var) {
  df %>%
  group_by({{gvar}}) %>%
  summarise(mean_dv = mean({{var}}, na.rm=TRUE),
            se_dv = sd({{var}}, na.rm=TRUE)/sqrt(n()))
}

```

### PLOT: Cost adjusted DV (results) by video

```{r gwwc_vid_results_tab}

gwwc_vid_results %>%
    filter(ave.cost.impr > 0) %>%
    group_by(media) %>%
    summarise(
    `Results per $ (adjusted)` = mean(DV_costadj),
    SE = std.error(DV_costadj),
    n = n()
  ) %>%
  arrange(-`Results per $ (adjusted)`) %>%
  .kable(digits = 3) %>%
  .kable_styling()

```

```{r gwwc_vid_results_plot}

gwwc_vid_results %>%
  grpsumgg(media, DV_costadj) %>%
  ggplot(aes(x=media, y=mean_dv)) +
  gg_gg_options +
  geom_bar(stat='identity',fill="#0072B2", position=dodge) +
  ylab('Results/$ spent') +
  xlab('Video') +
  ggtitle('Results/$ spent by Video') +
  scale_y_continuous(limits = c(0,.2),  breaks=seq(0,.2, by=.05)) +
  scale_x_discrete(labels=vid_types)

```

### PLOT: DV (Results) by video

```{r}
gwwc_vid_results %>% filter(ave.cost.impr > 0) %>%
  group_by(media) %>%
  summarise(
  results = 100 * mean(DV),
  SE = 100 * std.error(DV),
  n = n()
) %>%
  .kable(digits = 2) %>%
  .kable_styling()

gwwc_vid_results %>%
   grpsumgg(media, DV) %>%
  ggplot(aes(x=media, y=mean_dv)) +
  geom_bar(stat='identity', fill="#0072B2",position=dodge) +
  ylab('Results (%)')+
  xlab('Video')+
  ggtitle('Results by Video')+
  scale_x_discrete(labels=vid_types)



```
