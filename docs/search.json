[
  {
    "objectID": "chapters/tlycs_input_simple_analysis.html",
    "href": "chapters/tlycs_input_simple_analysis.html",
    "title": "5  TLYCS Portland trial: background, data input, brief report",
    "section": "",
    "text": "In December 2021, TLYCS ran a YouTube advertising campaign in single city, involving ‘donation advice’. The top 10% household income households were targeted with (one of) three categories of videos. One of the ultimate goals was to get households to sign up for a ‘concierge’ personal donor advising service.\nThe details are presented in our gitbook HERE\n\n\nThere were very few signups for the concierge advising service. (About 16 in December 2021 , only 1 from Portland.)\nWe consider a ‘difference in difference’, to compare the year-on-year changes in visits to TLYCS during this period for Portland vs other comparison cities.\nThis comparison yields a ‘middle estimate cost’ of $37.7 per additional visitor to the site. This seems relatively expensive. We could look into this further to build a more careful model and consider statistical bounds, if such work is warranted."
  },
  {
    "objectID": "chapters/tlycs_input_simple_analysis.html#capturing-data",
    "href": "chapters/tlycs_input_simple_analysis.html#capturing-data",
    "title": "5  TLYCS Portland trial: background, data input, brief report",
    "section": "5.2 Capturing data",
    "text": "5.2 Capturing data\n\n\n\n\n\n\nGoogle Analytics capture\n\n\n\n\n\nI (David Reinstein) did a manual ‘create report and download’ in TLYCS’s Google Analytics, basically as described here.\nThe Google Analytics report and it’s parameters can be accessed here, if you have access.\n\n\n\n\n\n\n\n\n\nGoogle Analytics report: parameters and data storage\n\n\n\n\n\nReport:\n\n3-31 December 2021 vs prior year, same dates\nAll North American cities with 1 or more user\nCounts: Users, sessions, certain types of conversions (see below)\n\nI downloaded this as an Excel spreadsheet to the private eamt_actual_data repo:\neamt_actual_data/tlycs/tlycs_dec_2021_vs_2020_by_city_n_america.xlsx"
  },
  {
    "objectID": "chapters/tlycs_input_simple_analysis.html#input-and-clean-data",
    "href": "chapters/tlycs_input_simple_analysis.html#input-and-clean-data",
    "title": "5  TLYCS Portland trial: background, data input, brief report",
    "section": "5.3 Input and clean data",
    "text": "5.3 Input and clean data\n1\n\n\nReading TLYCS trial data\n#tl21 <- read_excel(here::here(\"data_do_not_commit\", \"tlycs\", \"tlycs_dec_2021_vs_2020_by_city_n_america.xlsx\"), sheet = \"Dataset1\") #this should have worked?\n\n#tl21 <- readxl::read_excel(\"~/githubs/eamt_actual_data/tlycs/tlycs_dec_2021_vs_2020_by_city_n_america.xlsx\",  sheet = \"Dataset1\")\n\n\ntl21 <- readxl::read_excel(here::here(\"tlycs_portland_trial_2021\", \"tlycs_dec_2021_vs_2020_by_city_n_america.xlsx\"),  sheet = \"Dataset1\") %>%\n  dplyr::as_tibble()\n\n\nWe add companion data on US city sizes.2\n\n\ninput cities data\nus_cities_pop <- read.csv(here::here(\"tlycs_portland_trial_2021\", \"uscities_pop.csv\")) %>%\n  dplyr::select(name, rank, usps, pop2022) %>%\n  mutate(name = if_else(name==\"New York City\", \"New York\", name)) %>%\n  as_tibble()\n\ntl21 <- left_join(\n  tl21,\n  us_cities_pop,\n by = c(\"City\" = \"name\") ) %>%\n  mutate(\n    pop_gt250k = pop2022>250000 | str_det(City, \"Windsor|Oshawa|Halifax|Victoria|Kitchener|Hamilton|Quebec|Winnipeg|Ottawa|Edmonton|Calgary|Vancouver|Montreal|Toronto\")\n  ) %>%\n  dplyr::select(City, `Date Range`, Users, pop2022, pop_gt250k, everything())\n\n\n\n\n\n\n\n\nMore coding\n\n\n\n\n\nBelow, we:\n\nChoose the ‘largest Portland’ as this must be Portland, OR\nDrop other city duplicates to enable lagging/leading more easily\nCreates lags and ‘differences across years’ features.\n\n\n\n\n\n\nCreate ‘year’ feature\ntl21 <- tl21 %>% mutate(\n  year = case_when(\n    str_detect(`Date Range`, \"2021\") == TRUE ~ 2021,\n    str_detect(`Date Range`, \"2020\") == TRUE ~ 2020\n  )\n)\n\n\n\n\nTable of ‘Portland’ cities\n# Re-labels the 'correct' Portland (we think), as it's a common city name.^[And there are two other 'Portlands', each with a small number of sessions]\n\ntl21 %>%\n  filter(City==\"Portland\") %>%\n  dplyr::select(City, year, Users, pop2022, pop_gt250k) %>%\n  .kable() %>%\n  .kable_styling\n\n\n\n\n \n  \n    City \n    year \n    Users \n    pop2022 \n    pop_gt250k \n  \n \n\n  \n    Portland \n    2,021 \n    1 \n    666,453 \n    TRUE \n  \n  \n    Portland \n    2,020 \n    0 \n    666,453 \n    TRUE \n  \n  \n    Portland \n    2,021 \n    8 \n    666,453 \n    TRUE \n  \n  \n    Portland \n    2,020 \n    6 \n    666,453 \n    TRUE \n  \n  \n    Portland \n    2,021 \n    306 \n    666,453 \n    TRUE \n  \n  \n    Portland \n    2,020 \n    144 \n    666,453 \n    TRUE \n  \n\n\n\n\n\n\n\nrelable portland\n#Presumably the largest one is Portland, Oregon, and we'll re-label it as such.\n\ntl21 <- tl21 %>%\n  mutate(\n    City = case_when(City==\"Portland\" & Users>20 ~ \"Portland_OR\",\n              City==\"Portland\" ~ \"Other_Portland\",\n              TRUE ~ City)\n  )\n\n\n\n\ndrop_dup_cities\ntl21 <- tl21 %>%\n  rowwise() %>%\n   mutate(key = paste(sort(c(City, year)), collapse=\"\")) %>%\n   distinct(key, .keep_all=T) %>%\n   dplyr::select(-key) %>%\n  ungroup\n\n\n\n\nCreate lag and difference features\ntlag <- function(x, n = 1L, time) {\n  index <- match(time - n, time, incomparables = NA)\n  x[index]\n}\n\ntl21 <- tl21 %>%\n  group_by(City) %>%\n  mutate(\n  lag_users = tlag(Users, 1, time = year),\n  diff_users = Users-lag_users,\n    prop_diff_users = diff_users/lag_users\n    ) %>%\n  ungroup()"
  },
  {
    "objectID": "chapters/tlycs_input_simple_analysis.html#casualsimple-uptick-analysis",
    "href": "chapters/tlycs_input_simple_analysis.html#casualsimple-uptick-analysis",
    "title": "5  TLYCS Portland trial: background, data input, brief report",
    "section": "5.4 Casual/simple ‘uptick’ analysis",
    "text": "5.4 Casual/simple ‘uptick’ analysis\nBelow, for the comparable periods in 2020 and 2021, we give…\n…the total numbers of cities in the sample, the share with a positive number of user clicks, and the mean, median, 80th quantile, and standard deviation of the number of clicks.\n… For a few subsets\n… First for unique user visits, and then for total numbers of sessions.\n\n\ntabs of session by year\ntl21 %>% sumtab(Users, year, caption=\"All N. Amer. cities\")\n\n\n\n\nAll N. Amer. cities\n \n  \n    year \n    N \n    share > 0 \n    Mean \n    Median \n    P80 \n    Std.dev. \n  \n \n\n  \n    2020 \n    3006 \n    0.6 \n    9.38 \n    1 \n    4 \n    (296.34) \n  \n  \n    2021 \n    3006 \n    1.0 \n    13.48 \n    2 \n    4 \n    (425.33) \n  \n\n\n\n\n\ntabs of session by year\ntl21 %>% filter(!City==\"Portland_OR\") %>% sumtab(Users, year, caption=\"N. Amer. Cities other than Portland\")\n\n\n\n\nN. Amer. Cities other than Portland\n \n  \n    year \n    N \n    share > 0 \n    Mean \n    Median \n    P80 \n    Std.dev. \n  \n \n\n  \n    2020 \n    3004 \n    0.6 \n    3.94 \n    1 \n    4 \n    (21.01) \n  \n  \n    2021 \n    3004 \n    1.0 \n    5.64 \n    2 \n    4 \n    (30.79) \n  \n\n\n\n\n\ntabs of session by year\ntl21 %>% filter(pop2022>250000) %>% sumtab(Users, year, caption=\"All N. Amer. Cities with pop. > 250k\") #Fix -- filter on over 20 users for 2020 ONLY]\n\n\n\n\nAll N. Amer. Cities with pop. > 250k\n \n  \n    year \n    N \n    share > 0 \n    Mean \n    Median \n    P80 \n    Std.dev. \n  \n \n\n  \n    2020 \n    92 \n    0.848 \n    47.46 \n    17.0 \n    47.0 \n    (99.21) \n  \n  \n    2021 \n    92 \n    1.000 \n    70.04 \n    19.5 \n    80.2 \n    (147.88) \n  \n\n\n\n\n\ntabs of session by year\ntl21 %>% sumtab(Sessions, year, caption=\"Sessions by year, all\")\n\n\n\n\nSessions by year, all\n \n  \n    year \n    N \n    share > 0 \n    Mean \n    Median \n    P80 \n    Std.dev. \n  \n \n\n  \n    2020 \n    3006 \n    0.6 \n    11.75 \n    1 \n    4 \n    (370.61) \n  \n  \n    2021 \n    3006 \n    1.0 \n    16.80 \n    2 \n    5 \n    (528.67) \n  \n\n\n\n\n\nNote that all measures generally show an increase from year to year.\n\n\nUpticks for Oregon, other\nOR_users_21 <- tl21 %>% dplyr::filter(City==\"Portland_OR\" & year==2021) %>% dplyr::select('Users') %>% pull()\n\nOR_users_20 <- tl21 %>% dplyr::filter(City==\"Portland_OR\" & year==2020) %>% dplyr::select('Users') %>% pull()\n\nOR_uptick <- OR_users_21 - OR_users_20\n\nnonOR  <- tl21 %>% dplyr::filter(City!=\"Portland_OR\") %>% dplyr::select('Users', year)\nnonOR_gt250k  <- tl21 %>% dplyr::filter(pop_gt250k==TRUE) %>% dplyr::select('Users', year)\n\nnonOR_users_21 <- mean(nonOR$Users[nonOR$year==2021])\nnonOR_users_20 <- mean(nonOR$Users[nonOR$year==2020])\n\nnonOR_uptick <- (nonOR_users_21 - nonOR_users_20)/nonOR_users_20\n\nnonOR_gt250k_users_21 <- mean(nonOR_gt250k$Users[nonOR_gt250k$year==2021])\nnonOR_gt250k_users_20 <- mean(nonOR_gt250k$Users[nonOR_gt250k$year==2020])\n\nnonOR_gt250k_uptick <- (nonOR_gt250k_users_21 - nonOR_gt250k_users_20)/nonOR_gt250k_users_20\n\n\n\nBounding : Maximum impact/minimum cost (subject to random variation)\n(This duplicates the  hand-calculated results in Gitbook HERE)\n3\nWe have a….\n\nlower bound on cost of $13.07 per user ($10.28 per visit) if ‘all visits were generated by the ad’, and\na somewhat more reasonable $24.69 cost per user if Portland was the ‘same as last year’. But it seems most reasonable to allow Portland to have similar trends as other cities.\n\n\n\nDifference in Differences comparison to other cities\nGuiding assumptions:\n\nthe cities used are fairly representative\n‘uptick as a percentage’ is unrelated to city size/visits last year\nall the cities in the comparison group are ‘informative to the counterfactual’ in proportion to their total number of sessions.4\n\n\n\nThus\n112.5% visits uptick (Year on Year) for Portland in 2020\nFor ‘all North American cities other than Portland (with greater than 250,000 people )’:\nThe average is 46.5 users in the 2020 period and 64.5 users in the 2021 period, an uptick of 64.5 - 46.5)/46.5 = about 38.8%. 5\n38.8% uptick \\(\\times\\) 144 = 55.9 ‘counterfactual uptick’ in users for Portland\n162 -55.9 = 106 ‘uptick relative to counterfactual’\n\n\nCode\nor_uptick_vs_cfl_gt250 <- OR_users_21 - OR_users_20 - nonOR_gt250k_uptick*OR_users_20\n\n\nUSD 4000 /106 = $ 37.7 cost per user\nThis seems realistic at a first-pass.\n\n\n\n\nPlotting the ‘difference in difference’\nScatterplot of unique users by city, both time periods, US cities with 500k-1.5mill population, Portland highlighted\n\n\nusers_by_year\n(\n  users_by_year <-  tl21 %>%\n  filter(pop2022 >= 500000 & pop2022 < 1500000) %>%\nggplot() +\n  aes(x = pop2022, y = Users, label = City) +\n  geom_point(aes(shape = factor(year)), size=3, alpha=0.4) +\n  geom_path(aes(group = City)) +\n  geom_label(data = subset(tl21, City %in% c('Portland_OR','Boston','Seattle', 'San Francisco', 'Atlanta', 'San Diego', 'Indianapolis', 'Fort Worth', 'Sacramento', 'Denver', 'San Jose', 'Las Vegas') & year==2020), alpha  = 0.3, size =2.5) +\n  scale_x_continuous(trans='log10') +\n  theme_minimal()\n)\n\n\n\n\n\nusers_by_year\n#users_by_year %>%  plotly::ggplotly()\n\n\nPlotting increases in users by population…\n\n\nincrease_by_size\n(\n  increase_by_size <-  tl21 %>%\n      filter(pop2022 >= 500000 & pop2022 < 1500000 & year==2021) %>%\n   ggplot() +\n  aes(x = pop2022, y = diff_users, label = City) +\n  geom_point(size=3, alpha=0.4) +\n  geom_label(data = subset(tl21, City %in% c('Portland_OR','Boston','Seattle', 'San Francisco', 'Atlanta', 'San Diego', 'Indianapolis', 'Fort Worth', 'Sacramento', 'Denver', 'San Jose', 'Las Vegas')), alpha  = 0.3, size =2.5) +\n  scale_x_continuous(trans='log10') +\n  theme_minimal()\n)\n\n\n\n\n\nPlotting proportional increases in users by 2020 users…\n\n\nCode\n(\n  prop_increase_by_size <-  tl21 %>%\n      filter(pop2022 >= 500000 & pop2022 < 1500000 & year==2021 & lag_users>0) %>%\n   ggplot() +\n  aes(x = lag_users, y = prop_diff_users, label = City) +\n  geom_point(size=3, alpha=0.4) +\n    geom_smooth(method='lm') +\n  geom_text(hjust=0, vjust=0, alpha=.5) +\n  scale_x_continuous(trans='log10') +\n  theme_minimal() +\n    ggtitle(\"Mid-sized cities, proportional changes\") +\n     xlab(\"Users in 2020\") +\n     ylab(\"Proportional change in users\")\n)\n\n\n`geom_smooth()` using formula 'y ~ x'"
  },
  {
    "objectID": "chapters/tlycs_input_simple_analysis.html#next-steps-if-warranted",
    "href": "chapters/tlycs_input_simple_analysis.html#next-steps-if-warranted",
    "title": "5  TLYCS Portland trial: background, data input, brief report",
    "section": "5.5 Next steps, if warranted",
    "text": "5.5 Next steps, if warranted\nThe above comparisons are crude and have limitations:\n\nAll cities are weighted equally, no matter their size or similarity to Portland\nSome year-to-year idiosynchratic variation may be unrelated to trends or to the trial. We have not ‘quantified this uncertainty’\n\nIf we want a more precise estimate and careful CIs6 we can build an explicit model and simulation. But I want to know the value of precision here before I dig deeper."
  }
]