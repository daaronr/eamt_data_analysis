[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EA Market testing data analysis",
    "section": "",
    "text": "However, we’re not sure yet if and how it can be integrated with the https://app.gitbook.com/ content.↩︎\nNote: as this is Quarto and not Rmd, packages need to be loaded in every chapter. I’ll put these in code/shared_packages_code.R.↩︎"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html",
    "href": "chapters/oftw_upsell_input_first_analysis.html",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "",
    "text": "In December 2021, OftW sent out a sequence of emails to existing OftW pledgers/participants asking them for an additional donation. Ther e were two ‘treatment variants’; an emotional email and a standard impact-based email. The treatment was constant by individual (the same person always got emails with the same theme.\nThe details are presented in our (currently private) gitbook HERE and in the linked pre-registration (also on OSF)."
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#capturing-data",
    "href": "chapters/oftw_upsell_input_first_analysis.html#capturing-data",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.2 Capturing data",
    "text": "1.2 Capturing data\nKennan and Chloe captured the data and Metadata from\n\nThe OFTW database\nSurveyMonkey\n\nPutting this into the (private) Google sheet linked HERE\nWe added some metadata/explainers to that data.1"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#input-and-clean-data",
    "href": "chapters/oftw_upsell_input_first_analysis.html#input-and-clean-data",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.3 Input and clean data",
    "text": "1.3 Input and clean data\nWe input the sheets from the external Google sheet location (access required)…\n\n\nCode\ngs4_auth(scope = \"https://www.googleapis.com/auth/drive\")\ndrive_auth(token = gs4_token())\n\n#Mailchimp data \n\noftw_21_22_mc <- read_sheet(\"https://docs.google.com/spreadsheets/d/1iUKXkEqoadBgtUG_epBzUzCgA_J5mdWWstcXtpAdNJs/edit#gid=521638649\", \n  sheet=\"Raw data (Mailchimp)\")  %>% \n  select(-`Treatment group`) %>%  #remove an un-useful repeated name column \n    mutate(`Treatment Group` = purrr::map_chr(`Treatment Group`, ~ .[[1]])) %>%\n  select(`Email Address`, `Email Date`, `Treatment Group`, Opens, `Donate link clicks`, everything()) %>% #Most relevant features organized first\n  arrange(`Email Address`)\n\n\n#later: remove features brought in from OFTW database, reconstruct it\n\noftw_21_22_mc %>% names() %>% paste(collapse=\", \")\n\n\n[1] \"Email Address, Email Date, Treatment Group, Opens, Donate link clicks, sheet_descriptor, First Name, Last Name, Email Number, Class Year, Donor status, Total Given, Donation amount, Donation frequency, Start string, Platform, Portfolio string, Class lead, Impact 1, Impact 2, Impact 3, Employer, Pledge string, School string, Pledge year, Cancellation Type, Donation Amount String, OFTW matching, OFTW match amount, Corporate match amount, Bonuses announced, Post-bonus contact date, Email Preferences, Start Date, Lives Saved, Member Rating, Record rank, Total Giving Season contributions, Total Giving Season contribution amount\"\n\n\nCode\n#...input descriptors for the above (do this later from \"doc: ...Mailchimp\" sheet\n\n\n\n\nCode\n#Donations data (and OftW database info)\n\noftw_21_22_db_don <- read_sheet(\n  \"https://docs.google.com/spreadsheets/d/1iUKXkEqoadBgtUG_epBzUzCgA_J5mdWWstcXtpAdNJs/edit#gid=521638649\", \n  sheet=\"Giving Season contributions (BigQuery)\") %>% \n  mutate(`Treatment group` = purrr::map_chr(`Treatment group`, ~ .[[1]])) %>%\n    select(`email`, `primary_email`, `donation_date`, `Net_Contribution_Amount_USD`, `payment_platform`, everything()) %>%  #Most relevant features organized first\n  filter(donation_date>=as.Date(\"2021-11-15\")) # At least for now, remove pre-treatment donation data\n\noftw_21_22_db_don %>% names() %>% paste(collapse=\", \")\n\n\n[1] \"email, primary_email, donation_date, Net_Contribution_Amount_USD, payment_platform, Treatment group, Number of email opens, oftw_partner, school, chapter_type, portfolio, contribution_frequency, pledge_date, pledge_start_date, pledge_end_date, donor_status, cancellation_type, pledge_amount, pledge_contribution_frequency, x\"\n\n\n\n\n1.3.1 Labeling and cleaning\nThe code …\n…makes names snake_case, using original names as labels…\n\n\nCode\nlabelled::var_label(oftw_21_22_mc) <- names(oftw_21_22_mc) \nnames(oftw_21_22_mc) <- snakecase::to_snake_case(names(oftw_21_22_mc)) \n\nlabelled::var_label(oftw_21_22_db_don) <- names(oftw_21_22_db_don) \nnames(oftw_21_22_db_don) <- snakecase::to_snake_case(names(oftw_21_22_db_don)) \n\n\n\n…and anonymizes the data, hashing anything with the chance of being identifying\n\n\nCode\nsalty_hash <- function(x) {\n  salt(.seed = 42, x) %>% hash(.algo = \"crc32\")\n}\n\noftw_21_22_mc <- oftw_21_22_mc %>%\n  dplyr::select(-first_name, -last_name) %>%\n    mutate(across(c(email_address,  employer, school_string), salty_hash))\n\n  \noftw_21_22_db_don <- oftw_21_22_db_don %>%\n      mutate(across(c(primary_email, email, school), salty_hash))\n\n\nRoll up to 1 per person; summarize and pivot_wider\n\n\nCode\noutcomes_base_mc <- c(\"opens\", \"donate_link_clicks\")\n\n\noftw_21_22_mc_wide <- oftw_21_22_mc %>%\n  mutate(treat_emotion = case_when(\n    treatment_group == \"1.000000\" ~ 0,\n    treatment_group == \"2.000000\" ~ 1\n  )) %>%\n  group_by(email_address) %>%\n  mutate(across(all_of(outcomes_base_mc), sum, .names = \"{.col}_tot\")) %>%\n  tidyr::pivot_wider(names_from = email_number,\n    values_from = c(\"opens\", \"donate_link_clicks\")) %>%\n  mutate(d_click_don_link = donate_link_clicks_tot > 0) %>%\n  arrange(email_address) %>%\n  filter(row_number() == 1)\n\noftw_21_22_db_don <- oftw_21_22_db_don %>%\n  ungroup() %>%\n  group_by(email) %>%\n  mutate(\n    don_tot = sum(net_contribution_amount_usd),\n    num_don = n(),\n    d_don = num_don > 0,\n    don_tot_ot = sum(net_contribution_amount_usd[contribution_frequency ==\n        \"One-time\"]),\n    num_don_ot = sum(contribution_frequency == \"One-time\"),\n    d_don_ot = num_don_ot > 0,\n    #WAIT THIS IS NOT WIDE DATA -- don't interpret it as 'number of individuals'\n    don_tot_ss = sum(net_contribution_amount_usd[payment_platform == \"Squarespace\"]),\n    num_don_ss = sum(payment_platform == \"Squarespace\"),\n    d_don_ss = num_don_ss > 0,\n  )\n\n\noftw_21_22_db_don_persons <- oftw_21_22_db_don %>%  \n  arrange(email) %>%\n  filter(row_number()==1)     %>%\nmutate(\n      treat_emotion = case_when(\n        treatment_group==\"1.000000\" ~ 0,\n        treatment_group == \"2.000000\" ~ 1)\n    ) \n\n\noftw_mc_db <- power_full_join(oftw_21_22_mc_wide,\n   oftw_21_22_db_don_persons,  by = c(\"email_address\" = \"email\"), conflict = coalesce_xy) %>%\n   mutate(across(starts_with(\"d_don\"), ~replace(., is.na(.), 0)), #make it a 0 if it's not in the donation database\n   d_open= if_else(!is.na(treat_emotion),1,0)\n  )\n\n\noftw_mc_db_openers <- oftw_mc_db %>% \n  filter(!is.na(treat_emotion))\n\n# oftw_21_22_db_don_wide <- oftw_21_22_db_don %>%\n#   select(email, donation_date, net_contribution_amount_usd, payment_platform) %>% \n#    group_by(email) %>%\n#    mutate(row = row_number()) %>%\n#       tidyr::pivot_wider(names_from = row, values_from = c(\"donation_date\", \"net_contribution_amount_usd\"))\n\n\nPrelim results ::: {.cell}\n\nCode\noftw_mc_db %>% tabyl(treat_emotion, d_don)\n\n\n treat_emotion    0   1\n             0 1139 273\n             1  968 231\n            NA    0 395\n\n\nCode\noftw_mc_db %>% tabyl(treat_emotion, d_don_ss)\n\n\n treat_emotion    0 1\n             0 1404 8\n             1 1190 9\n            NA  391 4\n\n\nCode\noftw_21_22_db_don_persons %>% tabyl(treat_emotion, d_don_ot)\n\n\n treat_emotion FALSE TRUE NA_\n             0   248   15  10\n             1   215   12   4\n            NA   328   59   8\n\n\nCode\n#todo: simple statistical measures along with this\n\n:::\n\n\n1.3.2 Constructing outcome measures, especially ‘donations likely driven by email’\n\nDonations (presence, count, amounts) in giving seasons, 1 row per user (with treatment etc.)\n\n\noverall\nnon-regular\n‘likely from email’\n\nare in Giving Season contributions (BigQuery)\n\nsubset for payment platform = squarespace (unlikely to come from any other checkout page)\nemail as primary key, link to Raw Data (mailchimp), filter on ‘Donate link clicks`>0 (note that one needs aggregating by donor because it is ’per email’)\n\n\nGiving season donations ..\n\nGiving Season contributions (BigQuery), sum donation_date Net_Contribution_Amount_USD with filters for one-time etc\nCan check against fields ‘Total Giving Season contributions Total Giving Season contribution amount’\n\n\n\nCode\n#list/matrix of rates for later use\n\noc_mat <- oftw_mc_db %>% \n  mutate(d_open=n()) %>% \n  group_by(treat_emotion) %>% \n  dplyr::summarise(across(starts_with(\"d_\"), ~sum(.x, na.rm = TRUE), .names = \"tot_{.col}\"))\n\noc_mat_r <- oc_mat %>% filter(!is.na(treat_emotion)) #where treatment observed \n\nassigned_emails <- c(2000, 2000) #I was told that about 4000 emails were sent, 2000 to each group"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#descriptives-and-exploratory-analysis",
    "href": "chapters/oftw_upsell_input_first_analysis.html#descriptives-and-exploratory-analysis",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.4 Descriptives and exploratory analysis",
    "text": "1.4 Descriptives and exploratory analysis\nNotes:2\n\n1.4.1 Donation and outcome summary statistics, by treatment"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#basic-tests-donation-incidence-and-amounts",
    "href": "chapters/oftw_upsell_input_first_analysis.html#basic-tests-donation-incidence-and-amounts",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.5 Basic tests: Donation incidence and amounts",
    "text": "1.5 Basic tests: Donation incidence and amounts\n(See preregistration – go through preregistered tests one at a time. Note that given the observed conversion rates I do not expect any ‘significant differences’.)"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#basic-tests-clicks-and-retention-outcomes",
    "href": "chapters/oftw_upsell_input_first_analysis.html#basic-tests-clicks-and-retention-outcomes",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.6 Basic tests: Clicks and retention outcomes",
    "text": "1.6 Basic tests: Clicks and retention outcomes\nI’m following the approach discussed in the ‘RP methods discussion’ under “Significance and equivalence testing” with randomization inference/simulation; building to Bayes\nWe see a ‘small difference’ between treatment groups and it is ‘not significant in standard tests’ (tests not shown here yet). But can we put meaningful bounds on this? Can we statistically ‘rule out large effects’?\n(This parallels the analysis done in HERE, which includes some further explanation of the methods)\n\n\n\n1.6.1 Difference between two binomial random variables: Bayesian binomial test\n\n\nCode\n#would need to generate 'fill in data' if we want to use bayesAB, which requires actual vectors\n\n#add blank rows for 'assigned'\n\nblank_impact <- as_tibble(matrix(NA, nrow = assigned_emails[1]- oc_mat_r$tot_d_open[1], ncol = NCOL(oftw_mc_db)))\n\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0.\nUsing compatibility `.name_repair`.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\n\nCode\nnames(blank_impact) <- names(oftw_mc_db)\n\nblank_impact %<>% \n  mutate(across(starts_with(\"d_\"), ~ifelse(is.na(.), 0, 0)),\n    treat_emotion=0)\n  \nblank_emotion <- as_tibble(matrix(NA, nrow = assigned_emails[1]- oc_mat_r$tot_d_open[2], ncol = NCOL(oftw_mc_db)))\nnames(blank_emotion) <- names(oftw_mc_db)\n\nblank_emotion %<>% \n  mutate(across(starts_with(\"d_\"), ~ifelse(is.na(.), 0, 0)),\n    treat_emotion=1)\n\noftw_mc_db_assigned <- \n    bind_rows(oftw_mc_db, blank_impact, blank_emotion) %>%\n  filter(!is.na(treat_emotion))\n\noftw_mc_db_assigned %>% tabyl(treat_emotion)\n\n\n treat_emotion    n percent\n             0 2000     0.5\n             1 2000     0.5\n\n\nOpens by treatment:\n\n\nCode\n# Following r https://www.sumsar.net/blog/2014/06/bayesian-first-aid-prop-test/  \n# alt: http://frankportman.github.io/bayesAB/ \n\n\n#opens_by_treat_fit <- bayes.prop.test(oc_mat_r$tot_d_open, assigned_emails, cred.mass = 0.95) #here I highlight the 95% bounds because it's a strong effect!\n\n#plot(opens_by_treat_fit)\n\nunif_prior <- c('alpha' = 1, 'beta' = 1)\n \nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_open), 'beta' = sum(assigned_emails))\n\n\n#same with AB  package\n# Fit bernoulli test\nopens_by_treat_AB <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_open[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_open[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\nopens_by_treat_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_open[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_open[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(opens_by_treat_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(opens_by_treat_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\n#WTF -- I need to advance this by command prompt!?\n\n#AB1 <- bayesTest(oftw_21_22_db_don_persons$d_don_ot[trea], B_binom, priors = c('alpha' = 65, 'beta' = 200), n_samples = 1e5, distribution = 'bernoulli')\n\n\n\n\n‘Some donation’ by treatment (only for those who opened, otherwise donations are surely undercounted for Emotion treatment)\n\n\nCode\noftw_21_22_db_don_persons %>% tabyl(treat_emotion, d_don)\n\n\n treat_emotion TRUE\n             0  273\n             1  231\n            NA  395\n\n\nCode\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_don), 'beta' = sum(oc_mat_r$tot_d_open))\n\n(\n  don_by_treat_opened_fit <- bayes.prop.test(oc_mat_r$tot_d_don, oc_mat_r$tot_d_open, cred.mass = 0.80) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_don out of oc_mat_r$tot_d_open\nnumber of successes:   273,  231\nnumber of trials:     1412, 1199\nEstimated relative frequency of success [80% credible interval]:\n  Group 1: 0.19 [0.18, 0.21]\n  Group 2: 0.19 [0.18, 0.21]\nEstimated group difference (Group 1 - Group 2):\n  0 [-0.02, 0.02]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.515 and larger for Group 2 by a probability of 0.485 .\n\n\nCode\nplot(don_by_treat_opened_fit)\n\n\n\n\n\nCode\n#same with AB  package\n# Fit bernoulli test\ndon_by_treat_AB <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don[oftw_mc_db_openers$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_by_treat_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don[oftw_mc_db_openers$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(don_by_treat_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_by_treat_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nThus we put 80% probability on the difference between the donation rates being no more than (hard-coded) .023/.19 = 12% in either direction. Note that this is not terribly narrowly bounded.\n\n\nNext, for one-time donations only; again as a share of opens\n\n\nCode\n(\n  don_ot_by_treat_opened_fit <- bayes.prop.test(oc_mat_r$tot_d_don_ot, oc_mat_r$tot_d_open, cred.mass = 0.80) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_don_ot out of oc_mat_r$tot_d_open\nnumber of successes:    15,   12\nnumber of trials:     1412, 1199\nEstimated relative frequency of success [80% credible interval]:\n  Group 1: 0.011 [0.0075, 0.015]\n  Group 2: 0.011 [0.0068, 0.014]\nEstimated group difference (Group 1 - Group 2):\n  0 [-0.0048, 0.0056]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.55 and larger for Group 2 by a probability of 0.45 .\n\n\nCode\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_don_ot), 'beta' = sum(oc_mat_r$tot_d_open))\n\n#same with AB  package\n# Fit bernoulli test\ndon_ot_by_treat_AB <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don_ot[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don_ot[oftw_mc_db_openers$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_ot_by_treat_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don_ot[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don_ot[oftw_mc_db_openers$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(don_ot_by_treat_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_ot_by_treat_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\ndon_ot_by_treat_AB %>% summary(credInt=0.9)\n\n\nQuantiles of posteriors for A and B:\n\n$Probability\n$Probability$A\n         0%         25%         50%         75%        100% \n0.002702340 0.009300256 0.011076158 0.013056869 0.028481793 \n\n$Probability$B\n         0%         25%         50%         75%        100% \n0.002578133 0.008699817 0.010557270 0.012664164 0.031399003 \n\n\n--------------------------------------------\n\nP(A > B) by (0)%: \n\n$Probability\n[1] 0.5518\n\n--------------------------------------------\n\nCredible Interval on (A - B) / B for interval length(s) (0.9) : \n\n$Probability\n       5%       95% \n-0.434144  0.969118 \n\n--------------------------------------------\n\nPosterior Expected Loss for choosing A over B:\n\n$Probability\n[1] 0.1618676\n\n\nCode\ndon_ot_by_treat_AB_lift_int80 <- don_ot_by_treat_AB %>% summary(credInt=0.8)\n\n\ndon_ot_by_treat_AB_lift_int80_empir <- don_ot_by_treat_AB_empir %>% summary(credInt=0.8)\n\n\n80% credible intervals with the uniform prior for the ‘lift’ of Impact relative to Emotion are\n-0.351, 0.707\nand for the empirically informed (but symmetric prior):\n-0.234, 0.357\n(Hard-coded) Here there is just a trace of suggestive evidence that the emotion treatment performed worse. But even our 80% bounds are very wide.\n\n\nFor ‘Squarespace donations only’; these are the donations that plausibly came from the email. First as a share of opens for each treatment :\n\n\nCode\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_don_ss), 'beta' = sum(oc_mat_r$tot_d_open))\n\n\n(\n  don_ss_by_treat_opened_fit <- bayes.prop.test(oc_mat_r$tot_d_don_ss, oc_mat_r$tot_d_open, cred.mass = 0.80) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_don_ss out of oc_mat_r$tot_d_open\nnumber of successes:     8,    9\nnumber of trials:     1412, 1199\nEstimated relative frequency of success [80% credible interval]:\n  Group 1: 0.0062 [0.0033, 0.0085]\n  Group 2: 0.0081 [0.0047, 0.011]\nEstimated group difference (Group 1 - Group 2):\n  0 [-0.0062, 0.0023]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.282 and larger for Group 2 by a probability of 0.718 .\n\n\nCode\n#same with AB  package\n# Fit bernoulli test\ndon_ss_by_treat_AB <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don_ss[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don_ss[oftw_mc_db_openers$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_ss_by_treat_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don_ss[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don_ss[oftw_mc_db_openers$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\n\nplot(don_ss_by_treat_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_ss_by_treat_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\ndon_ss_by_treat_AB %>% summary(credInt=0.9)\n\n\nQuantiles of posteriors for A and B:\n\n$Probability\n$Probability$A\n          0%          25%          50%          75%         100% \n0.0009902386 0.0048437368 0.0061367516 0.0076340142 0.0191421384 \n\n$Probability$B\n         0%         25%         50%         75%        100% \n0.001462728 0.006437438 0.008042132 0.009891706 0.025724099 \n\n\n--------------------------------------------\n\nP(A > B) by (0)%: \n\n$Probability\n[1] 0.27906\n\n--------------------------------------------\n\nCredible Interval on (A - B) / B for interval length(s) (0.9) : \n\n$Probability\n        5%        95% \n-0.6515304  0.6391667 \n\n--------------------------------------------\n\nPosterior Expected Loss for choosing A over B:\n\n$Probability\n[1] 0.5346835\n\n\nCode\ndon_ss_by_treat_AB_lift_int80 <- don_ss_by_treat_AB %>% summary(credInt=0.8)\n\n\ndon_ss_by_treat_AB_lift_int80_empir <- don_ss_by_treat_AB_empir %>% summary(credInt=0.8)\n\n\n80% credible intervals with the uniform prior for the ‘lift’ of Impact relative to Emotion are\n-0.583, 0.383\nand for the empirically informed (but symmetric prior):\n-0.367, 0.304\n(Hard-coded) Again, even our 80% bounds are very wide.\n\n\nFinally, we consider the above as a share of total emails sent, allowing that ‘opens’ is non-random,\n… and also implicitly assuming that the only impact of these treatments could be on the Squarespace donations made by someone who did open the email.\n\n\nCode\n(\n  don_ss_by_treat_opened_fit_all <- bayes.prop.test(oc_mat_r$tot_d_don_ss, assigned_emails,\n    cred.mass = 0.80) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_don_ss out of assigned_emails\nnumber of successes:     8,    9\nnumber of trials:     2000, 2000\nEstimated relative frequency of success [80% credible interval]:\n  Group 1: 0.0043 [0.0025, 0.0062]\n  Group 2: 0.0049 [0.0029, 0.0067]\nEstimated group difference (Group 1 - Group 2):\n  0 [-0.0033, 0.0022]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.405 and larger for Group 2 by a probability of 0.595 .\n\n\nCode\n# \n#same with AB package\n\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_don_ss), 'beta' = sum(assigned_emails))\n\n\n# Fit Bernoulli test\ndon_ss_by_treat_all_AB <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_don_ss[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_don_ss[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_ss_by_treat_all_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_don_ss[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_don_ss[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(don_ss_by_treat_all_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_ss_by_treat_all_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\ndon_ss_by_treat_all_AB %>% summary(credInt=0.9)\n\n\nQuantiles of posteriors for A and B:\n\n$Probability\n$Probability$A\n          0%          25%          50%          75%         100% \n0.0006591401 0.0034229384 0.0043367467 0.0053948239 0.0139389081 \n\n$Probability$B\n          0%          25%          50%          75%         100% \n0.0008503472 0.0038633646 0.0048302873 0.0059443205 0.0137935894 \n\n\n--------------------------------------------\n\nP(A > B) by (0)%: \n\n$Probability\n[1] 0.4076\n\n--------------------------------------------\n\nCredible Interval on (A - B) / B for interval length(s) (0.9) : \n\n$Probability\n        5%        95% \n-0.5874267  0.9235146 \n\n--------------------------------------------\n\nPosterior Expected Loss for choosing A over B:\n\n$Probability\n[1] 0.353655\n\n\nCode\ndon_ss_by_treat_all_AB_lift_int80 <- don_ss_by_treat_all_AB %>% summary(credInt=0.8)\n\n\ndon_ss_by_treat_all_AB_lift_int80_empir <- don_ss_by_treat_all_AB_empir %>% summary(credInt=0.8)\n\n\n80% credible intervals with the uniform prior for the ‘lift’ of Impact relative to Emotion are\n\n\nCode\n op(don_ss_by_treat_all_AB_lift_int80$interval$Probability)\n\n\n     10%      90% \n\"-0.507\" \" 0.621\" \n\n\nand for the empirically informed (but symmetric prior):\n\n\nCode\nop(don_ss_by_treat_all_AB_lift_int80_empir$interval$Probability)\n\n\n     10%      90% \n\"-0.329\" \" 0.379\" \n\n\nHard-coded: Here there is almost no evidence in either direction. However, our 80% credible intervals remain wide.\n\n\nUnfortunately, this experiment proved to be underpowered, at least for the donation outcome.\nBut what about clicks on the ‘donation link’? This could arguably be seen as a measure of ‘desire and intention to donate’, and thus might be a more fine-grained and less noisy measure, improving our statistical power.\nSome quick crosstabs (here as a share of opens)\n\n\nCode\n(\n  donclick_by_treat <-  oftw_mc_db %>% \n  filter(!is.na(treat_emotion)) %>% \n  tabyl(treat_emotion, d_click_don_link) %>%\n    adorn_percentages(\"row\") %>%\n    adorn_pct_formatting() %>%\n    adorn_ns() %>%\n    adorn_title() %>% \n    kable(caption =\"Click on donation link by treatment; all opened emails\")  %>% \n  kable_styling(latex_options = \"scale_down\")\n)\n\n\n\nClick on donation link by treatment; all opened emails\n \n  \n     \n    d_click_don_link \n     \n     \n  \n \n\n  \n    treat_emotion \n    FALSE \n    TRUE \n    NA_ \n  \n  \n    0 \n    97.5% (1376) \n    2.1% (29) \n    0.5% (7) \n  \n  \n    1 \n    94.6% (1134) \n    4.7% (56) \n    0.8% (9) \n  \n\n\n\n\n\nIf this is our metric, it only seems fair to take into account ‘whether they opened the email’ as part of this effect. Thus, considering clicks as a share of total emails sent…\n\n\nCode\n(\n  click_don_by_treat_opened_fit <- bayes.prop.test(oc_mat_r$tot_d_click_don_link, assigned_emails,\n    cred.mass = 0.95) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_click_don_link out of assigned_emails\nnumber of successes:    29,   56\nnumber of trials:     2000, 2000\nEstimated relative frequency of success [95% credible interval]:\n  Group 1: 0.015 [0.0098, 0.020]\n  Group 2: 0.028 [0.021, 0.036]\nEstimated group difference (Group 1 - Group 2):\n  -0.01 [-0.023, -0.0046]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.002 and larger for Group 2 by a probability of 0.998 .\n\n\nCode\nplot(click_don_by_treat_opened_fit)\n\n\n\n\n\n\n\nCode\n#same with AB  package\n\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_click_don_link), 'beta' = sum(assigned_emails))\n\noftw_mc_db_assigned <- oftw_mc_db_assigned %>% dplyr::filter(!is.na(d_click_don_link))\n\n# Fit bernoulli test\ndon_click_by_treat_all_AB <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_click_don_link[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_click_don_link[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_click_by_treat_all_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_click_don_link[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_click_don_link[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(don_click_by_treat_all_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_click_by_treat_all_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\ndon_click_by_treat_all_AB %>% summary(credInt=0.9)\n\n\nQuantiles of posteriors for A and B:\n\n$Probability\n$Probability$A\n         0%         25%         50%         75%        100% \n0.005613925 0.013111564 0.014855512 0.016785020 0.030921759 \n\n$Probability$B\n        0%        25%        50%        75%       100% \n0.01457222 0.02602580 0.02846221 0.03102267 0.04764887 \n\n\n--------------------------------------------\n\nP(A > B) by (0)%: \n\n$Probability\n[1] 0.00155\n\n--------------------------------------------\n\nCredible Interval on (A - B) / B for interval length(s) (0.9) : \n\n$Probability\n        5%        95% \n-0.6412379 -0.2472723 \n\n--------------------------------------------\n\nPosterior Expected Loss for choosing A over B:\n\n$Probability\n[1] 0.9686057\n\n\nCode\ndon_click_by_treat_all_AB_lift_int80 <- don_click_by_treat_all_AB %>% summary(credInt=0.8)\n\ndon_click_by_treat_all_AB_lift_int80_empir <- don_click_by_treat_all_AB_empir %>% summary(credInt=0.8)\n\n\n80% credible intervals with the uniform prior for the ‘lift’ of Impact relative to Emotion are\n-0.610, -0.304\nand for the empirically informed (but symmetric prior):\n-0.3119, -0.0531\n(Hard-coded)\nThere is fairly strong evidence that the emotion email lead to a higher rate of clicks on the donation link; note that this even is in spite of the lower rate of email opens.\nThis suggests (IMO) it is worth testing this further.\n\n\n1.6.2 Redoing a bunch of stuff manually\nFirst, some building blocks;\nthe probability distribution over the absolute value of differences between two binomial random variables\nAdapting formulas from Stackexchange post discussion\nDefining their code for this function: ::: {.cell}\n\nCode\nmodBin <- dbinom #DR: I just do this renaming here for consistency with the rest ... but the modBin they defined was redundant as it's already built ins\n\ndiffBin <- function(z, n1, p1, n2, p2){\n\n  prob <- 0\n\n  if (z>=0){\n    for (i in 1:n1){\n      prob <- prob + modBin(i+z, n1, p1) * modBin(i, n2, p2)\n    }\n\n  }\n  else\n  {\n    for (i in 1:n2){\n      prob<-prob+modBin(i+z, n1, p1)*modBin(i, n2, p2)\n    }\n  }\n  return(prob)\n}\n\n:::\n\n\nWe generate an alternate version to cover ‘differences in one direction, i.e., but ’probability of observing (d1-d2)/(n1+n2) share more of d1 responses than d2 responses given sample sizes n1 and n2… over a range of true probabilities p1 and p2’\nthe probability distribution for differences between two binomial random variables in one direction\n\n\n\nFor the present case\nHard-coded notes…\n::: {.foldable}\n\n\n\nCode\nn1 <- oc_mat_r$tot_d_open[1]\nn2 <- oc_mat_r$tot_d_open[2]\nd1 <- oc_mat_r$tot_d_click_don_link[1]\nd2 <- oc_mat_r$tot_d_click_don_link[2]\nz <- d1-d2 #impact minus emotion\n\n\nComputation for a few ‘ad-hoc cases’ (later explore the space with vectors of values)\n\nSuppose truly equal incidence, at the mean level\n\n\n\nCode\np1 <- (d1+d2)/(n1+n2)\n\np2 <- p1\n\n(\n  db_0 <- diffBin(z, n1, p1, n2, p2)\n)\n\n\n[1] 3.963627e-05\n\n\nThis implies there is a 0.00396% chance of getting this exact difference of +-27 incidence(s) between the treatments (in one direction), if the true incidence rates were equal.\nLet’s plot this for a range of ‘incidence rate differences’ in this region. (Sorry, using the traditional plot, ggplot is better).\n\n\nCode\ns <- seq(-10*z, 10*z)\np<-sapply(s, function(z) diffBin(z, n1, p1, n2, p2))\nplot(s,p)\n\n\n\n\n\nWe see a large likelihood of values in the range of the +-27 difference observed, and a low likelihood of a difference of 10 or more in either direction.\n\n\n1.6.3 Adaptation: ‘of this magnitude or smaller’\n\n\nCode\nltmag_diffBin <- function(z, n1, p1, n2, p2){\n  prob <- 0\n  z_n <- -z #negative value\n\n  for (i in z_n:z){     #sum for all integer differences between observed value and its negative, inclusive\n    prob <- prob + diffBin(i, n1, p1, n2, p2)\n    }\n\n  return(prob)\n}\n\n\nNow, a similar computation as above, but for ‘a difference this big or smaller in magnitude’:\n\n\nCode\n  (\n    mag_db_0 <- ltmag_diffBin(z, n1, p1, n2, p2)\n  )\n\n\n[1] 0.9880585\n\n\nThis implies there is a 98.8% chance of getting a difference no larger than this one in magnitude of +/–27 incidences between the treatments if the true incidence rates were equal.\n\n\nAnd finally, what we were looking for: the chance of ‘a difference this small or smaller’ as a function of the true difference…\n(Think about: should we do this for ‘a difference in the same direction’ instead?)\nSet up an arbitrary vector of ‘true differences’ \nBelow, I plot\nY-axis: ’how likely would be a difference in donations ‘as small or smaller in magnitude’” than we see in the data against…\nX-axis: if the “true difference in incidence rates” were of these magnitudes\n(Note: this should cover ‘a difference in either direction’; the probability of a difference in the direction we do see is obviously somewhat smaller)\n\n\nCode\noptions(scipen=999)\n\nB <- c(1, 1.5, 2, 2.5, 3)\n\np1 <- rep((d1+d2)/(n1+n2), length(B))\np2 <- p1*B\n\n\nas.list(ltmag_diffBin(z, n1, p1, n2, p2)*100) %>% format(digits=3, scientific=FALSE)\n\n\n[1] \"98.8\"   \"93.2\"   \"33.6\"   \"1.81\"   \"0.0157\"\n\n\nCode\nprobmag <- ltmag_diffBin(z, n1, p1, n2, p2)\n\n\n#qplot(B, probmag, log  = \"x\", xlab = \"True relative incidence\", ylab =\"Prob. of difference this small\")\n\n(\n  probmag_plot <-\n    ggplot() +\n  aes(x=B, y=probmag) +\n  geom_point() +\n  scale_x_continuous(trans='log2') +\n    ylim(0,1) +\n    xlab(\"True relative incidence rate\") +\n    ylab(\"Prob. diff. as small as obsd\")\n\n)\n\n\n\n\n\nHard-coded takeaways 15 Dec 2021 :\nOur data is consistent with ‘no difference’ (of course) … but its also consistent with ‘a fairly large difference in incidence’\nE.g., even if one treatment truly lead to ‘twice as many donations as the other’, we still have a 20% chance of seeing a differences as small as the one we see (of 8 versus 6)\nWe can reasonably ‘rule out’ differences of maybe 2.5x or greater\nMain point: given the rareness of donations in this context, our sample size doesn’t let us make very strong conclusions in either directions … at least not yet. I hope that combined with other evidence, we will be able to infer more\n\n\n1.6.4 Quick redo assuming equal shares recieved each email, and treating ‘email reciepts as denom’\nApprox 4000 total emails sent?\nFor squarespace\n\n\nCode\nn1 <- 2000\nn2 <- 2000\nd1 <- 10\nd2 <- 9\nz <- d1-d2\n\nB <- c(1/3, 1/2.5, 1/2, 1/1.5, 1, 1.5, 2, 2.5, 3)\n\np1 <- rep((d1+d2)/(n1+n2), length(B))\np2 <- p1*B\n\n\n\n(\n    mag_db_0_ss <- ltmag_diffBin(z, n1, p1, n2, p2)\n  )\n\n\n[1] 0.071197896 0.100275616 0.147727269 0.220724651 0.272100392 0.154218060\n[7] 0.046306831 0.009174658 0.001345637\n\n\nCode\nprobmag_ss <- ltmag_diffBin(z, n1, p1, n2, p2)\n\n\n(\n  probmag_plot_ss <-\n    ggplot() +\n  aes(x=B, y=probmag_ss) +\n  geom_point() +\n  scale_x_continuous(trans='log2') +\n    ylim(0,.51) +\n    xlab(\"True relative incidence rate\") +\n    ylab(\"Prob. diff. as small as obsd\")\n\n)\n\n\n\n\n\nCode\n#note that it is not symmetric bc (I think) a very low incidence on one side makes particular large observed proportional differences more likely\n\n\nFor all one-time donations\n\n\nCode\nn1 <- 2000\nn2 <- 2000\nd1 <- 15\nd2 <- 12\nz <- d1-d2\n\nB <- c(1/3, 1/2.5, 1/2, 1/1.5, 1, 1.5, 2, 2.5, 3)\n\np1 <- rep((d1+d2)/(n1+n2), length(B))\np2 <- p1*B\n\n\n(\n    mag_db_0 <- ltmag_diffBin(z, n1, p1, n2, p2)\n  )\n\n\n[1] 0.0922168538 0.1395427545 0.2249330548 0.3745240308 0.5032003013\n[6] 0.2505329859 0.0521354769 0.0059810731 0.0004413855\n\n\n(the below halts on build, so I commented it out)\n\n\nCode\n(\n  probmag_plot_ot <-\n    ggplot() +\n  aes(x=B, y=probmag) +\n  geom_point() +\n  scale_x_continuous(trans='log2') +\n    ylim(0,.51) +\n    xlab(\"True relative incidence rate\") +\n    ylab(\"Prob. diff. as small as obsd\")\n\n)"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#demographics-and-interactions-to-do",
    "href": "chapters/oftw_upsell_input_first_analysis.html#demographics-and-interactions-to-do",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.7 Demographics and interactions (to do)",
    "text": "1.7 Demographics and interactions (to do)"
  },
  {
    "objectID": "chapters/tlycs_placeholder.html",
    "href": "chapters/tlycs_placeholder.html",
    "title": "2  The Life You Can Save trial: redacted (empty)",
    "section": "",
    "text": "As we have not (yet) been given explicit permission to share the details of the trial with The Life You Can Save, we are not hosting it in the public version"
  },
  {
    "objectID": "chapters/gwwc_gg.html",
    "href": "chapters/gwwc_gg.html",
    "title": "1  Giving What We Can: Giving guides",
    "section": "",
    "text": "Note\n\n\n\nNote: this presentation should align with a (forthcoming) EA Forum post, which will be linked here (and vice-versa)."
  },
  {
    "objectID": "chapters/gwwc_gg.html#capturing-data",
    "href": "chapters/gwwc_gg.html#capturing-data",
    "title": "3  Giving What We Can: Giving guides",
    "section": "3.2 Capturing data",
    "text": "3.2 Capturing data"
  },
  {
    "objectID": "chapters/gwwc_fb.html",
    "href": "chapters/gwwc_fb.html",
    "title": "4  Giving What We Can: Feb 22 Facebook Message Test",
    "section": "",
    "text": "Details in Gitbook HERE and Gdoc here\n\n\nCode\nknitr::include_url(\"https://effective-giving-marketing.gitbook.io/untitled/partner-organizations-and-trials/gwwc/feb-22-message-test\")"
  },
  {
    "objectID": "chapters/gwwc_fb.html#capturing-data",
    "href": "chapters/gwwc_fb.html#capturing-data",
    "title": "4  Giving What We Can: Feb 22 Facebook Message Test",
    "section": "4.2 Capturing data",
    "text": "4.2 Capturing data\n\n\n\n\n\n\nBringing in the data Erin coded\n\n\n\n\n\nAs a start, I source build work (Erin’s work, which I edited a bit) to bring in (and store) the data. I would do the coding a bit differently (more ‘tidyverse’ and less repetition), but it may not be worth redoing at this point.\n\n\n\n\n\nCode\n#this seems to be what Erin used ... but what is \n\nsource(here(\"gwwc\", \"build_GWWC_Feb_22_Message_test.R\"))"
  },
  {
    "objectID": "chapters/gwwc_gg.html#build-source-data-input-and-cleaning-code",
    "href": "chapters/gwwc_gg.html#build-source-data-input-and-cleaning-code",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.3 Build: Source data input and cleaning code",
    "text": "1.3 Build: Source data input and cleaning code\nUpdate 10 Jun 2022: I am re-doing the ’bringing down and inputting of data.\nSee:\nAccessing and bringing down simple results HERE\nMost relevant breakdowns as pivot tables\nWe import this exported ‘pivot table’ gg_campaign_by_ad_by_text below.\n15 Jun 2022 - Replacing with more detailed version: gg-campaign-by-ad-set-text-age-gender.csv\nEach row represents a combination of1\n\ncampaign_name: When and and with what funds the ad was launched, I think (?)\nad_set: An ad set can specifically tie an ad_name to an audience (I think)\nad_name: Which video/media (or collection of optimized videos/media) was shown; note this is paired with ‘which audience’ in it’s label, as there were specific ‘global poverty’, ‘animal welfare’, ‘climate change’, ‘philanthropy’ and ‘retargeting’ audiences\n\nCaveat: The ad_name seems to select from a different set of media for optimization depending on which ad_set it is in.2\n\ntext: Which text was shown along with the video\n\n\n\nCode\ngg_campaign_by_ad_by_text <- read_csv(here(\"gwwc\", \"gg_raw_data_shareable\", \"gg_campaign_by_ad_by_text.csv\"), show_col_types=FALSE) %>%\n  dplyr::select(-\"Campaign name...4\") %>% #duplicate column\n  as_tibble() %>% \n  janitor::clean_names() %>% \n  janitor::remove_empty() # removes empty rows and columns, here `unique_link_clicks`\n\nattribution_setting <- gg_campaign_by_ad_by_text$attribution_setting %>% .[1]\nreporting_starts <- gg_campaign_by_ad_by_text$reporting_starts %>% .[1]\nreporting_ends <- gg_campaign_by_ad_by_text$reporting_ends %>% .[1]\n\ngg_campaign_by_ad_by_text <- gg_campaign_by_ad_by_text %>%\n  dplyr::select(-attribution_setting, -reporting_starts, -reporting_ends) #take out columns with all the same\n\n# renaming, relabeling etc\ngg_campaign_by_ad_by_text <- gg_campaign_by_ad_by_text %>% \n  mutate(\n    campaign_name = str_replace(campaign_name_1, \"Giving Guide 2021\", \"GG21\")\n    ) %>% \n  dplyr::select(campaign_name, everything(), -campaign_name_1)\n\n# Shorter 'text treatment' column\ngg_campaign_by_ad_by_text <- gg_campaign_by_ad_by_text %>% \n  mutate(\n    text_treat = case_when(\n      str_detect(text, \"^Want to make a bigger difference next year?\") ~ \"Bigger difference\",\n      str_detect(text, \"^Did you know that the best charities can have a 100x greater impact?\") ~ \"100x impact\",\n      str_detect(text, \"^Giving What We Can has helped\") ~ \"6000+ people\",\n      str_detect(text, \"^Whether we’re moved by animal welfare, the climate crisis\") ~ \"Cause list\",\n      str_detect(text, \"^Use our free guide to learn\") ~ \"Learn\",\n      str_detect(text, \"^Only 3% of donors give based on charity effectiveness yet\") ~ \"Only 3% research\",\n      str_detect(text, \"^It can be overwhelming with so many problems\") ~ \"Overwhelming\",\n      TRUE ~ \"\"\n    ),\n#campaign theme aggregation\n    campaign_theme = case_when(\n      str_detect(campaign_name, \"Emotional\") ~ \"Cause-specific\",\n      str_detect(campaign_name, \"Factual\") ~ \"Factual-effectiveness-research\",\n      str_detect(campaign_name, \"Hypercube\") ~ \"Hypercube video\",\n      str_detect(campaign_name, \"PPCo \") ~ \"'Optimized' Factual, Emotional- PPCo creatives\",\n      TRUE ~ \"\"), \n    version = case_when(\n      str_detect(campaign_name, \"V2\") &  str_detect(campaign_name, \"Factual\") ~ \"V2 - factual shortened\",\n      #Emotional ads remained the same for V1 and V2, and a second set of filmed ads were used for V3\n      #Factual ad was shortened for V2, and a second filmed ad was used for V3  \n      str_detect(campaign_name, \"V3\") ~ \"V3 - sometimes Luke\",\n      str_detect(campaign_name, \"Hypercube\") ~ \"Video/creatives\",\n      str_detect(campaign_name, \"PPCo \") ~ \"Video/creatives\",\n      TRUE ~ \"V1\"),\n    audience = case_when(\n      str_detect(ad_name, \"Animal\") ~ \"Animal\",\n      str_detect(ad_name, \"Climate\") ~ \"Climate\",\n      str_detect(ad_name, \"Poverty\") ~ \"Global Poverty\",\n      str_detect(ad_name, \"Philanthropy\") ~ \"Philanthropy\",\n      str_detect(ad_name, \"Retargeting\") ~ \"Retargeting\",\n      str_detect(ad_name, \"Lookalikes\") ~ \"Lookalikes\",\n      TRUE ~ \"General audience\"),\n    video_theme = case_when( # Cause category aggregation\n      str_detect(ad_name, \"Animal\") & str_detect(ad_name, \"Emotional\")  ~ \"Animal\",\n      str_detect(ad_name, \"Climate\") & str_detect(ad_name, \"Emotional\")  ~ \"Climate\",\n      str_detect(ad_name, \"Poverty\") & str_detect(ad_name, \"Emotional\")  ~ \"Poverty\",\n      str_detect(ad_name, \"Animated\") ~ \"Animated\",\n      TRUE ~ \"Factual or optimized mix\")\n  )\n\n\n\nThis data frame has one row per combination of ‘campaign, ad, and text’.\n\n\n\n\n\n\nUpdate: The discussion below does not pertain to the actual raw data.\n\n\n\n\n\nThe actual original/raw data is collapsed (breakdowns) by demography and ad set, into 2 files:\nvideo breakdown.csv\ntext breakdown.csv\nThat data is clearly not identifying individuals; it involves aggregates based on real or assumed characteristics … and, as the other data is derived from it, there is clearly nothing that needs to be hidden there.\nWe input the ‘actual raw data’ (the statistics in a minimal format) below.\n\n\n\n\n\nCode\nraw_data_path <- list(\"gwwc\", \"gg_raw_data_shareable\")\n\nraw_gwwc_gg_vid <-  read.csv(here(raw_data_path, \"video breakdown.csv\")) %>% as_tibble()\n\nraw_gwwc_gg_text <-  read.csv(here(raw_data_path, \"text breakdown.csv\")) %>% as_tibble()\n\n\n\n\nCode\n#raw_gwwc_gg_vid %>% group_by(Campaign.name) %>% summarise(impressions = sum(Impressions))\n\n\n\n\n\n\n\n\nAccess to data\n\n\n\n\n\nNote: You must have access to the GWWC raw data to run this. This includes data that was constructed (with what code?) by expanding Facebook’s aggregate reporting.\nThe files:\ntextdata_dv_linkclicks.csv, videodata_dv_results.csv, textdata_dv_results.csv , and videodata_dv_linkclicks.csv\nare gitignored because of size\n\n\n\n\n\nCode\nsource(here(\"gwwc\", \"giving_guides\", \"input_build_gwwc_gg_data_results.R\"))\n\n#source(here(\"gwwc\", \"giving_guides\", \"input_build_gwwc_gg_data_clicks.R\"))\n\n\nThe code above inputs and builds 2-4 related data frames (tibbles), which were constructed from the collapsed (aggregated) data by multiplying rows according to observation counts.3\ngwwc_text_clicks: Observations of link clicks … by texts above video gwwc_vid_clicks: … by video content4\ngwwc_text_results: Observations of emails provided … by texts above video gwwc_vid_results: … by video content"
  },
  {
    "objectID": "chapters/gwwc_gg.html#asking-and-answering-questions",
    "href": "chapters/gwwc_gg.html#asking-and-answering-questions",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.4 Asking and answering questions",
    "text": "1.4 Asking and answering questions\n\n\n\n\n\n\nThis dynamic document format allows us to ask and answer a series of questions\n\n\n\n\n\n\nUsing the data, with all coding steps shown\nIdeally, following a pre-defined (pre-analysis) plan\nUsing the data and statistics directly and automatically in the narrative\n\nAnd everything will be automatically adjusted if we bring in new data or adjust/correct features\n\n\n\n\n\n\nIn this context, how much does it cost to get a ’Result”, i.e., to get a person to give their email to receive a Giving Guide?\n5\n\n\nWhich pre-defined audience yields a Result at the lowest cost? How does this cost vary by audience?\n\n\nWhich pre-defined audience yields the highest ‘rate of Result’? How does this vary by audience?\nNote, this is not the same as the previous question because some audiences are more costly to target on Facebook.\n\n\nWhich video yields a Result at the highest rate/lowest cost?\n6\n\nHow does the ‘best video’ vary by audience?\n\n\nAggregating: Which category of videos yields a result at the highest rate/lowest cost? (“Facts”, “Cause focus”, or “Arguments, rich content”)\n\n\n\nWhich message yields a Result at the highest rate/lowest cost?\n7\nSub-questions\n\nHow does the ‘best message’ vary by audience?\n\n\n\n\n\n\nOther questions (less interest or less feasible)\n\n\n\n\n\n\nDo the message treatments ‘interact’ with the video treatments (i.e., are their synergies and better pairings)?\nDo some videos lead to higher click rates?\nDo some videos lead to higher watch rates?\n\n\n\n\n\n\n\n1.4.1 Defining the ‘outcomes of interest’ (as objects)\n\n\n\nNext, we define the ‘features of interest’ and the ‘controls’\n\n\nCode\n#features and controls\n#geog <- c(\"where_live_cat\", \"city_cat\")\n#key_demog <- c(\"ln_age\", \"not_male_cat\", \"student_cat\", \"race_cat\", geog)\n#key_demog_n <- c(\"age_d2sd\", \"not_male_cat\", \"student_cat\", \"race_cat\", geog)"
  },
  {
    "objectID": "chapters/gwwc_gg.html#analysis-and-visuals-moved-from-erins-work",
    "href": "chapters/gwwc_gg.html#analysis-and-visuals-moved-from-erins-work",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.4 Analysis and visuals (moved from Erin’s work)",
    "text": "1.4 Analysis and visuals (moved from Erin’s work)\n\n\nCode\n#summary(gwwc_vid_results$DV_costadj)\n#summary(gwwc_vid_results$DV)\n#summary(gwwc_vid_results$ave.cost.impr)\n\n\nData summary\n\nBelow, a few data summary bits (from Erin). I commented most of it out and will redo it using an automated and formatted ‘key summary statistics’ package.\n\n\n\nCode\ngwwc_vid_results %>% group_by(Age) %>% summarise(n=n()) %>% .kable()\n\n\n\n \n  \n    Age \n    n \n  \n \n\n  \n    25-34 \n    287,682 \n  \n  \n    13-17 \n    444 \n  \n  \n    18-24 \n    147,805 \n  \n  \n    35-44 \n    158,352 \n  \n  \n    45-54 \n    48,728 \n  \n  \n    55-64 \n    60,904 \n  \n  \n    65+ \n    66,198 \n  \n\n\n\n\n\nCode\ngwwc_vid_results %>% group_by(Gender) %>% summarise(n=n())  %>% .kable()\n\n\n\n \n  \n    Gender \n    n \n  \n \n\n  \n    female \n    573,705 \n  \n  \n    male \n    178,321 \n  \n  \n    unknown \n    18,087 \n  \n\n\n\n\n\nCode\n#print(gwwc_vid_results %>% group_by(Gender,Age) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=40)\n#print(gwwc_vid_results %>% group_by(Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=41)\n#print(gwwc_vid_results %>% group_by(Campaign.name,Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=100)\ngwwc_vid_results %>% group_by(audience) %>% summarise(n=n(),cost=mean(ave.cost.impr)*100) %>% .kable(digits=2)\n\n\n\n \n  \n    audience \n    n \n    cost \n  \n \n\n  \n    philanthropy \n    248,852 \n    2.20 \n  \n  \n    animal \n    187,212 \n    2.22 \n  \n  \n    climate \n    139,824 \n    1.81 \n  \n  \n    general \n    57,012 \n    1.30 \n  \n  \n    lookalike \n    67,359 \n    2.66 \n  \n  \n    poverty \n    69,404 \n    1.82 \n  \n  \n    retargeting \n    450 \n    2.50 \n  \n\n\n\n\n\nCode\ngwwc_vid_results %>% group_by(message) %>% summarise(n=n(),cost=mean(ave.cost.impr)*100) %>% .kable(digits=2)\n\n\n\n \n  \n    message \n    n \n    cost \n  \n \n\n  \n    Factual \n    291,027 \n    2.24 \n  \n  \n    Emotional \n    274,718 \n    2.37 \n  \n  \n    Hypercube \n    75,790 \n    1.76 \n  \n  \n    PPCo \n    128,578 \n    1.25 \n  \n\n\n\n\n\n### CHART DATA\n\n\nCode\n#print(gwwc_vid_results %>% group_by(audience,media) %>% #summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)"
  },
  {
    "objectID": "chapters/gwwc_gg.html#plots",
    "href": "chapters/gwwc_gg.html#plots",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.6 PLOTS",
    "text": "1.6 PLOTS\n\n\nCode\n#Plot options in common\n\nlimits <- aes(ymax = mean_dv + (se_dv), ymin = mean_dv - (se_dv))\ndodge <- position_dodge(width = 0.9)\n\nvid_types <-\n  c(\"factual short\",\n    \"animal\",\n    \"climate\",\n    \"factual long\",\n    \"hypercube\",\n    \"poverty\")\n\ngg_gg_options <- list(geom_bar(stat = 'identity', position=dodge),\n  geom_errorbar(limits, position=dodge,  width=0.05),\n  jtools::theme_apa(),\n  theme(legend.position=\"none\"),\n  geom_text(aes(label = paste(\"$\",mean_dv %>% round(.,2)), y=5), position = position_dodge(.9), size=4, color=\"white\"),\n  theme(text=element_text(size=10))\n)\n\ngrpsumgg <- function(df, gvar, var) {\n  df %>%\n  group_by({{gvar}}) %>%\n  summarise(mean_dv = mean({{var}}, na.rm=TRUE),\n            se_dv = sd({{var}}, na.rm=TRUE)/sqrt(n()))\n}\n\n\n\n1.6.1 PLOT: Cost adjusted DV (results) by video\n\n\nCode\ngwwc_vid_results %>%\n    filter(ave.cost.impr > 0) %>%\n    group_by(media) %>%\n    summarise(\n    `Results per $ (adjusted)` = mean(DV_costadj),\n    SE = std.error(DV_costadj),\n    n = n()\n  ) %>%\n  arrange(-`Results per $ (adjusted)`) %>%\n  .kable(digits = 3) %>%\n  .kable_styling()\n\n\n\n \n  \n    media \n    Results per $ (adjusted) \n    SE \n    n \n  \n \n\n  \n    climate \n    0.118 \n    0.016 \n    38,663 \n  \n  \n    factual short \n    0.117 \n    0.005 \n    331,197 \n  \n  \n    poverty \n    0.117 \n    0.009 \n    113,608 \n  \n  \n    animal \n    0.093 \n    0.005 \n    180,291 \n  \n  \n    hypercube \n    0.062 \n    0.007 \n    75,785 \n  \n  \n    factual long \n    0.037 \n    0.006 \n    30,356 \n  \n\n\n\n\n\n\n\nCode\ngwwc_vid_results %>%\n  grpsumgg(media, DV_costadj) %>%\n  ggplot(aes(x=media, y=mean_dv)) +\n  gg_gg_options +\n  geom_bar(stat='identity',fill=\"#0072B2\", position=dodge) +\n  ylab('Results/$ spent') +\n  xlab('Video') +\n  ggtitle('Results/$ spent by Video') +\n  scale_y_continuous(limits = c(0,.2),  breaks=seq(0,.2, by=.05)) +\n  scale_x_discrete(labels=vid_types)\n\n\n\n\n\n\n\n1.6.2 PLOT: DV (Results) by video\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr > 0) %>%\n  group_by(media) %>%\n  summarise(\n  results = 100 * mean(DV),\n  SE = 100 * std.error(DV),\n  n = n()\n) %>%\n  .kable(digits = 2) %>%\n  .kable_styling()\n\n\n\n \n  \n    media \n    results \n    SE \n    n \n  \n \n\n  \n    factual short \n    0.22 \n    0.01 \n    331,197 \n  \n  \n    animal \n    0.25 \n    0.01 \n    180,291 \n  \n  \n    climate \n    0.19 \n    0.02 \n    38,663 \n  \n  \n    factual long \n    0.17 \n    0.02 \n    30,356 \n  \n  \n    hypercube \n    0.10 \n    0.01 \n    75,785 \n  \n  \n    poverty \n    0.17 \n    0.01 \n    113,608 \n  \n\n\n\n\n\nCode\ngwwc_vid_results %>%\n   grpsumgg(media, DV) %>%\n  ggplot(aes(x=media, y=mean_dv)) +\n  geom_bar(stat='identity', fill=\"#0072B2\",position=dodge) +\n  ylab('Results (%)')+\n  xlab('Video')+\n  ggtitle('Results by Video')+\n  scale_x_discrete(labels=vid_types)\n\n\n\n\n\n\n\n1.6.3 PLOT: Cost adjusted DV (results) by video and audience\nQuestions/Notes: Removed the retargeting audience\n\n\nCode\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>% group_by(media,audience) %>% #summarise(results=mean(DV_costadj),SE=std.error(DV_costadj),n=n()),n=50) %>% .kable(digits=2)\n\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>%\n  group_by(media, audience) %>%\n  summarise(mean_dv = mean(DV_costadj, na.rm=TRUE),\n            se_dv = sd(DV_costadj, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=audience, y=mean_dv, group=media, fill=media)) +\n  gg_gg_options +\n  labs(fill=\"Video\")+\n  scale_fill_brewer(palette=\"RdBu\")+\n  ylab('Results/$ spent')+\n  xlab('Audience')+\n  ggtitle('Results/$ spent by Video and Audience')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.25), oob = rescale_none, breaks=seq(0,.75, by=.25)) +\n  scale_x_discrete(labels=c(\"philanthropy\",\"animal\",\"climate\",\"general\",\"lookalike\",\"poverty\",\"retargeting\")) %>% \n  DT::datatable()\n\n\nClasses 'ScaleDiscretePosition', 'ScaleDiscrete', 'Scale', 'ggproto', 'gg' <ggproto object: Class ScaleDiscretePosition, ScaleDiscrete, Scale, gg>\n    aesthetics: x xmin xmax xend\n    axis_order: function\n    break_info: function\n    break_positions: function\n    breaks: waiver\n    call: call\n    clone: function\n    dimension: function\n    drop: TRUE\n    expand: waiver\n    get_breaks: function\n    get_breaks_minor: function\n    get_labels: function\n    get_limits: function\n    guide: waiver\n    is_discrete: function\n    is_empty: function\n    labels: philanthropy animal climate general lookalike poverty re ...\n    limits: NULL\n    make_sec_title: function\n    make_title: function\n    map: function\n    map_df: function\n    n.breaks.cache: NULL\n    na.translate: TRUE\n    na.value: NA\n    name: waiver\n    palette: function\n    palette.cache: NULL\n    position: bottom\n    range: <ggproto object: Class RangeDiscrete, Range, gg>\n        range: NULL\n        reset: function\n        train: function\n        super:  <ggproto object: Class RangeDiscrete, Range, gg>\n    range_c: <ggproto object: Class RangeContinuous, Range, gg>\n        range: NULL\n        reset: function\n        train: function\n        super:  <ggproto object: Class RangeContinuous, Range, gg>\n    rescale: function\n    reset: function\n    scale_name: position_d\n    train: function\n    train_df: function\n    transform: function\n    transform_df: function\n    super:  <ggproto object: Class ScaleDiscretePosition, ScaleDiscrete, Scale, gg> \n\n\nError in DT::datatable(.): 'data' must be 2-dimensional (e.g. data frame or matrix)\n\n\nCode\n#levels(gwwc_vid_results$audience)\n\n\n\n\n1.6.4 PLOT: DV (results) by video and audience\nQuestions/Notes: Removed the retargeting audience\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr > 0 &\n    audience != \"retargeting\") %>% group_by(media, audience) %>% summarise(\n      results = 100 * mean(DV),\n      SE = 100 * std.error(DV),\n      n = n()\n    ) %>% .kable(digits = 2) %>% .kable_styling()\n\n\n\n \n  \n    media \n    audience \n    results \n    SE \n    n \n  \n \n\n  \n    factual short \n    philanthropy \n    0.23 \n    0.02 \n    59,660 \n  \n  \n    factual short \n    animal \n    0.20 \n    0.01 \n    90,832 \n  \n  \n    factual short \n    climate \n    0.21 \n    0.01 \n    96,005 \n  \n  \n    factual short \n    general \n    0.10 \n    0.02 \n    15,559 \n  \n  \n    factual short \n    lookalike \n    0.39 \n    0.03 \n    34,207 \n  \n  \n    factual short \n    poverty \n    0.21 \n    0.02 \n    34,815 \n  \n  \n    animal \n    philanthropy \n    0.21 \n    0.02 \n    79,525 \n  \n  \n    animal \n    animal \n    0.28 \n    0.02 \n    80,642 \n  \n  \n    animal \n    general \n    0.14 \n    0.04 \n    10,542 \n  \n  \n    animal \n    lookalike \n    0.42 \n    0.07 \n    9,441 \n  \n  \n    climate \n    philanthropy \n    0.28 \n    0.04 \n    13,810 \n  \n  \n    climate \n    climate \n    0.11 \n    0.03 \n    14,083 \n  \n  \n    climate \n    general \n    0.16 \n    0.05 \n    7,445 \n  \n  \n    climate \n    lookalike \n    0.21 \n    0.08 \n    3,283 \n  \n  \n    factual long \n    philanthropy \n    0.16 \n    0.05 \n    6,923 \n  \n  \n    factual long \n    animal \n    0.15 \n    0.04 \n    8,729 \n  \n  \n    factual long \n    climate \n    0.19 \n    0.04 \n    9,542 \n  \n  \n    factual long \n    lookalike \n    0.72 \n    0.36 \n    557 \n  \n  \n    factual long \n    poverty \n    0.11 \n    0.05 \n    4,595 \n  \n  \n    hypercube \n    philanthropy \n    0.14 \n    0.03 \n    17,400 \n  \n  \n    hypercube \n    animal \n    0.07 \n    0.03 \n    6,988 \n  \n  \n    hypercube \n    climate \n    0.09 \n    0.02 \n    20,154 \n  \n  \n    hypercube \n    general \n    0.09 \n    0.02 \n    22,132 \n  \n  \n    hypercube \n    lookalike \n    0.25 \n    0.14 \n    1,194 \n  \n  \n    hypercube \n    poverty \n    0.08 \n    0.03 \n    7,835 \n  \n  \n    poverty \n    philanthropy \n    0.15 \n    0.01 \n    71,466 \n  \n  \n    poverty \n    general \n    0.08 \n    0.08 \n    1,327 \n  \n  \n    poverty \n    lookalike \n    0.24 \n    0.04 \n    18,652 \n  \n  \n    poverty \n    poverty \n    0.15 \n    0.03 \n    22,129 \n  \n\n\n\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>%\n  group_by(media, audience) %>%\n  summarise(mean_dv = 100*mean(DV, na.rm=TRUE),\n            se_dv = 100*sd(DV, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=audience, y=mean_dv, group=media, fill=media)) +\n  gg_gg_options +\n  labs(fill=\"Video\")+\n  scale_fill_brewer(palette=\"RdBu\")+\n  ylab('Results (%)')+\n  xlab('Audience')+\n  ggtitle('Results by Video and Audience')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,1.1),  oob = rescale_none,  breaks=seq(0,1.1, by=.1)) +\n  scale_x_discrete(labels=c(\"philanthropy\",\"animal\",\"climate\",\"general\",\"lookalike\",\"poverty\",\"retargeting\"))\n\n\n\n\n\n\n\n1.6.5 PLOT: Cost adjusted DV (results) by audience\n\n\nCode\n#pirint(gwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>% group_by(audience) %>% summarise(results=mean(DV_costadj),SE=std.error(DV_costadj),n=n()),n=50)\n\n\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>%\n  group_by(audience) %>%\nsummarise(mean_dv = mean(DV_costadj, na.rm=TRUE),\n            se_dv = sd(DV_costadj, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=audience, y=mean_dv)) +\n  gg_gg_options +\n  ylab('Results/$ spent')+\n  xlab('Audience')+\n  ggtitle('Results/$ spent by Audience')+\n  scale_y_continuous(limits = c(0,.2),  breaks=seq(0,.2, by=.05)) +\n  scale_x_discrete(labels=c(\"philanthropy\",\"animal\"   ,\"climate\",\"general\",\"lookalike\",\"poverty\"))\n\n\n\n\n\n\n\n1.6.6 PLOT: DV (Results) by audience\n\n\nCode\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>% group_by(audience) %>% summarise(results=100*mean(DV),SE=100*std.error(DV),n=n()),n=50)\n\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>%\n  group_by(audience) %>%\n  summarise(mean_dv = 100*mean(DV, na.rm=TRUE),\n            se_dv = 100*sd(DV, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=audience, y=mean_dv)) +\n  gg_gg_options +\n  ylab('Results (%)')+\n  xlab('Audience')+\n  ggtitle('Results by Audience')+\n  scale_y_continuous(limits = c(0,.4),  breaks=seq(0,.4, by=.05)) +\n  scale_x_discrete(labels=c(\"philanthropy\",\"animal\"   ,\"climate\",\"general\",\"lookalike\",\"poverty\"))\n\n\n\n\n\n\n\n1.6.7 PLOT: Cost adjusted DV (results) by age and gender\nDid not filter out the retargeting audience like i did for the other charts\n\n\nCode\ngwwc_vid_results$Gender <- as.factor(gwwc_vid_results$Gender)\n#levels(gwwc_vid_results$Gender)\n\nclass(gwwc_vid_results$Age)\n\n\n[1] \"factor\"\n\n\nCode\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"18-24\")\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"13-17\")\n#levels(gwwc_vid_results$Age)\n\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0) %>% group_by(Age,Gender) %>% summarise(results=mean(DV_costadj),SE=std.error(DV_costadj),n=n()),n=50)\n\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & Age!=\"13-17\") %>%\n  group_by(Age, Gender) %>%\n  summarise(mean_dv = mean(DV_costadj, na.rm=TRUE),\n            se_dv = sd(DV_costadj, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=Age, y=mean_dv, group=Gender, fill=Gender)) +\n  gg_gg_options +\n  labs(fill=\"Gender\")+\n  scale_fill_brewer(palette=\"Paired\")+\n  ylab('Results/$ spent')+\n  xlab('Age')+\n  ggtitle('Results/$ spent by Age and Gender')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.35),  breaks=seq(0,.35, by=.1)) +\n  scale_x_discrete(labels=c(\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\" ))\n\n\n\n\n\n\n\n1.6.8 PLOT: DV (results) by age and gender\n\n\nCode\ngwwc_vid_results$Gender <- as.factor(gwwc_vid_results$Gender)\n#levels(gwwc_vid_results$Gender)\n\n#class(gwwc_vid_results$Age)\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"18-24\")\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"13-17\")\n#levels(gwwc_vid_results$Age)\n\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0) %>% group_by(Age,Gender) %>% summarise(results=100*mean(DV),SE=std.error(100*DV),n=n()),n=50)\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & Age!=\"13-17\") %>%\n  group_by(Age, Gender) %>%\n  summarise(mean_dv = 100*mean(DV, na.rm=TRUE),\n            se_dv = 100*sd(DV, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=Age, y=mean_dv, group=Gender, fill=Gender)) +\n  gg_gg_options +\n  labs(fill=\"Gender\")+\n  scale_fill_brewer(palette=\"Paired\")+\n  ylab('Results (%)')+\n  xlab('Age')+\n  ggtitle('Results by Age and Gender')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.75),  breaks=seq(0,.75, by=.25)) +\n  scale_x_discrete(labels=c(\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\" ))\n\n\n\n\n\n\n\n1.6.9 PLOT: Cost adjusted DV (results) by Video and Age\n\n\nCode\nclass(gwwc_vid_results$Age)\n\n\n[1] \"factor\"\n\n\nCode\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"18-24\")\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"13-17\")\nlevels(gwwc_vid_results$Age)\n\n\n[1] \"13-17\" \"18-24\" \"25-34\" \"35-44\" \"45-54\" \"55-64\" \"65+\"  \n\n\nCode\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0) %>% group_by(Age,media) %>% summarise(results=mean(DV_costadj),SE=std.error(DV_costadj),n=n()),n=50)\n\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & Age!=\"13-17\") %>%\n  group_by(media, Age) %>%\n  summarise(mean_dv = mean(DV_costadj, na.rm=TRUE),\n            se_dv = sd(DV_costadj, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=Age, y=mean_dv, group=media, fill=media)) +\n  gg_gg_options +\n  labs(fill=\"Video\")+\n  scale_fill_brewer(palette=\"RdBu\")+\n  ylab('Results/$ spent')+\n  xlab('Age')+\n  ggtitle('Results/$ spent by Video and Age')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.2),  breaks=seq(0,.2, by=.05)) +\n  scale_x_discrete(labels=c(\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\"))\n\n\n\n\n\n\n\n1.6.10 PLOT: DV (results) by video and age\n\n\nCode\nclass(gwwc_vid_results$Age)\n\n\n[1] \"factor\"\n\n\nCode\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"18-24\")\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"13-17\")\n#levels(gwwc_vid_results$Age)\n\ngwwc_vid_results %>% filter(ave.cost.impr>0) %>% group_by(Age,media) %>% summarise(results=100*mean(DV),SE=100*std.error(DV),n=n()) %>%\n  .kable(digits=2) %>%  .kable_styling()\n\n\n\n \n  \n    Age \n    media \n    results \n    SE \n    n \n  \n \n\n  \n    13-17 \n    factual short \n    0.00 \n    0.00 \n    176 \n  \n  \n    13-17 \n    animal \n    0.00 \n    0.00 \n    101 \n  \n  \n    13-17 \n    climate \n    0.00 \n    0.00 \n    20 \n  \n  \n    13-17 \n    factual long \n    0.00 \n    NA \n    1 \n  \n  \n    13-17 \n    hypercube \n    0.00 \n    0.00 \n    46 \n  \n  \n    13-17 \n    poverty \n    0.00 \n    0.00 \n    81 \n  \n  \n    18-24 \n    factual short \n    0.11 \n    0.01 \n    55,045 \n  \n  \n    18-24 \n    animal \n    0.12 \n    0.02 \n    35,453 \n  \n  \n    18-24 \n    climate \n    0.09 \n    0.03 \n    9,513 \n  \n  \n    18-24 \n    factual long \n    0.00 \n    0.00 \n    5,283 \n  \n  \n    18-24 \n    hypercube \n    0.12 \n    0.03 \n    18,632 \n  \n  \n    18-24 \n    poverty \n    0.14 \n    0.02 \n    23,823 \n  \n  \n    25-34 \n    factual short \n    0.15 \n    0.01 \n    124,020 \n  \n  \n    25-34 \n    animal \n    0.16 \n    0.02 \n    54,928 \n  \n  \n    25-34 \n    climate \n    0.17 \n    0.03 \n    17,904 \n  \n  \n    25-34 \n    factual long \n    0.08 \n    0.04 \n    5,161 \n  \n  \n    25-34 \n    hypercube \n    0.10 \n    0.02 \n    38,313 \n  \n  \n    25-34 \n    poverty \n    0.14 \n    0.02 \n    47,287 \n  \n  \n    35-44 \n    factual short \n    0.16 \n    0.02 \n    68,690 \n  \n  \n    35-44 \n    animal \n    0.23 \n    0.03 \n    34,263 \n  \n  \n    35-44 \n    climate \n    0.15 \n    0.05 \n    6,719 \n  \n  \n    35-44 \n    factual long \n    0.18 \n    0.07 \n    4,336 \n  \n  \n    35-44 \n    hypercube \n    0.09 \n    0.02 \n    18,794 \n  \n  \n    35-44 \n    poverty \n    0.20 \n    0.03 \n    25,492 \n  \n  \n    45-54 \n    factual short \n    0.26 \n    0.04 \n    17,482 \n  \n  \n    45-54 \n    animal \n    0.35 \n    0.04 \n    19,751 \n  \n  \n    45-54 \n    climate \n    0.24 \n    0.17 \n    851 \n  \n  \n    45-54 \n    factual long \n    0.15 \n    0.06 \n    4,548 \n  \n  \n    45-54 \n    poverty \n    0.30 \n    0.07 \n    6,090 \n  \n  \n    55-64 \n    factual short \n    0.35 \n    0.03 \n    28,557 \n  \n  \n    55-64 \n    animal \n    0.41 \n    0.04 \n    20,126 \n  \n  \n    55-64 \n    climate \n    0.33 \n    0.16 \n    1,221 \n  \n  \n    55-64 \n    factual long \n    0.17 \n    0.06 \n    4,848 \n  \n  \n    55-64 \n    poverty \n    0.20 \n    0.06 \n    6,150 \n  \n  \n    65+ \n    factual short \n    0.66 \n    0.04 \n    37,227 \n  \n  \n    65+ \n    animal \n    0.57 \n    0.06 \n    15,669 \n  \n  \n    65+ \n    climate \n    0.66 \n    0.16 \n    2,435 \n  \n  \n    65+ \n    factual long \n    0.40 \n    0.08 \n    6,179 \n  \n  \n    65+ \n    poverty \n    0.21 \n    0.07 \n    4,685 \n  \n\n\n\n\n\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr>0 & Age !=\"13-17\") %>%\n    group_by(media, Age) %>%\n  summarise(mean_dv = 100*mean(DV, na.rm=TRUE),\n            se_dv = 100*sd(DV, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=Age, y=mean_dv, group=media, fill=media)) +\n  gg_gg_options +\n  labs(fill=\"Video\")+\n  scale_fill_brewer(palette=\"RdBu\")+\n  ylab('Results (%)')+\n  xlab('Age')+\n  ggtitle('Results by Video and Age')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.85),  breaks=seq(0,.85, by=.25)) +\n  scale_x_discrete(labels=c(\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\"))"
  },
  {
    "objectID": "chapters/gwwc_gg.html#statistics-and-mi-needs-to-be-made-into-table",
    "href": "chapters/gwwc_gg.html#statistics-and-mi-needs-to-be-made-into-table",
    "title": "3  Giving What We Can: Giving guides",
    "section": "3.6 Statistics and mi– needs to be made into table",
    "text": "3.6 Statistics and mi– needs to be made into table\n\n3.6.1 Regressions with interactions\n\n\nCode\nsummary(lm(data = gwwc_vid_results, DV~Gender*Age+ave.cost.impr))\n\n\n\nCall:\nlm(formula = DV ~ Gender * Age + ave.cost.impr, data = gwwc_vid_results)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.04779 -0.00203 -0.00151 -0.00129  0.99914 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            -9.180e-04  3.006e-03  -0.305    0.760    \nGendermale              1.965e-04  4.810e-03   0.041    0.967    \nGenderunknown           4.097e-04  6.120e-03   0.067    0.947    \nAge18-24                1.497e-03  3.007e-03   0.498    0.619    \nAge25-34                1.799e-03  3.005e-03   0.599    0.549    \nAge35-44                1.874e-03  3.006e-03   0.623    0.533    \nAge45-54                2.607e-03  3.012e-03   0.865    0.387    \nAge55-64                2.712e-03  3.012e-03   0.900    0.368    \nAge65+                  4.702e-03  3.019e-03   1.557    0.119    \nave.cost.impr           4.306e-02  6.608e-03   6.516 7.25e-11 ***\nGendermale:Age18-24    -6.997e-05  4.817e-03  -0.015    0.988    \nGenderunknown:Age18-24 -4.670e-04  6.156e-03  -0.076    0.940    \nGendermale:Age25-34    -4.299e-04  4.814e-03  -0.089    0.929    \nGenderunknown:Age25-34 -7.873e-04  6.151e-03  -0.128    0.898    \nGendermale:Age35-44    -6.757e-06  4.818e-03  -0.001    0.999    \nGenderunknown:Age35-44 -8.994e-04  6.166e-03  -0.146    0.884    \nGendermale:Age45-54    -1.671e-03  4.845e-03  -0.345    0.730    \nGenderunknown:Age45-54  2.184e-03  6.270e-03   0.348    0.728    \nGendermale:Age55-64    -7.455e-04  4.836e-03  -0.154    0.877    \nGenderunknown:Age55-64  2.492e-04  6.247e-03   0.040    0.968    \nGendermale:Age65+      -1.479e-03  4.831e-03  -0.306    0.760    \nGenderunknown:Age65+   -9.135e-04  6.224e-03  -0.147    0.883    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04524 on 770091 degrees of freedom\nMultiple R-squared:  0.0009605, Adjusted R-squared:  0.0009332 \nF-statistic: 35.25 on 21 and 770091 DF,  p-value: < 2.2e-16\n\n\nCode\nsummary(lm(data = gwwc_vid_results,DV~Gender*Age))\n\n\n\nCall:\nlm(formula = DV ~ Gender * Age, data = gwwc_vid_results)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.00629 -0.00180 -0.00150 -0.00120  0.99895 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)  \n(Intercept)             3.049e-14  3.003e-03   0.000   1.0000  \nGendermale             -2.692e-14  4.810e-03   0.000   1.0000  \nGenderunknown           3.038e-14  6.119e-03   0.000   1.0000  \nAge18-24                1.132e-03  3.006e-03   0.376   0.7066  \nAge25-34                1.502e-03  3.004e-03   0.500   0.6172  \nAge35-44                1.706e-03  3.006e-03   0.568   0.5703  \nAge45-54                3.089e-03  3.011e-03   1.026   0.3050  \nAge55-64                3.507e-03  3.010e-03   1.165   0.2439  \nAge65+                  6.293e-03  3.010e-03   2.091   0.0365 *\nGendermale:Age18-24     6.977e-05  4.817e-03   0.014   0.9884  \nGenderunknown:Age18-24 -7.811e-05  6.156e-03  -0.013   0.9899  \nGendermale:Age25-34    -3.072e-04  4.814e-03  -0.064   0.9491  \nGenderunknown:Age25-34 -4.034e-04  6.151e-03  -0.066   0.9477  \nGendermale:Age35-44     9.669e-05  4.818e-03   0.020   0.9840  \nGenderunknown:Age35-44 -6.279e-04  6.166e-03  -0.102   0.9189  \nGendermale:Age45-54    -1.687e-03  4.845e-03  -0.348   0.7277  \nGenderunknown:Age45-54  2.235e-03  6.270e-03   0.356   0.7215  \nGendermale:Age55-64    -9.220e-04  4.836e-03  -0.191   0.8488  \nGenderunknown:Age55-64  2.439e-04  6.247e-03   0.039   0.9689  \nGendermale:Age65+      -2.110e-03  4.830e-03  -0.437   0.6623  \nGenderunknown:Age65+   -1.408e-03  6.224e-03  -0.226   0.8210  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04524 on 770092 degrees of freedom\nMultiple R-squared:  0.0009054, Adjusted R-squared:  0.0008794 \nF-statistic: 34.89 on 20 and 770092 DF,  p-value: < 2.2e-16\n\n\n\n\n3.6.2 Regressions with no interactions\njust demographics, not control\n\n\nCode\nsummary(data = lm(gwwc_vid_results,DV~Gender+Age))\n\n\nError in as.data.frame.default(data): cannot coerce class '\"formula\"' to a data.frame\n\n\njust demographic, controlling for cost\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nmeans and standard errors for age groups/gender\n\n\nCode\nprint(gwwc_vid_results %>% group_by(Gender,Age) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)\n\n\n# A tibble: 21 × 7\n# Groups:   Gender [3]\n   Gender  Age   results      SE      n   cost      CPR\n   <fct>   <fct>   <dbl>   <dbl>  <int>  <dbl>    <dbl>\n 1 female  13-17   0     0          227 0.0213 Inf     \n 2 female  18-24   0.113 0.0107   98953 0.0129   0.114 \n 3 female  25-34   0.150 0.00843 211071 0.0144   0.0960\n 4 female  35-44   0.171 0.0118  121915 0.0174   0.102 \n 5 female  45-54   0.309 0.0276   40467 0.0325   0.105 \n 6 female  55-64   0.351 0.0265   49900 0.0398   0.113 \n 7 female  65+     0.629 0.0350   51172 0.0583   0.0926\n 8 male    13-17   0     0          145 0.0168 Inf     \n 9 male    18-24   0.120 0.0165   44107 0.0115   0.0960\n10 male    25-34   0.119 0.0130   71149 0.0127   0.106 \n11 male    35-44   0.180 0.0234   32727 0.0153   0.0847\n12 male    45-54   0.140 0.0443    7134 0.0276   0.197 \n13 male    55-64   0.259 0.0516    9671 0.0311   0.120 \n14 male    65+     0.418 0.0558   13388 0.0390   0.0933\n15 unknown 13-17   0     0           72 0.0118 Inf     \n16 unknown 18-24   0.105 0.0471    4745 0.0124   0.117 \n17 unknown 25-34   0.110 0.0448    5462 0.0138   0.126 \n18 unknown 35-44   0.108 0.0539    3710 0.0142   0.132 \n19 unknown 45-54   0.532 0.217     1127 0.0242   0.0454\n20 unknown 55-64   0.375 0.167     1333 0.0302   0.0804\n21 unknown 65+     0.488 0.172     1638 0.0372   0.0763\n\n\n\n\nCode\nhist(gwwc_vid_results$DV_costadj[gwwc_vid_results$DV_costadj>0])\n\n\n\n\n\nCode\nhist(gwwc_vid_results$DV_costadj[gwwc_vid_results$DV_costadj>=0])\n\n\n\n\n\n\n\n3.6.3 DEMOGRAPHICS WITH CONTROLS FOR VIDEO AND COST\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\nsummary(lm(gwwc_vid_results, DV_costadj~Gender+Age))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\n\n3.6.3.1 AUDIENCES\nmain effects\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nNEW DV\n\n\nCode\nsummary(lm(gwwc_vid_results,DV_costadj~Gender+Age+audience))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #interactions\n  summary(lm(gwwc_vid_results,DV~Gender*audience+ave.cost.impr+Age))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n## NEW DV\n    summary(lm(gwwc_vid_results,DV_costadj~Gender*audience+Age))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  summary(lm(gwwc_vid_results,DV~Age*audience+ave.cost.impr+Gender))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #means for audience\n  print(gwwc_vid_results %>% group_by(audience) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)\n\n\n# A tibble: 7 × 6\n  audience     results      SE      n   cost    CPR\n  <fct>          <dbl>   <dbl>  <int>  <dbl>  <dbl>\n1 philanthropy   0.195 0.00885 248852 0.0220 0.112 \n2 animal         0.229 0.0110  187212 0.0222 0.0973\n3 climate        0.178 0.0113  139824 0.0181 0.102 \n4 general        0.112 0.0140   57012 0.0130 0.116 \n5 lookalike      0.344 0.0226   67359 0.0266 0.0773\n6 poverty        0.171 0.0157   69404 0.0182 0.106 \n7 retargeting    0.667 0.384      450 0.0250 0.0376\n\n\n\n\n3.6.3.2 MESSAGES\nno controls\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~message))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #control for cost only\n  summary(lm(gwwc_vid_results,DV~message+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #check results with campaign\n  summary(lm(gwwc_vid_results,DV~Campaign.name))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #check results with campaign and cost control\n  summary(lm(gwwc_vid_results,DV~Campaign.name+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nwith controls\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience+message))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #interactions\n  #with audience\n  summary(lm(gwwc_vid_results,DV~message*audience+ave.cost.impr+Age+Gender))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #with Gender\n  summary(lm(gwwc_vid_results,DV~message*Gender+ave.cost.impr+Age+audience))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #with Age (emotional much worse with ages 65+)\n  summary(lm(gwwc_vid_results,DV~message*Age+ave.cost.impr+Age+audience))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\ninteraction with age and campaign restriction\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~message*agetrin+message*restriction18_39+ave.cost.impr+Age+Gender))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~message*agetrin+message*restriction18_39+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nin just early campaigns\n\n\nCode\nsummary(lm(subset(data,restriction18_39==0),DV~message*agetrin+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': object 'restriction18_39' not found\n\n\n\n\n\n3.6.4 MEDIA\nno controls\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~media))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% group_by(media) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results)\n\n\n# A tibble: 6 × 6\n  media         results      SE      n   cost    CPR\n  <fct>           <dbl>   <dbl>  <int>  <dbl>  <dbl>\n1 factual short   0.223 0.00820 331287 0.0186 0.0834\n2 animal          0.250 0.0118  180327 0.0274 0.110 \n3 climate         0.186 0.0219   38703 0.0160 0.0862\n4 factual long    0.171 0.0237   30359 0.0378 0.221 \n5 hypercube       0.104 0.0117   75790 0.0176 0.169 \n6 poverty         0.165 0.0121  113647 0.0155 0.0939\n\n\ncontrol for cost only\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~media+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame"
  },
  {
    "objectID": "chapters/gwwc_gg.html#new-dv",
    "href": "chapters/gwwc_gg.html#new-dv",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.8 NEW DV",
    "text": "1.8 NEW DV\n\n\nCode\n#lm(gwwc_vid_results,DV_costadj~media))####THIS IS GOOD\n\n\nwith controls\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience+media)\n\n\n\n1.8.1 NEW DV\n\n\nCode\n#lm(gwwc_vid_results,DV_costadj~Gender+Age+audience+media)\n\n\ninteractions\n\n\nCode\n#lm(gwwc_vid_results,DV~media*Age+media*Gender+media*audience+ave.cost.impr)\n#lm(gwwc_vid_results,DV_costadj~media*Age+media*Gender+media*audience)\n#lm(gwwc_vid_results,DV~media*Age+media*Gender+media*audience)\n#lm(gwwc_vid_results,DV_costadj~Age+Gender+media*audience)\n\n\nwith audience\n\n\nCode\n#lm(gwwc_vid_results,DV~media*audience+ave.cost.impr+Age+Gender)\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% group_by(audience,media) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results) %>%\n.kable() %>% .kable_styling()\n\n\n\n \n  \n    audience \n    media \n    results \n    SE \n    n \n    cost \n    CPR \n  \n \n\n  \n    philanthropy \n    factual short \n    0.2278935 \n    0.0195196 \n    59,677 \n    0.0212306 \n    0.0931603 \n  \n  \n    philanthropy \n    animal \n    0.2124797 \n    0.0163273 \n    79,537 \n    0.0287906 \n    0.1354982 \n  \n  \n    philanthropy \n    climate \n    0.2748644 \n    0.0445292 \n    13,825 \n    0.0194358 \n    0.0707105 \n  \n  \n    philanthropy \n    factual long \n    0.1588907 \n    0.0478727 \n    6,923 \n    0.0442424 \n    0.2784455 \n  \n  \n    philanthropy \n    hypercube \n    0.1436699 \n    0.0287142 \n    17,401 \n    0.0165272 \n    0.1150360 \n  \n  \n    philanthropy \n    poverty \n    0.1496734 \n    0.0144587 \n    71,489 \n    0.0146207 \n    0.0976841 \n  \n  \n    animal \n    factual short \n    0.2025473 \n    0.0149169 \n    90,843 \n    0.0177818 \n    0.0877908 \n  \n  \n    animal \n    animal \n    0.2802197 \n    0.0186139 \n    80,651 \n    0.0264827 \n    0.0945071 \n  \n  \n    animal \n    factual long \n    0.1489118 \n    0.0412723 \n    8,730 \n    0.0331970 \n    0.2229308 \n  \n  \n    animal \n    hypercube \n    0.0715512 \n    0.0319895 \n    6,988 \n    0.0176674 \n    0.2469200 \n  \n  \n    climate \n    factual short \n    0.2051549 \n    0.0146018 \n    96,025 \n    0.0167376 \n    0.0815853 \n  \n  \n    climate \n    climate \n    0.1063830 \n    0.0274543 \n    14,100 \n    0.0135738 \n    0.1275933 \n  \n  \n    climate \n    factual long \n    0.1886397 \n    0.0444232 \n    9,542 \n    0.0362073 \n    0.1919389 \n  \n  \n    climate \n    hypercube \n    0.0942601 \n    0.0216151 \n    20,157 \n    0.0195252 \n    0.2071421 \n  \n  \n    general \n    factual short \n    0.0963824 \n    0.0248746 \n    15,563 \n    0.0096248 \n    0.0998600 \n  \n  \n    general \n    animal \n    0.1422880 \n    0.0367142 \n    10,542 \n    0.0134842 \n    0.0947667 \n  \n  \n    general \n    climate \n    0.1611171 \n    0.0464761 \n    7,448 \n    0.0100953 \n    0.0626583 \n  \n  \n    general \n    hypercube \n    0.0948852 \n    0.0206963 \n    22,132 \n    0.0162078 \n    0.1708143 \n  \n  \n    general \n    poverty \n    0.0753580 \n    0.0753580 \n    1,327 \n    0.0111831 \n    0.1484000 \n  \n  \n    lookalike \n    factual short \n    0.3886843 \n    0.0336381 \n    34,218 \n    0.0254869 \n    0.0655722 \n  \n  \n    lookalike \n    animal \n    0.4234148 \n    0.0668094 \n    9,447 \n    0.0398878 \n    0.0942050 \n  \n  \n    lookalike \n    climate \n    0.2129601 \n    0.0804179 \n    3,287 \n    0.0257438 \n    0.1208857 \n  \n  \n    lookalike \n    factual long \n    0.7181329 \n    0.3580964 \n    557 \n    0.0782406 \n    0.1089500 \n  \n  \n    lookalike \n    hypercube \n    0.2512563 \n    0.1449412 \n    1,194 \n    0.0249665 \n    0.0993667 \n  \n  \n    lookalike \n    poverty \n    0.2412093 \n    0.0359149 \n    18,656 \n    0.0206915 \n    0.0857822 \n  \n  \n    poverty \n    factual short \n    0.2124178 \n    0.0246672 \n    34,837 \n    0.0185498 \n    0.0873270 \n  \n  \n    poverty \n    factual long \n    0.1088139 \n    0.0486419 \n    4,595 \n    0.0349859 \n    0.3215200 \n  \n  \n    poverty \n    hypercube \n    0.0765697 \n    0.0312495 \n    7,836 \n    0.0180028 \n    0.2351167 \n  \n  \n    poverty \n    poverty \n    0.1535960 \n    0.0263218 \n    22,136 \n    0.0143694 \n    0.0935529 \n  \n  \n    retargeting \n    factual short \n    0.0000000 \n    0.0000000 \n    124 \n    0.0254032 \n    Inf \n  \n  \n    retargeting \n    animal \n    0.6666667 \n    0.6666667 \n    150 \n    0.0304000 \n    0.0456000 \n  \n  \n    retargeting \n    climate \n    0.0000000 \n    0.0000000 \n    43 \n    0.0200000 \n    Inf \n  \n  \n    retargeting \n    factual long \n    8.3333333 \n    8.3333333 \n    12 \n    0.0933333 \n    0.0112000 \n  \n  \n    retargeting \n    hypercube \n    0.0000000 \n    0.0000000 \n    82 \n    0.0131707 \n    Inf \n  \n  \n    retargeting \n    poverty \n    2.5641026 \n    2.5641026 \n    39 \n    0.0128205 \n    0.0050000 \n  \n\n\n\n\n\nwith Gender\n\n\nCode\n#lm(gwwc_vid_results,DV~media*Gender+ave.cost.impr+Age+audience)\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% group_by(Gender, media) %>% summarise(\n  results = mean(DV) * 100,\n  SE = std.error(DV) * 100,\n  n = n(),\n  cost = mean(ave.cost.impr),\n  CPR = cost / results\n)\n\n\n\ninteraction with age and campaign restriction - old people really hated factual long\n\n\nCode\n#lm(gwwc_vid_results,DV~media*agetrin+media*restriction18_39+ave.cost.impr+Age+Gender))\n#lm(gwwc_vid_results,DV~media*agetrin+media*restriction18_39+ave.cost.impr))\n\n\nin just early campaigns\n\n\nCode\n#subset(gwwc_vid_results,restriction18_39==0),DV~media*agetrin+ave.cost.impr))\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% filter(restriction18_39 == 0) %>% group_by(Age, media) %>% summarise(\n  results = mean(DV) * 100,\n  SE = std.error(DV) * 100,\n  n = n(),\n  cost = mean(ave.cost.impr),\n  CPR = cost / results\n)"
  },
  {
    "objectID": "chapters/gwwc_gg.html#statistics-and-models-needs-to-be-made-into-tables",
    "href": "chapters/gwwc_gg.html#statistics-and-models-needs-to-be-made-into-tables",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.7 Statistics and models – needs to be made into tables",
    "text": "1.7 Statistics and models – needs to be made into tables\n\n1.7.1 Regressions with interactions\n\n\nCode\n#lm(data = gwwc_vid_results, DV~Gender*Age+ave.cost.impr)\n#lm(data = gwwc_vid_results,DV~Gender*Age))\n\n\n\n\n1.7.2 Regressions with no interactions\njust demographics, not control\n\n\nCode\n#data = lm(gwwc_vid_results,DV~Gender+Age)\n\n\njust demographic, controlling for cost\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr)\n\n\nmeans and standard errors for age groups/gender\n\n\nCode\ngwwc_vid_results %>% group_by(Gender,Age) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results) %>%\n  .kable() %>% .kable_styling()\n\n\n\n \n  \n    Gender \n    Age \n    results \n    SE \n    n \n    cost \n    CPR \n  \n \n\n  \n    female \n    13-17 \n    0.0000000 \n    0.0000000 \n    227 \n    0.0213216 \n    Inf \n  \n  \n    female \n    18-24 \n    0.1131850 \n    0.0106890 \n    98,953 \n    0.0128517 \n    0.1135455 \n  \n  \n    female \n    25-34 \n    0.1501864 \n    0.0084290 \n    211,071 \n    0.0144178 \n    0.0959994 \n  \n  \n    female \n    35-44 \n    0.1706107 \n    0.0118197 \n    121,915 \n    0.0174212 \n    0.1021111 \n  \n  \n    female \n    45-54 \n    0.3088937 \n    0.0275859 \n    40,467 \n    0.0325183 \n    0.1052736 \n  \n  \n    female \n    55-64 \n    0.3507014 \n    0.0264643 \n    49,900 \n    0.0397964 \n    0.1134766 \n  \n  \n    female \n    65+ \n    0.6292504 \n    0.0349566 \n    51,172 \n    0.0582582 \n    0.0925835 \n  \n  \n    male \n    13-17 \n    0.0000000 \n    0.0000000 \n    145 \n    0.0167586 \n    Inf \n  \n  \n    male \n    18-24 \n    0.1201623 \n    0.0164958 \n    44,107 \n    0.0115342 \n    0.0959887 \n  \n  \n    male \n    25-34 \n    0.1194676 \n    0.0129504 \n    71,149 \n    0.0127057 \n    0.1063529 \n  \n  \n    male \n    35-44 \n    0.1802793 \n    0.0234496 \n    32,727 \n    0.0152608 \n    0.0846508 \n  \n  \n    male \n    45-54 \n    0.1401738 \n    0.0442989 \n    7,134 \n    0.0275820 \n    0.1967700 \n  \n  \n    male \n    55-64 \n    0.2585048 \n    0.0516368 \n    9,671 \n    0.0311354 \n    0.1204440 \n  \n  \n    male \n    65+ \n    0.4182850 \n    0.0557807 \n    13,388 \n    0.0390365 \n    0.0933250 \n  \n  \n    unknown \n    13-17 \n    0.0000000 \n    0.0000000 \n    72 \n    0.0118056 \n    Inf \n  \n  \n    unknown \n    18-24 \n    0.1053741 \n    0.0471048 \n    4,745 \n    0.0123688 \n    0.1173800 \n  \n  \n    unknown \n    25-34 \n    0.1098499 \n    0.0448255 \n    5,462 \n    0.0138191 \n    0.1258000 \n  \n  \n    unknown \n    35-44 \n    0.1078167 \n    0.0538865 \n    3,710 \n    0.0142102 \n    0.1318000 \n  \n  \n    unknown \n    45-54 \n    0.5323869 \n    0.2168629 \n    1,127 \n    0.0241792 \n    0.0454167 \n  \n  \n    unknown \n    55-64 \n    0.3750938 \n    0.1674950 \n    1,333 \n    0.0301575 \n    0.0804000 \n  \n  \n    unknown \n    65+ \n    0.4884005 \n    0.1723061 \n    1,638 \n    0.0372466 \n    0.0762625 \n  \n\n\n\n\n\n\n\nCode\nhist(gwwc_vid_results$DV_costadj[gwwc_vid_results$DV_costadj>0])\n\n\n\n\n\nCode\nhist(gwwc_vid_results$DV_costadj[gwwc_vid_results$DV_costadj>=0])\n\n\n\n\n\n\n\n1.7.3 DEMOGRAPHICS WITH CONTROLS FOR VIDEO AND COST\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr)\n#lm(gwwc_vid_results, DV_costadj~Gender+Age)\n\n\n\n1.7.3.1 AUDIENCES\nmain effects\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience)\n\n\nNEW DV\n\n\nCode\n#lm(gwwc_vid_results,DV_costadj~Gender+Age+audience)\n\n  #interactions\n  #lm(gwwc_vid_results,DV~Gender*audience+ave.cost.impr+Age)\n\n## NEW DV\n    #lm(gwwc_vid_results,DV_costadj~Gender*audience+Age)\n  #lm(gwwc_vid_results,DV~Age*audience+ave.cost.impr+Gender)\n\n  #means for audience\ngwwc_vid_results %>%\n  group_by(audience) %>%\n  summarise(\n    results=mean(DV)*100,\n    SE=std.error(DV)*100,\n    n=n(),\n    cost=mean(ave.cost.impr),\n    CPR=cost/results) %>%\n    .kable %>%\n      .kable_styling()\n\n\n\n \n  \n    audience \n    results \n    SE \n    n \n    cost \n    CPR \n  \n \n\n  \n    philanthropy \n    0.1952968 \n    0.0088502 \n    248,852 \n    0.0219596 \n    0.1124424 \n  \n  \n    animal \n    0.2286178 \n    0.0110380 \n    187,212 \n    0.0222447 \n    0.0973009 \n  \n  \n    climate \n    0.1780810 \n    0.0112754 \n    139,824 \n    0.0181491 \n    0.1019149 \n  \n  \n    general \n    0.1122571 \n    0.0140244 \n    57,012 \n    0.0129917 \n    0.1157312 \n  \n  \n    lookalike \n    0.3444232 \n    0.0225737 \n    67,359 \n    0.0266180 \n    0.0772828 \n  \n  \n    poverty \n    0.1714599 \n    0.0157043 \n    69,404 \n    0.0182429 \n    0.1063975 \n  \n  \n    retargeting \n    0.6666667 \n    0.3840420 \n    450 \n    0.0250444 \n    0.0375667 \n  \n\n\n\n\n\n\n\n1.7.3.2 MESSAGES\nno controls\n\n\nCode\n#lm(gwwc_vid_results,DV~message\n  #control for cost only\n  #lm(gwwc_vid_results,DV~message+ave.cost.impr)\n  #check results with campaign\n  #lm(gwwc_vid_results,DV~Campaign.name)\n  #check results with campaign and cost control\n  #lm(gwwc_vid_results,DV~Campaign.name+ave.cost.impr)\n\n\nwith controls\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience+message)\n\n#interactions\n#with audience\n#lm(gwwc_vid_results,DV~message*audience+ave.cost.impr+Age+Gender)\n#with Gender\n#lm(gwwc_vid_results,DV~message*Gender+ave.cost.impr+Age+audience)\n#with Age (emotional much worse with ages 65+)\n#lm(gwwc_vid_results,DV~message*Age+ave.cost.impr+Age+audience)\n\n\ninteraction with age and campaign restriction\n\n\nCode\n#lm(gwwc_vid_results,DV~message*agetrin+message*restriction18_39+ave.cost.impr+Age+Gender)\n#lm(gwwc_vid_results,DV~message*agetrin+message*restriction18_39+ave.cost.impr)\n\n\nin just early campaigns\n\n\nCode\n#lm(subset(data,restriction18_39==0),DV~message*agetrin+ave.cost.impr)\n\n\n\n\n\n1.7.4 MEDIA\nno controls\n\n\nCode\n#lm(gwwc_vid_results,DV~media)\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% group_by(media) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results)\n\n\n# A tibble: 6 × 6\n  media         results      SE      n   cost    CPR\n  <fct>           <dbl>   <dbl>  <int>  <dbl>  <dbl>\n1 factual short   0.223 0.00820 331287 0.0186 0.0834\n2 animal          0.250 0.0118  180327 0.0274 0.110 \n3 climate         0.186 0.0219   38703 0.0160 0.0862\n4 factual long    0.171 0.0237   30359 0.0378 0.221 \n5 hypercube       0.104 0.0117   75790 0.0176 0.169 \n6 poverty         0.165 0.0121  113647 0.0155 0.0939\n\n\ncontrol for cost only\n\n\nCode\n#lm(gwwc_vid_results,DV~media+ave.cost.impr)"
  },
  {
    "objectID": "chapters/gwwc_gg.html#analysis-and-visuals",
    "href": "chapters/gwwc_gg.html#analysis-and-visuals",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.5 Analysis and visuals",
    "text": "1.5 Analysis and visuals\n8\n\n\nCode\n##gwwc_vid_results$DV_costadj)\n##gwwc_vid_results$DV)\n##gwwc_vid_results$ave.cost.impr)\n\n\nData summary\n\nBelow, a few data summary bits (from Erin). I commented most of it out and will redo it using an automated and formatted ‘key summary statistics’ package.\nI may also present the data in a dashboard for self-service.\n\n\n\nCode\n#datatable(gwwc_vid_results)\n\n\n\n\nCode\ngwwc_vid_results %>% group_by(Age) %>% summarise(n=n()) %>% .kable() %>%  .kable_styling()\n\n\n\n \n  \n    Age \n    n \n  \n \n\n  \n    25-34 \n    287,682 \n  \n  \n    13-17 \n    444 \n  \n  \n    18-24 \n    147,805 \n  \n  \n    35-44 \n    158,352 \n  \n  \n    45-54 \n    48,728 \n  \n  \n    55-64 \n    60,904 \n  \n  \n    65+ \n    66,198 \n  \n\n\n\n\n\nCode\ngwwc_vid_results %>% group_by(Gender) %>% summarise(n=n())  %>% .kable() %>%  .kable_styling()\n\n\n\n \n  \n    Gender \n    n \n  \n \n\n  \n    female \n    573,705 \n  \n  \n    male \n    178,321 \n  \n  \n    unknown \n    18,087 \n  \n\n\n\n\n\nCode\n#print(gwwc_vid_results %>% group_by(Gender,Age) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=40)\n#print(gwwc_vid_results %>% group_by(Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=41)\n#print(gwwc_vid_results %>% group_by(Campaign.name,Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=100)\n\ngwwc_vid_results %>% group_by(audience) %>% summarise(n=n(), cost=mean(ave.cost.impr)*100) %>% .kable(digits=2, caption=\"Average cost per impression (in pennies)\") %>%  .kable_styling()\n\n\n\nAverage cost per impression (in pennies)\n \n  \n    audience \n    n \n    cost \n  \n \n\n  \n    philanthropy \n    248,852 \n    2.20 \n  \n  \n    animal \n    187,212 \n    2.22 \n  \n  \n    climate \n    139,824 \n    1.81 \n  \n  \n    general \n    57,012 \n    1.30 \n  \n  \n    lookalike \n    67,359 \n    2.66 \n  \n  \n    poverty \n    69,404 \n    1.82 \n  \n  \n    retargeting \n    450 \n    2.50 \n  \n\n\n\n\n\nCode\ngwwc_vid_results %>% group_by(message) %>% summarise(n=n(),cost=mean(ave.cost.impr)*100) %>% .kable(digits=2, caption=\"Average cost per impression (in pennies)\") %>%  .kable_styling()\n\n\n\nAverage cost per impression (in pennies)\n \n  \n    message \n    n \n    cost \n  \n \n\n  \n    Factual \n    291,027 \n    2.24 \n  \n  \n    Emotional \n    274,718 \n    2.37 \n  \n  \n    Hypercube \n    75,790 \n    1.76 \n  \n  \n    PPCo \n    128,578 \n    1.25 \n  \n\n\n\n\n\n\n\nCode\n### CHART DATA\n\n#print(gwwc_vid_results %>% group_by(audience,media) %>% #summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)"
  },
  {
    "objectID": "chapters/gwwc_gg.html#notes-from-the-trial-description",
    "href": "chapters/gwwc_gg.html#notes-from-the-trial-description",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.2 Notes from the trial description",
    "text": "1.2 Notes from the trial description\n“In the original version of our test, we had 1 video for the factual appeal and 3 videos for the cause led approach - 1 for global health and development, 1 for animal welfare and 1 for climate change.”\n“We targeted our ads to audiences we thought were likely to engage based on their interests and demographics, and targeted the cause led videos to a relevant audience, i.e. climate change message to climate change audience.”\n“We also had various text above the videos that were displayed and optimised.”\nDetails in Gitbook HERE and Gdoc here\n\n\nCode\nknitr::include_url(\"https://effective-giving-marketing.gitbook.io/untitled/partner-organizations-and-trials/gwwc/giving-guides-+\")"
  },
  {
    "objectID": "chapters/gwwc_gg.html#the-trial",
    "href": "chapters/gwwc_gg.html#the-trial",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.1 The trial",
    "text": "1.1 The trial\nSee full description in the gitbook here.\nContext: Facebook advertisements on a range of audiences\n\nEffective Giving Guide Lead Generation campaign … ran late November 2021 - January 2022. The objective of this campaign was to see whether a factual [‘who researches giving’, ‘magnitude of impact differences’] or cause-led approach was more cost-effective at getting people to fill out a form and give us their email in order to download our Effective Giving Guide.\n\n\n1.1.1 Treatments (text x video)\nThere were two dimensions of treatment content:\n\nThe texts displayed above the videos\n\n\n\n\n\n\n\nTexts\n\n\n\n\n\nBigger difference next year: Want to make a bigger difference next year? Start with our Effective Giving Guide and learn how to make a remarkable impact just by carefully choosing the charities you give to.\n100x impact: Did you know that the best charities can have a 100x greater impact? Download our free Effective Giving Guide for the best tips on doing the most good this holiday season.\n6000 people: Giving What We Can has helped 6,000+ people make a bigger impact on the causes they care about most. Download our free guide and learn how you can do the same.\nCause list: Whether we’re moved by animal welfare, the climate crisis, or worldwide humanitarian efforts, our community is united by one thing: making the biggest impact we can. Make a bigger difference in the world through charitable giving. Start by downloading our Effective Giving Guide. You’ll learn how to approach charity research and smart giving. And be sure to share it with others who care about making a greater impact on the causes closest to their hearts.\nLearn: Use our free guide to learn how to make a bigger impact on the causes you care about most.\nOnly 3% research: Only 3% of donors give based on charity effectiveness yet the best charities can be 100x more impactful. That’s incredible! Check out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes.\nOverwhelming: It can be overwhelming with so many problems in the world. Fortunately, we can do a lot to help, if we give effectively. Check out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes.\n\n\n\n\nThe Video ads theme and content\n\n\n\n\n\n\n\n“Facts”\n\n\n\n\n\n\nCharity research facts short video (8 seconds): Only 3% of donors research charity effectiveness, yet the best charities can 100x your impact, learn how to give effectively \nCharity research facts long video (22 seconds): Trivial things we search (shows someone searching how to do Gangnam style), things we should research (shows someone searching how to donate effectively), only 3% of donors research charity effectiveness, yet the best charities can 100x your impact, learn how to give effectively. Slower paced music compared to the short video and cause videos.  \n\n\n\n\n\n\n\n\n\n\n“Cause focus”\n\n\n\n\n\n\nClimate change (15 seconds): Care about climate change? You don’t have to renounce all your possessions, But you could give to effective environmental charities, Learn how to maximize your charitable impact, Download the Effective Giving Guide \nAnimal welfare (16 seconds): Care about animals? You don’t have to adopt 100 cats, But you could give to effective animal charities, Learn how to maximize your charitable impact, Download the Effective Giving Guide \nPoverty (16 seconds): Want to help reduce global poverty? You don’t have to build a village, But you could give to effective global development charities, Learn how to maximize your charitable impact, Download the Effective Giving Guide \n\n\n\n\n\n\n\n\n\n\nArguments, rich content from “Hypercube”\n\n\n\n\n\n\nHypercube (1 min 22 seconds): Animated and voiceover video that explains how GWWC can help maximize charitable impact (support, community, and information) and the problems GWWC addresses (good intentions don’t always produce the desired outcomes, there are millions of charities that have varying degrees of impact and some can even cause harm). CTA: Check out givingwhatwecan.org to learn how you can become an effective giver.\n\n\n\n\n\n\nFurther detail, links\n\n\n\n\n\n\nNotes from the trial description\n\n\n\n\n\n“In the original version of our test, we had 1 video for the factual appeal and 3 videos for the cause led approach - 1 for global health and development, 1 for animal welfare and 1 for climate change.”\n“We targeted our ads to audiences we thought were likely to engage based on their interests and demographics, and targeted the cause led videos to a relevant audience, i.e. climate change message to climate change audience.”\n“We also had various text above the videos that were displayed and optimized.”\n\n\n\nDetails in Gitbook HERE (and embedded below) and Gdoc here\n\n\nCode\nknitr::include_url(\"https://effective-giving-marketing.gitbook.io/untitled/partner-organizations-and-trials/gwwc/giving-guides-+\")"
  },
  {
    "objectID": "chapters/gwwc_gg.html#implementation-and-treatment-assignment-key-details",
    "href": "chapters/gwwc_gg.html#implementation-and-treatment-assignment-key-details",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.2 Implementation and treatment assignment: key details",
    "text": "1.2 Implementation and treatment assignment: key details\n\n\n\n\n\n\nTreatment assignment order, dates\n\n\n\n\n\nThe treatment assignment was determined by Facebook’s algorithm. Video content was manipulated across three split tests. Test 1 (Nov 30, 2021 – Dec 8, 2021) displayed either the long factual video or a cause focus video. In the cause focus condition, cause-specific audiences for animal rights, climate change, and poverty (based on their behavior on Facebook) were shown the relevant cause video.\nTest 2 (add dates) was the same as Test 1 but used the short factual video instead of the cause-focus videos.\nTest 3 (add dates) was the same as Test 2 but had a new version of the videos (with Luke just holding up signs with the words). This test was also restricted to 18-35 year olds.\nTest 4: The Hypercube video was displayed in a separate “Hypercube” campaign which was tested against another campaign that allowed the algorithm to optimize between the short factual and cause focus videos (although not allowing each cause specific audience to see the ads for other cause areas).\nIn all tests, the text content displayed above the video was determined by Facebook’s algorithm. Balance across variations was determined to equate budgets across split tests; otherwise, according to Facebook’s algorithm. All variation was done at the level of the impression.\nThe videos were adapted across the trials as we learned. First, we updated the factual video to be shorter for Trial 2, and then we tried videos of Luke holding up signs spelling out the voiceover in Trial 3 for all videos."
  }
]