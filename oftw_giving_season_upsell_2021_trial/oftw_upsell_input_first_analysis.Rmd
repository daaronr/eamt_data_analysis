# OftW pre-giving-tuesday-email upselling split test (considering 'impact vs emotion')

## The trial

In December 2021, OftW sent out a sequence of emails to existing OftW pledgers/participants asking them for an additional donation. There were two 'treatment variants'; an emotional email and a standard impact-based email. The treatment was constant by individual (the same person always got emails with the same theme.

The details are presented in our (currently private) gitbook [HERE](https://app.gitbook.com/o/-MfFk4CTSGwVOPkwnRgx/s/-Mf8cHxdwePMZXRTKnEE/contexts-and-environments-for-testing/one-for-the-world/pre-giving-tuesday-email-split-test) and in the linked pre-registration (also on OSF).

## Capturing data

Kennan and Chloe captured the data and Metadata from

1. The OFTW database
2. SurveyMonkey

Putting this into the (private) Google sheet linked [HERE](https://docs.google.com/spreadsheets/d/1iUKXkEqoadBgtUG_epBzUzCgA_J5mdWWstcXtpAdNJs/edit#gid=521638649)

We added some metadata/explainers to that data.^[Todo -- more direct input through API tools; package bigrquery for bitquery.]


<!-- (This is gitignored so it won't be 'committed' to our repo, at least for now)

Quick note here on how Kennan put the (different types of) data together in that Gsheet. We probably should use the API tool to import it directly here. -->



## Input and clean data

We input the sheets from the external Google sheet location (access required)...

```{r oftw_21_22_mc, warning=FALSE, message=FALSE}

gs4_auth(scope = "https://www.googleapis.com/auth/drive")
drive_auth(token = gs4_token())

#Mailchimp data 

oftw_21_22_mc <- read_sheet("https://docs.google.com/spreadsheets/d/1iUKXkEqoadBgtUG_epBzUzCgA_J5mdWWstcXtpAdNJs/edit#gid=521638649", 
  sheet="Raw data (Mailchimp)")  %>% 
  select(-`Treatment group`) %>%  #remove an un-useful repeated name column 
    mutate(`Treatment Group` = purrr::map_chr(`Treatment Group`, ~ .[[1]])) %>%
  select(`Email Address`, `Email Date`, `Treatment Group`, Opens, `Donate link clicks`, everything()) %>% #Most relevant features organized first
  arrange(`Email Address`)


#later: remove features brought in from OFTW database, reconstruct it

oftw_21_22_mc %>% names() %>% paste(collapse=", ")
 
#...input descriptors for the above (do this later from "doc: ...Mailchimp" sheet

```

```{r oftw_21_22_db_don, warning=FALSE, message=FALSE}

#Donations data (and OftW database info)

oftw_21_22_db_don <- read_sheet(
  "https://docs.google.com/spreadsheets/d/1iUKXkEqoadBgtUG_epBzUzCgA_J5mdWWstcXtpAdNJs/edit#gid=521638649", 
  sheet="Giving Season contributions (BigQuery)") %>% 
  mutate(`Treatment group` = purrr::map_chr(`Treatment group`, ~ .[[1]])) %>%
    select(`email`, `primary_email`, `donation_date`, `Net_Contribution_Amount_USD`, `payment_platform`, everything()) %>%  #Most relevant features organized first
  filter(donation_date>=as.Date("2021-11-15")) # At least for now, remove pre-treatment donation data

oftw_21_22_db_don %>% names() %>% paste(collapse=", ")


```

<!-- 

For the first question, we'll need to transform the contribution data to look at how many contributions came from people in each group who actually opened the emails (Column D) and then further subset it to just website donations (ie Column I = "Squarespace").

For the second, I just updated the formulas in both of those columns. Remember that, since the Raw Data (Mailchimp) tab holds one observation for each email-open by a given donor, an individual donor may appear up to five times. Accordingly, summing these aggregated columns will vastly inflate the totals. We may be better off making a unique() call to the emails and constructing a donor-level dataset separately. Happy to talk more tomorrow (or next week if those times don't work).
-->



### Labeling and cleaning 


The code ... 

...makes names `snake_case`, using original names as labels...

```{r}

labelled::var_label(oftw_21_22_mc) <- names(oftw_21_22_mc) 
names(oftw_21_22_mc) <- snakecase::to_snake_case(names(oftw_21_22_mc)) 

labelled::var_label(oftw_21_22_db_don) <- names(oftw_21_22_db_don) 
names(oftw_21_22_db_don) <- snakecase::to_snake_case(names(oftw_21_22_db_don)) 
```

<!--Todo: Remove useless columns -->


...and anonymizes the data, hashing anything with the chance of being identifying

```{r}

salty_hash <- function(x) {
  salt(.seed = 42, x) %>% hash(.algo = "crc32")
}

oftw_21_22_mc <- oftw_21_22_mc %>%
  dplyr::select(-first_name, -last_name) %>%
    mutate(across(c(email_address,  employer, school_string), salty_hash))

  
oftw_21_22_db_don <- oftw_21_22_db_don %>%
      mutate(across(c(primary_email, email, school), salty_hash))

```

Roll up to 1 per person; summarize and pivot_wider

```{r}

outcomes_base_mc <- c("opens", "donate_link_clicks")

oftw_21_22_mc_wide <- oftw_21_22_mc %>%
  group_by(email_address) %>%
      mutate(across(all_of(outcomes_base_mc), sum, .names = "{.col}_tot")) %>% 
  tidyr::pivot_wider(names_from = email_number, values_from = c("opens", "donate_link_clicks")) %>%
  arrange(email_address) %>%
  filter(row_number()==1)

oftw_21_22_db_don <- oftw_21_22_db_don %>%
  group_by(email) %>%
    mutate(
      don_tot = sum(net_contribution_amount_usd),
      num_don= n(),
      d_don = num_don>0,
      don_tot_ot = sum(net_contribution_amount_usd[contribution_frequency=="One-time"]),
      num_don_ot= sum(contribution_frequency=="One-time"),
      d_don_ot = num_don_ot>0, #WAIT THIS IS NOT WIDE DATA -- don't interpret it as 'number of individuals'
      don_tot_ss = sum(net_contribution_amount_usd[payment_platform=="Squarespace"]),
      num_don_ss= sum(payment_platform=="Squarespace"),
      d_don_ss = num_don_ss>0,
      ) 


oftw_21_22_db_don_persons <- oftw_21_22_db_don %>%  
  arrange(email) %>%
  filter(row_number()==1)

# oftw_21_22_db_don_wide <- oftw_21_22_db_don %>%
#   select(email, donation_date, net_contribution_amount_usd, payment_platform) %>% 
#    group_by(email) %>%
#    mutate(row = row_number()) %>%
#       tidyr::pivot_wider(names_from = row, values_from = c("donation_date", "net_contribution_amount_usd"))

```


Prelim results 
```{r}


oftw_21_22_db_don_persons %>% tabyl(treatment_group, d_don)
oftw_21_22_db_don_persons %>% tabyl(treatment_group, d_don_ss)
oftw_21_22_db_don_persons %>% tabyl(treatment_group, d_don_ot)



```

### Constructing outcome measures, especially  'donations likely driven by email'


1. Donations (presence, count, amounts) in giving seasons, 1 row per user (with treatment etc.)

- overall
- non-regular
- 'likely from email'





are in Giving Season contributions (BigQuery)

- subset for payment platform = squarespace (unlikely to come from any other checkout page)
- email as primary key, link to `Raw Data (mailchimp)`, filter on 'Donate link clicks`>0
(note that one needs aggregating by donor because it is 'per email')


2. Giving season donations .. 

Giving Season contributions (BigQuery), sum donation_date	Net_Contribution_Amount_USD with filters for one-time etc

Can check against fields 'Total Giving Season contributions	Total Giving Season contribution amount' 


Could make a nested array:
- Dates emails sent, number of clicks per email
- Dates donations made, donation amount

## Descriptives and exploratory analysis

We could and should do a great deal of this. We should present the results relevant to this trial in specific here. Elsewhere we can do a deeper dive into OftW data in a general sense.   


### Donation and outcome summary statistics, by treatment

Incidence rates

## Basic tests: Donation incidence and amounts

(See preregistration -- go through preregistered tests one at a time. Note that given observed conversion rates I do not expect any 'significant differences'.)   

## Basic tests: Clicks and retention outcomes

## "Equivalence testing" with randomization inference/simulation    

We see a 'small difference' between and it is 'not significant in standard' (tests not shown here yet). But can we put meaningful bounds on this? Can we statistically 'rule out large effects'?
                
(This parallels the analysis done in  [HERE](https://rethinkpriorities.github.io/methodology-statistics-design/inference-and-rough-equivalence-testing-with-binomial-outcomes.html#how-likely-are-proportions-this-similar-under-different-size-true-effect-sizes), which includes dome further explanation of the methods)



###  Difference between two binomial random variables.

First, some building blocks. 

**Adapting formulas from [Stackexchange post](https://math.stackexchange.com/questions/562119/difference-of-two-binomial-random-variables) discussion**

Defining their code for this function:
```{r}
modBin <-dbinom #DR: I just do this renaming here for consistency with the rest ... but the modBin they defined was redundant

diffBin<-function(z, n1, p1, n2, p2){

  prob <- 0

  if (z>=0){
    for (i in 1:n1){
      prob <- prob + modBin(i+z, n1, p1) * modBin(i, n2, p2)
    }

  }
  else
  {
    for (i in 1:n2){
      prob<-prob+modBin(i+z, n1, p1)*modBin(i, n2, p2)
    }
  }
  return(prob)
}
```



For the present case

 Hard-coded notes...
 
::: {.foldable} 


Treatment 1 - Impact and
Treatment 2 - Emotion Story tabs

Treatment 1: We record
- 8 unique emails donating, 26 donations in total,
- worth 5200 USD in total
- 1345 unique emails listed as getting  ‘control’ treatment 1

Treatment 2:
-  6 unique emails, 28 donations so far
—  worth 7500 USD in total.
- 1190 unique emails listed for treatment 2

If I believe my ‘unique emails count’, that implies
an 0.59% ‘conversion’ rate for T1 - Control
a 0.50% conversion rate for T2 - Emotion/Story
 
:::

Putting the observations into defined objects 


<!-- Doing this from the (later: do from data) -->


```{r}

n1 <- 1345
n2 <- 1190
d1 <- 8
d2 <- 6
z <- d1-d2

```

Computation for a few 'ad-hoc cases' (later explore the space with vectors of values)

1. Suppose truly equal incidence, at the mean level

```{r}
p1 <- (d1+d2)/(n1+n2)

p2 <- p1

(
  db_0 <- diffBin(z, n1, p1, n2, p2)
)
```

This implies there is a `r op(db_0*100)`% chance of getting this *exact* difference of +`r z` incidences between the treatments (in one direction), if the true incidence rates were equal.

Let's plot this for a range of 'incidence rate differences' in this region. (Sorry, using the traditional plot, ggplot is better).

```{r}

s <- seq(-10*z, 10*z)
p<-sapply(s, function(z) diffBin(z, n1, p1, n2, p2))
plot(s,p)
```

We see a large likelihood of values in the range of the +`r z` difference observed, and a low likelihood of a difference of 10 or more in either direction.

### Adaptation: 'of this magnitude or smaller'

```{r}

ltmag_diffBin <- function(z, n1, p1, n2, p2){
  prob <- 0
  z_n <- -z #negative value

  for (i in z_n:z){     #sum for all integer differences between observed value and its negative, inclusive
    prob <- prob + diffBin(i, n1, p1, n2, p2)
    }

  return(prob)
}
```

Now, a similar computation as above, but for 'this big or smaller in magnitude':

```{r}
  (
    mag_db_0 <- ltmag_diffBin(z, n1, p1, n2, p2)
  )
```

This implies there is a `r op(mag_db_0*100)`% chance of getting a difference *no larger than this one in magnitude* of +/-`r z` incidences between the treatments if the true incidence rates were equal.

\

**And finally, what we were looking for:** the chance of 'a difference this small or smaller' as a function of the **true difference...**

Set up an arbitrary vector of 'true differences' (to keep it simple, only change it in one direction for now ...)


Below, I plot

Y-axis: ’how likely would a difference in donations ‘as small or smaller in magnitude’” than we see in the data  against

X-axis: if the “true difference in incidence rates” were of these magnitudes

```{r}

options(scipen=999)

B <- c(1, 1.5, 2, 2.5, 3, 4, 10)

p1 <- rep((d1+d2)/(n1+n2), length(B))
p2 <- p1*B


as.list(ltmag_diffBin(z, n1, p1, n2, p2)*100) %>% format(digits=3, scientific=FALSE)


probmag <- ltmag_diffBin(z, n1, p1, n2, p2)


#qplot(B, probmag, log  = "x", xlab = "True relative incidence", ylab ="Prob. of difference this small")

(
  probmag_plot <-
    ggplot() +
  aes(x=B, y=probmag) +
  geom_point() +
  scale_x_continuous(trans='log2') +
    ylim(0,.51) +
    xlab("True relative incidence rate") +
    ylab("Prob. diff. as small as obsd")

)

```


Hard-coded takeaways 15 Dec 2021 :

Our data is consistent with ‘no difference’ (of course) ... but its also consistent with ‘a fairly large difference in incidence’

E.g., even if one treatment truly lead to ‘twice as many donations as the other’, we still have a 20% chance of seeing a differences as small as the one we see (of 8 versus 6)

We can reasonably ‘rule out’ differences of maybe 2.5x or greater


Main point: given the rareness of donations in this context, our sample size doesn’t let us make very strong conclusions in either directions … at least not yet. I hope that combined with other evidence, we will be able to infer more


### Quick redo assuming equal shares recieved each email, and treating 'email reciepts as denom'

Approx 4000 total emails sent?

For squarespace

```{r}

n1 <- 2000
n2 <- 2000
d1 <- 8
d2 <- 9
z <- d1-d2

B <- c(1/3, 1/2.5, 1/2, 1/1.5, 1, 1.5, 2, 2.5, 3)

p1 <- rep((d1+d2)/(n1+n2), length(B))
p2 <- p1*B


(
    mag_db_0 <- ltmag_diffBin(z, n1, p1, n2, p2)
  )

```   



For all one-time donations 

```{r}

n1 <- 2000
n2 <- 2000
d1 <- 15
d2 <- 12
z <- d1-d2

B <- c(1/3, 1/2.5, 1/2, 1/1.5, 1, 1.5, 2, 2.5, 3)

p1 <- rep((d1+d2)/(n1+n2), length(B))
p2 <- p1*B


(
    mag_db_0 <- ltmag_diffBin(z, n1, p1, n2, p2)
  )

```   

