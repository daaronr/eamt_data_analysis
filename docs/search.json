[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EA Market testing data analysis",
    "section": "",
    "text": "However, we’re not sure yet if and how it can be integrated with the https://app.gitbook.com/ content.↩︎\nNote: as this is Quarto and not Rmd, packages need to be loaded in every chapter. I’ll put these in code/shared_packages_code.R.↩︎"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html",
    "href": "chapters/oftw_upsell_input_first_analysis.html",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "",
    "text": "In December 2021, OftW sent out a sequence of emails to existing OftW pledgers/participants asking them for an additional donation. Ther e were two ‘treatment variants’; an emotional email and a standard impact-based email. The treatment was constant by individual (the same person always got emails with the same theme.\nThe details are presented in our (currently private) gitbook HERE and in the linked pre-registration (also on OSF)."
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#capturing-data",
    "href": "chapters/oftw_upsell_input_first_analysis.html#capturing-data",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.2 Capturing data",
    "text": "1.2 Capturing data\nKennan and Chloe captured the data and Metadata from\n\nThe OFTW database\nSurveyMonkey\n\nPutting this into the (private) Google sheet linked HERE\nWe added some metadata/explainers to that data.1"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#input-and-clean-data",
    "href": "chapters/oftw_upsell_input_first_analysis.html#input-and-clean-data",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.3 Input and clean data",
    "text": "1.3 Input and clean data\nWe input the sheets from the external Google sheet location (access required)…\n\n\nCode\ngs4_auth(scope = \"https://www.googleapis.com/auth/drive\")\ndrive_auth(token = gs4_token())\n\n#Mailchimp data \n\noftw_21_22_mc <- read_sheet(\"https://docs.google.com/spreadsheets/d/1iUKXkEqoadBgtUG_epBzUzCgA_J5mdWWstcXtpAdNJs/edit#gid=521638649\", \n  sheet=\"Raw data (Mailchimp)\")  %>% \n  select(-`Treatment group`) %>%  #remove an un-useful repeated name column \n    mutate(`Treatment Group` = purrr::map_chr(`Treatment Group`, ~ .[[1]])) %>%\n  select(`Email Address`, `Email Date`, `Treatment Group`, Opens, `Donate link clicks`, everything()) %>% #Most relevant features organized first\n  arrange(`Email Address`)\n\n\n#later: remove features brought in from OFTW database, reconstruct it\n\noftw_21_22_mc %>% names() %>% paste(collapse=\", \")\n\n\n[1] \"Email Address, Email Date, Treatment Group, Opens, Donate link clicks, sheet_descriptor, First Name, Last Name, Email Number, Class Year, Donor status, Total Given, Donation amount, Donation frequency, Start string, Platform, Portfolio string, Class lead, Impact 1, Impact 2, Impact 3, Employer, Pledge string, School string, Pledge year, Cancellation Type, Donation Amount String, OFTW matching, OFTW match amount, Corporate match amount, Bonuses announced, Post-bonus contact date, Email Preferences, Start Date, Lives Saved, Member Rating, Record rank, Total Giving Season contributions, Total Giving Season contribution amount\"\n\n\nCode\n#...input descriptors for the above (do this later from \"doc: ...Mailchimp\" sheet\n\n\n\n\nCode\n#Donations data (and OftW database info)\n\noftw_21_22_db_don <- read_sheet(\n  \"https://docs.google.com/spreadsheets/d/1iUKXkEqoadBgtUG_epBzUzCgA_J5mdWWstcXtpAdNJs/edit#gid=521638649\", \n  sheet=\"Giving Season contributions (BigQuery)\") %>% \n  mutate(`Treatment group` = purrr::map_chr(`Treatment group`, ~ .[[1]])) %>%\n    select(`email`, `primary_email`, `donation_date`, `Net_Contribution_Amount_USD`, `payment_platform`, everything()) %>%  #Most relevant features organized first\n  filter(donation_date>=as.Date(\"2021-11-15\")) # At least for now, remove pre-treatment donation data\n\noftw_21_22_db_don %>% names() %>% paste(collapse=\", \")\n\n\n[1] \"email, primary_email, donation_date, Net_Contribution_Amount_USD, payment_platform, Treatment group, Number of email opens, oftw_partner, school, chapter_type, portfolio, contribution_frequency, pledge_date, pledge_start_date, pledge_end_date, donor_status, cancellation_type, pledge_amount, pledge_contribution_frequency, x\"\n\n\n\n\n1.3.1 Labeling and cleaning\nThe code …\n…makes names snake_case, using original names as labels…\n\n\nCode\nlabelled::var_label(oftw_21_22_mc) <- names(oftw_21_22_mc) \nnames(oftw_21_22_mc) <- snakecase::to_snake_case(names(oftw_21_22_mc)) \n\nlabelled::var_label(oftw_21_22_db_don) <- names(oftw_21_22_db_don) \nnames(oftw_21_22_db_don) <- snakecase::to_snake_case(names(oftw_21_22_db_don)) \n\n\n\n…and anonymizes the data, hashing anything with the chance of being identifying\n\n\nCode\nsalty_hash <- function(x) {\n  salt(.seed = 42, x) %>% hash(.algo = \"crc32\")\n}\n\noftw_21_22_mc <- oftw_21_22_mc %>%\n  dplyr::select(-first_name, -last_name) %>%\n    mutate(across(c(email_address,  employer, school_string), salty_hash))\n\n  \noftw_21_22_db_don <- oftw_21_22_db_don %>%\n      mutate(across(c(primary_email, email, school), salty_hash))\n\n\nRoll up to 1 per person; summarize and pivot_wider\n\n\nCode\noutcomes_base_mc <- c(\"opens\", \"donate_link_clicks\")\n\n\noftw_21_22_mc_wide <- oftw_21_22_mc %>%\n  mutate(treat_emotion = case_when(\n    treatment_group == \"1.000000\" ~ 0,\n    treatment_group == \"2.000000\" ~ 1\n  )) %>%\n  group_by(email_address) %>%\n  mutate(across(all_of(outcomes_base_mc), sum, .names = \"{.col}_tot\")) %>%\n  tidyr::pivot_wider(names_from = email_number,\n    values_from = c(\"opens\", \"donate_link_clicks\")) %>%\n  mutate(d_click_don_link = donate_link_clicks_tot > 0) %>%\n  arrange(email_address) %>%\n  filter(row_number() == 1)\n\noftw_21_22_db_don <- oftw_21_22_db_don %>%\n  ungroup() %>%\n  group_by(email) %>%\n  mutate(\n    don_tot = sum(net_contribution_amount_usd),\n    num_don = n(),\n    d_don = num_don > 0,\n    don_tot_ot = sum(net_contribution_amount_usd[contribution_frequency ==\n        \"One-time\"]),\n    num_don_ot = sum(contribution_frequency == \"One-time\"),\n    d_don_ot = num_don_ot > 0,\n    #WAIT THIS IS NOT WIDE DATA -- don't interpret it as 'number of individuals'\n    don_tot_ss = sum(net_contribution_amount_usd[payment_platform == \"Squarespace\"]),\n    num_don_ss = sum(payment_platform == \"Squarespace\"),\n    d_don_ss = num_don_ss > 0,\n  )\n\n\noftw_21_22_db_don_persons <- oftw_21_22_db_don %>%  \n  arrange(email) %>%\n  filter(row_number()==1)     %>%\nmutate(\n      treat_emotion = case_when(\n        treatment_group==\"1.000000\" ~ 0,\n        treatment_group == \"2.000000\" ~ 1)\n    ) \n\n\noftw_mc_db <- power_full_join(oftw_21_22_mc_wide,\n   oftw_21_22_db_don_persons,  by = c(\"email_address\" = \"email\"), conflict = coalesce_xy) %>%\n   mutate(across(starts_with(\"d_don\"), ~replace(., is.na(.), 0)), #make it a 0 if it's not in the donation database\n   d_open= if_else(!is.na(treat_emotion),1,0)\n  )\n\n\noftw_mc_db_openers <- oftw_mc_db %>% \n  filter(!is.na(treat_emotion))\n\n# oftw_21_22_db_don_wide <- oftw_21_22_db_don %>%\n#   select(email, donation_date, net_contribution_amount_usd, payment_platform) %>% \n#    group_by(email) %>%\n#    mutate(row = row_number()) %>%\n#       tidyr::pivot_wider(names_from = row, values_from = c(\"donation_date\", \"net_contribution_amount_usd\"))\n\n\nPrelim results ::: {.cell}\n\nCode\noftw_mc_db %>% tabyl(treat_emotion, d_don)\n\n\n treat_emotion    0   1\n             0 1139 273\n             1  968 231\n            NA    0 395\n\n\nCode\noftw_mc_db %>% tabyl(treat_emotion, d_don_ss)\n\n\n treat_emotion    0 1\n             0 1404 8\n             1 1190 9\n            NA  391 4\n\n\nCode\noftw_21_22_db_don_persons %>% tabyl(treat_emotion, d_don_ot)\n\n\n treat_emotion FALSE TRUE NA_\n             0   248   15  10\n             1   215   12   4\n            NA   328   59   8\n\n\nCode\n#todo: simple statistical measures along with this\n\n:::\n\n\n1.3.2 Constructing outcome measures, especially ‘donations likely driven by email’\n\nDonations (presence, count, amounts) in giving seasons, 1 row per user (with treatment etc.)\n\n\noverall\nnon-regular\n‘likely from email’\n\nare in Giving Season contributions (BigQuery)\n\nsubset for payment platform = squarespace (unlikely to come from any other checkout page)\nemail as primary key, link to Raw Data (mailchimp), filter on ‘Donate link clicks`>0 (note that one needs aggregating by donor because it is ’per email’)\n\n\nGiving season donations ..\n\nGiving Season contributions (BigQuery), sum donation_date Net_Contribution_Amount_USD with filters for one-time etc\nCan check against fields ‘Total Giving Season contributions Total Giving Season contribution amount’\n\n\n\nCode\n#list/matrix of rates for later use\n\noc_mat <- oftw_mc_db %>% \n  mutate(d_open=n()) %>% \n  group_by(treat_emotion) %>% \n  dplyr::summarise(across(starts_with(\"d_\"), ~sum(.x, na.rm = TRUE), .names = \"tot_{.col}\"))\n\noc_mat_r <- oc_mat %>% filter(!is.na(treat_emotion)) #where treatment observed \n\nassigned_emails <- c(2000, 2000) #I was told that about 4000 emails were sent, 2000 to each group"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#descriptives-and-exploratory-analysis",
    "href": "chapters/oftw_upsell_input_first_analysis.html#descriptives-and-exploratory-analysis",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.4 Descriptives and exploratory analysis",
    "text": "1.4 Descriptives and exploratory analysis\nNotes:2\n\n1.4.1 Donation and outcome summary statistics, by treatment"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#basic-tests-donation-incidence-and-amounts",
    "href": "chapters/oftw_upsell_input_first_analysis.html#basic-tests-donation-incidence-and-amounts",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.5 Basic tests: Donation incidence and amounts",
    "text": "1.5 Basic tests: Donation incidence and amounts\n(See preregistration – go through preregistered tests one at a time. Note that given the observed conversion rates I do not expect any ‘significant differences’.)"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#basic-tests-clicks-and-retention-outcomes",
    "href": "chapters/oftw_upsell_input_first_analysis.html#basic-tests-clicks-and-retention-outcomes",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.6 Basic tests: Clicks and retention outcomes",
    "text": "1.6 Basic tests: Clicks and retention outcomes\nI’m following the approach discussed in the ‘RP methods discussion’ under “Significance and equivalence testing” with randomization inference/simulation; building to Bayes\nWe see a ‘small difference’ between treatment groups and it is ‘not significant in standard tests’ (tests not shown here yet). But can we put meaningful bounds on this? Can we statistically ‘rule out large effects’?\n(This parallels the analysis done in HERE, which includes some further explanation of the methods)\n\n\n\n1.6.1 Difference between two binomial random variables: Bayesian binomial test\n\n\nCode\n#would need to generate 'fill in data' if we want to use bayesAB, which requires actual vectors\n\n#add blank rows for 'assigned'\n\nblank_impact <- as_tibble(matrix(NA, nrow = assigned_emails[1]- oc_mat_r$tot_d_open[1], ncol = NCOL(oftw_mc_db)))\n\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0.\nUsing compatibility `.name_repair`.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\n\nCode\nnames(blank_impact) <- names(oftw_mc_db)\n\nblank_impact %<>% \n  mutate(across(starts_with(\"d_\"), ~ifelse(is.na(.), 0, 0)),\n    treat_emotion=0)\n  \nblank_emotion <- as_tibble(matrix(NA, nrow = assigned_emails[1]- oc_mat_r$tot_d_open[2], ncol = NCOL(oftw_mc_db)))\nnames(blank_emotion) <- names(oftw_mc_db)\n\nblank_emotion %<>% \n  mutate(across(starts_with(\"d_\"), ~ifelse(is.na(.), 0, 0)),\n    treat_emotion=1)\n\noftw_mc_db_assigned <- \n    bind_rows(oftw_mc_db, blank_impact, blank_emotion) %>%\n  filter(!is.na(treat_emotion))\n\noftw_mc_db_assigned %>% tabyl(treat_emotion)\n\n\n treat_emotion    n percent\n             0 2000     0.5\n             1 2000     0.5\n\n\nOpens by treatment:\n\n\nCode\n# Following r https://www.sumsar.net/blog/2014/06/bayesian-first-aid-prop-test/  \n# alt: http://frankportman.github.io/bayesAB/ \n\n\n#opens_by_treat_fit <- bayes.prop.test(oc_mat_r$tot_d_open, assigned_emails, cred.mass = 0.95) #here I highlight the 95% bounds because it's a strong effect!\n\n#plot(opens_by_treat_fit)\n\nunif_prior <- c('alpha' = 1, 'beta' = 1)\n \nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_open), 'beta' = sum(assigned_emails))\n\n\n#same with AB  package\n# Fit bernoulli test\nopens_by_treat_AB <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_open[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_open[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\nopens_by_treat_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_open[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_open[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(opens_by_treat_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(opens_by_treat_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\n#WTF -- I need to advance this by command prompt!?\n\n#AB1 <- bayesTest(oftw_21_22_db_don_persons$d_don_ot[trea], B_binom, priors = c('alpha' = 65, 'beta' = 200), n_samples = 1e5, distribution = 'bernoulli')\n\n\n\n\n‘Some donation’ by treatment (only for those who opened, otherwise donations are surely undercounted for Emotion treatment)\n\n\nCode\noftw_21_22_db_don_persons %>% tabyl(treat_emotion, d_don)\n\n\n treat_emotion TRUE\n             0  273\n             1  231\n            NA  395\n\n\nCode\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_don), 'beta' = sum(oc_mat_r$tot_d_open))\n\n(\n  don_by_treat_opened_fit <- bayes.prop.test(oc_mat_r$tot_d_don, oc_mat_r$tot_d_open, cred.mass = 0.80) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_don out of oc_mat_r$tot_d_open\nnumber of successes:   273,  231\nnumber of trials:     1412, 1199\nEstimated relative frequency of success [80% credible interval]:\n  Group 1: 0.19 [0.18, 0.21]\n  Group 2: 0.19 [0.18, 0.21]\nEstimated group difference (Group 1 - Group 2):\n  0 [-0.02, 0.02]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.515 and larger for Group 2 by a probability of 0.485 .\n\n\nCode\nplot(don_by_treat_opened_fit)\n\n\n\n\n\nCode\n#same with AB  package\n# Fit bernoulli test\ndon_by_treat_AB <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don[oftw_mc_db_openers$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_by_treat_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don[oftw_mc_db_openers$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(don_by_treat_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_by_treat_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nThus we put 80% probability on the difference between the donation rates being no more than (hard-coded) .023/.19 = 12% in either direction. Note that this is not terribly narrowly bounded.\n\n\nNext, for one-time donations only; again as a share of opens\n\n\nCode\n(\n  don_ot_by_treat_opened_fit <- bayes.prop.test(oc_mat_r$tot_d_don_ot, oc_mat_r$tot_d_open, cred.mass = 0.80) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_don_ot out of oc_mat_r$tot_d_open\nnumber of successes:    15,   12\nnumber of trials:     1412, 1199\nEstimated relative frequency of success [80% credible interval]:\n  Group 1: 0.011 [0.0075, 0.015]\n  Group 2: 0.011 [0.0068, 0.014]\nEstimated group difference (Group 1 - Group 2):\n  0 [-0.0048, 0.0056]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.55 and larger for Group 2 by a probability of 0.45 .\n\n\nCode\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_don_ot), 'beta' = sum(oc_mat_r$tot_d_open))\n\n#same with AB  package\n# Fit bernoulli test\ndon_ot_by_treat_AB <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don_ot[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don_ot[oftw_mc_db_openers$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_ot_by_treat_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don_ot[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don_ot[oftw_mc_db_openers$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(don_ot_by_treat_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_ot_by_treat_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\ndon_ot_by_treat_AB %>% summary(credInt=0.9)\n\n\nQuantiles of posteriors for A and B:\n\n$Probability\n$Probability$A\n         0%         25%         50%         75%        100% \n0.002702340 0.009300256 0.011076158 0.013056869 0.028481793 \n\n$Probability$B\n         0%         25%         50%         75%        100% \n0.002578133 0.008699817 0.010557270 0.012664164 0.031399003 \n\n\n--------------------------------------------\n\nP(A > B) by (0)%: \n\n$Probability\n[1] 0.5518\n\n--------------------------------------------\n\nCredible Interval on (A - B) / B for interval length(s) (0.9) : \n\n$Probability\n       5%       95% \n-0.434144  0.969118 \n\n--------------------------------------------\n\nPosterior Expected Loss for choosing A over B:\n\n$Probability\n[1] 0.1618676\n\n\nCode\ndon_ot_by_treat_AB_lift_int80 <- don_ot_by_treat_AB %>% summary(credInt=0.8)\n\n\ndon_ot_by_treat_AB_lift_int80_empir <- don_ot_by_treat_AB_empir %>% summary(credInt=0.8)\n\n\n80% credible intervals with the uniform prior for the ‘lift’ of Impact relative to Emotion are\n-0.351, 0.707\nand for the empirically informed (but symmetric prior):\n-0.234, 0.357\n(Hard-coded) Here there is just a trace of suggestive evidence that the emotion treatment performed worse. But even our 80% bounds are very wide.\n\n\nFor ‘Squarespace donations only’; these are the donations that plausibly came from the email. First as a share of opens for each treatment :\n\n\nCode\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_don_ss), 'beta' = sum(oc_mat_r$tot_d_open))\n\n\n(\n  don_ss_by_treat_opened_fit <- bayes.prop.test(oc_mat_r$tot_d_don_ss, oc_mat_r$tot_d_open, cred.mass = 0.80) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_don_ss out of oc_mat_r$tot_d_open\nnumber of successes:     8,    9\nnumber of trials:     1412, 1199\nEstimated relative frequency of success [80% credible interval]:\n  Group 1: 0.0062 [0.0033, 0.0085]\n  Group 2: 0.0081 [0.0047, 0.011]\nEstimated group difference (Group 1 - Group 2):\n  0 [-0.0062, 0.0023]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.282 and larger for Group 2 by a probability of 0.718 .\n\n\nCode\n#same with AB  package\n# Fit bernoulli test\ndon_ss_by_treat_AB <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don_ss[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don_ss[oftw_mc_db_openers$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_ss_by_treat_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_openers$d_don_ss[oftw_mc_db_openers$treat_emotion==0],\n  oftw_mc_db_openers$d_don_ss[oftw_mc_db_openers$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\n\nplot(don_ss_by_treat_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_ss_by_treat_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\ndon_ss_by_treat_AB %>% summary(credInt=0.9)\n\n\nQuantiles of posteriors for A and B:\n\n$Probability\n$Probability$A\n          0%          25%          50%          75%         100% \n0.0009902386 0.0048437368 0.0061367516 0.0076340142 0.0191421384 \n\n$Probability$B\n         0%         25%         50%         75%        100% \n0.001462728 0.006437438 0.008042132 0.009891706 0.025724099 \n\n\n--------------------------------------------\n\nP(A > B) by (0)%: \n\n$Probability\n[1] 0.27906\n\n--------------------------------------------\n\nCredible Interval on (A - B) / B for interval length(s) (0.9) : \n\n$Probability\n        5%        95% \n-0.6515304  0.6391667 \n\n--------------------------------------------\n\nPosterior Expected Loss for choosing A over B:\n\n$Probability\n[1] 0.5346835\n\n\nCode\ndon_ss_by_treat_AB_lift_int80 <- don_ss_by_treat_AB %>% summary(credInt=0.8)\n\n\ndon_ss_by_treat_AB_lift_int80_empir <- don_ss_by_treat_AB_empir %>% summary(credInt=0.8)\n\n\n80% credible intervals with the uniform prior for the ‘lift’ of Impact relative to Emotion are\n-0.583, 0.383\nand for the empirically informed (but symmetric prior):\n-0.367, 0.304\n(Hard-coded) Again, even our 80% bounds are very wide.\n\n\nFinally, we consider the above as a share of total emails sent, allowing that ‘opens’ is non-random,\n… and also implicitly assuming that the only impact of these treatments could be on the Squarespace donations made by someone who did open the email.\n\n\nCode\n(\n  don_ss_by_treat_opened_fit_all <- bayes.prop.test(oc_mat_r$tot_d_don_ss, assigned_emails,\n    cred.mass = 0.80) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_don_ss out of assigned_emails\nnumber of successes:     8,    9\nnumber of trials:     2000, 2000\nEstimated relative frequency of success [80% credible interval]:\n  Group 1: 0.0043 [0.0025, 0.0062]\n  Group 2: 0.0049 [0.0029, 0.0067]\nEstimated group difference (Group 1 - Group 2):\n  0 [-0.0033, 0.0022]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.405 and larger for Group 2 by a probability of 0.595 .\n\n\nCode\n# \n#same with AB package\n\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_don_ss), 'beta' = sum(assigned_emails))\n\n\n# Fit Bernoulli test\ndon_ss_by_treat_all_AB <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_don_ss[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_don_ss[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_ss_by_treat_all_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_don_ss[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_don_ss[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(don_ss_by_treat_all_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_ss_by_treat_all_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\ndon_ss_by_treat_all_AB %>% summary(credInt=0.9)\n\n\nQuantiles of posteriors for A and B:\n\n$Probability\n$Probability$A\n          0%          25%          50%          75%         100% \n0.0006591401 0.0034229384 0.0043367467 0.0053948239 0.0139389081 \n\n$Probability$B\n          0%          25%          50%          75%         100% \n0.0008503472 0.0038633646 0.0048302873 0.0059443205 0.0137935894 \n\n\n--------------------------------------------\n\nP(A > B) by (0)%: \n\n$Probability\n[1] 0.4076\n\n--------------------------------------------\n\nCredible Interval on (A - B) / B for interval length(s) (0.9) : \n\n$Probability\n        5%        95% \n-0.5874267  0.9235146 \n\n--------------------------------------------\n\nPosterior Expected Loss for choosing A over B:\n\n$Probability\n[1] 0.353655\n\n\nCode\ndon_ss_by_treat_all_AB_lift_int80 <- don_ss_by_treat_all_AB %>% summary(credInt=0.8)\n\n\ndon_ss_by_treat_all_AB_lift_int80_empir <- don_ss_by_treat_all_AB_empir %>% summary(credInt=0.8)\n\n\n80% credible intervals with the uniform prior for the ‘lift’ of Impact relative to Emotion are\n\n\nCode\n op(don_ss_by_treat_all_AB_lift_int80$interval$Probability)\n\n\n     10%      90% \n\"-0.507\" \" 0.621\" \n\n\nand for the empirically informed (but symmetric prior):\n\n\nCode\nop(don_ss_by_treat_all_AB_lift_int80_empir$interval$Probability)\n\n\n     10%      90% \n\"-0.329\" \" 0.379\" \n\n\nHard-coded: Here there is almost no evidence in either direction. However, our 80% credible intervals remain wide.\n\n\nUnfortunately, this experiment proved to be underpowered, at least for the donation outcome.\nBut what about clicks on the ‘donation link’? This could arguably be seen as a measure of ‘desire and intention to donate’, and thus might be a more fine-grained and less noisy measure, improving our statistical power.\nSome quick crosstabs (here as a share of opens)\n\n\nCode\n(\n  donclick_by_treat <-  oftw_mc_db %>% \n  filter(!is.na(treat_emotion)) %>% \n  tabyl(treat_emotion, d_click_don_link) %>%\n    adorn_percentages(\"row\") %>%\n    adorn_pct_formatting() %>%\n    adorn_ns() %>%\n    adorn_title() %>% \n    kable(caption =\"Click on donation link by treatment; all opened emails\")  %>% \n  kable_styling(latex_options = \"scale_down\")\n)\n\n\n\nClick on donation link by treatment; all opened emails\n \n  \n     \n    d_click_don_link \n     \n     \n  \n \n\n  \n    treat_emotion \n    FALSE \n    TRUE \n    NA_ \n  \n  \n    0 \n    97.5% (1376) \n    2.1% (29) \n    0.5% (7) \n  \n  \n    1 \n    94.6% (1134) \n    4.7% (56) \n    0.8% (9) \n  \n\n\n\n\n\nIf this is our metric, it only seems fair to take into account ‘whether they opened the email’ as part of this effect. Thus, considering clicks as a share of total emails sent…\n\n\nCode\n(\n  click_don_by_treat_opened_fit <- bayes.prop.test(oc_mat_r$tot_d_click_don_link, assigned_emails,\n    cred.mass = 0.95) # 80% credible interval for decision-making purposes\n)\n\n\n\n    Bayesian First Aid proportion test\n\ndata: oc_mat_r$tot_d_click_don_link out of assigned_emails\nnumber of successes:    29,   56\nnumber of trials:     2000, 2000\nEstimated relative frequency of success [95% credible interval]:\n  Group 1: 0.015 [0.0098, 0.020]\n  Group 2: 0.028 [0.021, 0.036]\nEstimated group difference (Group 1 - Group 2):\n  -0.01 [-0.023, -0.0046]\nThe relative frequency of success is larger for Group 1 by a probability\nof 0.002 and larger for Group 2 by a probability of 0.998 .\n\n\nCode\nplot(click_don_by_treat_opened_fit)\n\n\n\n\n\n\n\nCode\n#same with AB  package\n\nempir_prior <- c('alpha' = sum(oc_mat_r$tot_d_click_don_link), 'beta' = sum(assigned_emails))\n\noftw_mc_db_assigned <- oftw_mc_db_assigned %>% dplyr::filter(!is.na(d_click_don_link))\n\n# Fit bernoulli test\ndon_click_by_treat_all_AB <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_click_don_link[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_click_don_link[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = unif_prior,\n                 distribution = 'bernoulli')\n\ndon_click_by_treat_all_AB_empir <- bayesAB::bayesTest(\n  oftw_mc_db_assigned$d_click_don_link[oftw_mc_db_assigned$treat_emotion==0],\n  oftw_mc_db_assigned$d_click_don_link[oftw_mc_db_assigned$treat_emotion==1],\n                 priors = empir_prior,\n                 distribution = 'bernoulli')\n\nplot(don_click_by_treat_all_AB) \n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(don_click_by_treat_all_AB_empir) \n\n\n\n\n\n\n\n\n\n\n\nCode\ndon_click_by_treat_all_AB %>% summary(credInt=0.9)\n\n\nQuantiles of posteriors for A and B:\n\n$Probability\n$Probability$A\n         0%         25%         50%         75%        100% \n0.005613925 0.013111564 0.014855512 0.016785020 0.030921759 \n\n$Probability$B\n        0%        25%        50%        75%       100% \n0.01457222 0.02602580 0.02846221 0.03102267 0.04764887 \n\n\n--------------------------------------------\n\nP(A > B) by (0)%: \n\n$Probability\n[1] 0.00155\n\n--------------------------------------------\n\nCredible Interval on (A - B) / B for interval length(s) (0.9) : \n\n$Probability\n        5%        95% \n-0.6412379 -0.2472723 \n\n--------------------------------------------\n\nPosterior Expected Loss for choosing A over B:\n\n$Probability\n[1] 0.9686057\n\n\nCode\ndon_click_by_treat_all_AB_lift_int80 <- don_click_by_treat_all_AB %>% summary(credInt=0.8)\n\ndon_click_by_treat_all_AB_lift_int80_empir <- don_click_by_treat_all_AB_empir %>% summary(credInt=0.8)\n\n\n80% credible intervals with the uniform prior for the ‘lift’ of Impact relative to Emotion are\n-0.610, -0.304\nand for the empirically informed (but symmetric prior):\n-0.3119, -0.0531\n(Hard-coded)\nThere is fairly strong evidence that the emotion email lead to a higher rate of clicks on the donation link; note that this even is in spite of the lower rate of email opens.\nThis suggests (IMO) it is worth testing this further.\n\n\n1.6.2 Redoing a bunch of stuff manually\nFirst, some building blocks;\nthe probability distribution over the absolute value of differences between two binomial random variables\nAdapting formulas from Stackexchange post discussion\nDefining their code for this function: ::: {.cell}\n\nCode\nmodBin <- dbinom #DR: I just do this renaming here for consistency with the rest ... but the modBin they defined was redundant as it's already built ins\n\ndiffBin <- function(z, n1, p1, n2, p2){\n\n  prob <- 0\n\n  if (z>=0){\n    for (i in 1:n1){\n      prob <- prob + modBin(i+z, n1, p1) * modBin(i, n2, p2)\n    }\n\n  }\n  else\n  {\n    for (i in 1:n2){\n      prob<-prob+modBin(i+z, n1, p1)*modBin(i, n2, p2)\n    }\n  }\n  return(prob)\n}\n\n:::\n\n\nWe generate an alternate version to cover ‘differences in one direction, i.e., but ’probability of observing (d1-d2)/(n1+n2) share more of d1 responses than d2 responses given sample sizes n1 and n2… over a range of true probabilities p1 and p2’\nthe probability distribution for differences between two binomial random variables in one direction\n\n\n\nFor the present case\nHard-coded notes…\n::: {.foldable}\n\n\n\nCode\nn1 <- oc_mat_r$tot_d_open[1]\nn2 <- oc_mat_r$tot_d_open[2]\nd1 <- oc_mat_r$tot_d_click_don_link[1]\nd2 <- oc_mat_r$tot_d_click_don_link[2]\nz <- d1-d2 #impact minus emotion\n\n\nComputation for a few ‘ad-hoc cases’ (later explore the space with vectors of values)\n\nSuppose truly equal incidence, at the mean level\n\n\n\nCode\np1 <- (d1+d2)/(n1+n2)\n\np2 <- p1\n\n(\n  db_0 <- diffBin(z, n1, p1, n2, p2)\n)\n\n\n[1] 3.963627e-05\n\n\nThis implies there is a 0.00396% chance of getting this exact difference of +-27 incidence(s) between the treatments (in one direction), if the true incidence rates were equal.\nLet’s plot this for a range of ‘incidence rate differences’ in this region. (Sorry, using the traditional plot, ggplot is better).\n\n\nCode\ns <- seq(-10*z, 10*z)\np<-sapply(s, function(z) diffBin(z, n1, p1, n2, p2))\nplot(s,p)\n\n\n\n\n\nWe see a large likelihood of values in the range of the +-27 difference observed, and a low likelihood of a difference of 10 or more in either direction.\n\n\n1.6.3 Adaptation: ‘of this magnitude or smaller’\n\n\nCode\nltmag_diffBin <- function(z, n1, p1, n2, p2){\n  prob <- 0\n  z_n <- -z #negative value\n\n  for (i in z_n:z){     #sum for all integer differences between observed value and its negative, inclusive\n    prob <- prob + diffBin(i, n1, p1, n2, p2)\n    }\n\n  return(prob)\n}\n\n\nNow, a similar computation as above, but for ‘a difference this big or smaller in magnitude’:\n\n\nCode\n  (\n    mag_db_0 <- ltmag_diffBin(z, n1, p1, n2, p2)\n  )\n\n\n[1] 0.9880585\n\n\nThis implies there is a 98.8% chance of getting a difference no larger than this one in magnitude of +/–27 incidences between the treatments if the true incidence rates were equal.\n\n\nAnd finally, what we were looking for: the chance of ‘a difference this small or smaller’ as a function of the true difference…\n(Think about: should we do this for ‘a difference in the same direction’ instead?)\nSet up an arbitrary vector of ‘true differences’ \nBelow, I plot\nY-axis: ’how likely would be a difference in donations ‘as small or smaller in magnitude’” than we see in the data against…\nX-axis: if the “true difference in incidence rates” were of these magnitudes\n(Note: this should cover ‘a difference in either direction’; the probability of a difference in the direction we do see is obviously somewhat smaller)\n\n\nCode\noptions(scipen=999)\n\nB <- c(1, 1.5, 2, 2.5, 3)\n\np1 <- rep((d1+d2)/(n1+n2), length(B))\np2 <- p1*B\n\n\nas.list(ltmag_diffBin(z, n1, p1, n2, p2)*100) %>% format(digits=3, scientific=FALSE)\n\n\n[1] \"98.8\"   \"93.2\"   \"33.6\"   \"1.81\"   \"0.0157\"\n\n\nCode\nprobmag <- ltmag_diffBin(z, n1, p1, n2, p2)\n\n\n#qplot(B, probmag, log  = \"x\", xlab = \"True relative incidence\", ylab =\"Prob. of difference this small\")\n\n(\n  probmag_plot <-\n    ggplot() +\n  aes(x=B, y=probmag) +\n  geom_point() +\n  scale_x_continuous(trans='log2') +\n    ylim(0,1) +\n    xlab(\"True relative incidence rate\") +\n    ylab(\"Prob. diff. as small as obsd\")\n\n)\n\n\n\n\n\nHard-coded takeaways 15 Dec 2021 :\nOur data is consistent with ‘no difference’ (of course) … but its also consistent with ‘a fairly large difference in incidence’\nE.g., even if one treatment truly lead to ‘twice as many donations as the other’, we still have a 20% chance of seeing a differences as small as the one we see (of 8 versus 6)\nWe can reasonably ‘rule out’ differences of maybe 2.5x or greater\nMain point: given the rareness of donations in this context, our sample size doesn’t let us make very strong conclusions in either directions … at least not yet. I hope that combined with other evidence, we will be able to infer more\n\n\n1.6.4 Quick redo assuming equal shares recieved each email, and treating ‘email reciepts as denom’\nApprox 4000 total emails sent?\nFor squarespace\n\n\nCode\nn1 <- 2000\nn2 <- 2000\nd1 <- 10\nd2 <- 9\nz <- d1-d2\n\nB <- c(1/3, 1/2.5, 1/2, 1/1.5, 1, 1.5, 2, 2.5, 3)\n\np1 <- rep((d1+d2)/(n1+n2), length(B))\np2 <- p1*B\n\n\n\n(\n    mag_db_0_ss <- ltmag_diffBin(z, n1, p1, n2, p2)\n  )\n\n\n[1] 0.071197896 0.100275616 0.147727269 0.220724651 0.272100392 0.154218060\n[7] 0.046306831 0.009174658 0.001345637\n\n\nCode\nprobmag_ss <- ltmag_diffBin(z, n1, p1, n2, p2)\n\n\n(\n  probmag_plot_ss <-\n    ggplot() +\n  aes(x=B, y=probmag_ss) +\n  geom_point() +\n  scale_x_continuous(trans='log2') +\n    ylim(0,.51) +\n    xlab(\"True relative incidence rate\") +\n    ylab(\"Prob. diff. as small as obsd\")\n\n)\n\n\n\n\n\nCode\n#note that it is not symmetric bc (I think) a very low incidence on one side makes particular large observed proportional differences more likely\n\n\nFor all one-time donations\n\n\nCode\nn1 <- 2000\nn2 <- 2000\nd1 <- 15\nd2 <- 12\nz <- d1-d2\n\nB <- c(1/3, 1/2.5, 1/2, 1/1.5, 1, 1.5, 2, 2.5, 3)\n\np1 <- rep((d1+d2)/(n1+n2), length(B))\np2 <- p1*B\n\n\n(\n    mag_db_0 <- ltmag_diffBin(z, n1, p1, n2, p2)\n  )\n\n\n[1] 0.0922168538 0.1395427545 0.2249330548 0.3745240308 0.5032003013\n[6] 0.2505329859 0.0521354769 0.0059810731 0.0004413855\n\n\n(the below halts on build, so I commented it out)\n\n\nCode\n(\n  probmag_plot_ot <-\n    ggplot() +\n  aes(x=B, y=probmag) +\n  geom_point() +\n  scale_x_continuous(trans='log2') +\n    ylim(0,.51) +\n    xlab(\"True relative incidence rate\") +\n    ylab(\"Prob. diff. as small as obsd\")\n\n)"
  },
  {
    "objectID": "chapters/oftw_upsell_input_first_analysis.html#demographics-and-interactions-to-do",
    "href": "chapters/oftw_upsell_input_first_analysis.html#demographics-and-interactions-to-do",
    "title": "1  OftW pre-giving-tuesday-email upselling split test (considering ‘impact vs emotion’)",
    "section": "1.7 Demographics and interactions (to do)",
    "text": "1.7 Demographics and interactions (to do)"
  },
  {
    "objectID": "chapters/tlycs_placeholder.html",
    "href": "chapters/tlycs_placeholder.html",
    "title": "2  The Life You Can Save trial: redacted (empty)",
    "section": "",
    "text": "As we have not (yet) been given explicit permission to share the details of the trial with The Life You Can Save, we are not hosting it in the public version"
  },
  {
    "objectID": "chapters/gwwc_gg.html",
    "href": "chapters/gwwc_gg.html",
    "title": "1  Giving What We Can: Giving guides",
    "section": "",
    "text": "Note\n\n\n\nThis chapter should align with a (forthcoming) EA Forum post, which will be linked here (and vice-versa)."
  },
  {
    "objectID": "chapters/gwwc_gg.html#capturing-data",
    "href": "chapters/gwwc_gg.html#capturing-data",
    "title": "3  Giving What We Can: Giving guides",
    "section": "3.2 Capturing data",
    "text": "3.2 Capturing data"
  },
  {
    "objectID": "chapters/gwwc_fb.html",
    "href": "chapters/gwwc_fb.html",
    "title": "4  Giving What We Can: Feb 22 Facebook Message Test",
    "section": "",
    "text": "Details in Gitbook HERE and Gdoc here\n\n\nCode\nknitr::include_url(\"https://effective-giving-marketing.gitbook.io/untitled/partner-organizations-and-trials/gwwc/feb-22-message-test\")"
  },
  {
    "objectID": "chapters/gwwc_fb.html#capturing-data",
    "href": "chapters/gwwc_fb.html#capturing-data",
    "title": "4  Giving What We Can: Feb 22 Facebook Message Test",
    "section": "4.2 Capturing data",
    "text": "4.2 Capturing data\n\n\n\n\n\n\nBringing in the data Erin coded\n\n\n\n\n\nAs a start, I source build work (Erin’s work, which I edited a bit) to bring in (and store) the data. I would do the coding a bit differently (more ‘tidyverse’ and less repetition), but it may not be worth redoing at this point.\n\n\n\n\n\nCode\n#this seems to be what Erin used ... but what is \n\nsource(here(\"gwwc\", \"build_GWWC_Feb_22_Message_test.R\"))"
  },
  {
    "objectID": "chapters/gwwc_gg.html#build-source-data-input-and-cleaning-code",
    "href": "chapters/gwwc_gg.html#build-source-data-input-and-cleaning-code",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.3 Build: Source data input and cleaning code",
    "text": "1.3 Build: Source data input and cleaning code\n\n\n\n\n\n\nAccessing, downloading, inputting data\n\n\n\n\n\nSee:\nAccessing and bringing down simple results HERE; (Public access version here)\nWe import the exported ‘pivot table’ gg_campaign_by_ad_by_text below, as well as the more detailed version, broken down by age range and gender: gg-campaign-by-ad-set-text-age-gender.csv.2\n\n\n\n\n\n\n\n\n\n\nData structure\n\n\n\n\n\nThe data frame gg_campaign_by_ad_by_text_age_gender has one row per combination of ‘campaign, ad, text, age group, gender’.\nEach row represents a combination of the below (with different numbers of ‘reach’ for each row)3\n\ncampaign_name: When and and with what funds the ad was launched, I think (?)\nad_set: An ad set can specifically tie an ad_name to an audience (I think)\nad_name: Which video/media (or collection of optimized videos/media) was shown; note this is paired with ‘which audience’ in it’s label, as there were specific ‘global poverty’, ‘animal welfare’, ‘climate change’, ‘philanthropy’ and ‘retargeting’ audiences\n\nCaveat: The ad_name seems to select from a different set of media for optimization depending on which ad_set it is in.4\n\ntext: Which text was shown along with the video\nage (a range of ages)\ngender (female, male, unknown)\n\n\n\n\n\n\nCode\nraw_data_path <- list(\"gwwc\", \"gg_raw_data_shareable\")\n\n#already input above: gg_campaign_by_ad_by_text\n\n#Version allowing demographic breakdown:\ngg_campaign_by_ad_by_text_age_gender <- read_csv(here(raw_data_path, \"gg-campaign-by-ad-set-text-age-gender.csv\"), show_col_types=FALSE) %>%\n  #dplyr::select(-\"Campaign name...4\") %>% #duplicate columns?\n mini_clean()\n\n#Version with information on cause videos shown (even to those in 'general' groups):\n\ngg_video_breakdowns <- read_csv(here(raw_data_path, \"gg-image-video-breakdowns.csv\"), show_col_types=FALSE)\n\n#capture and remove columns that are the same everywhere\nattribution_setting_c <- gg_campaign_by_ad_by_text_age_gender$attribution_setting %>% .[1]\nreporting_starts_c <- gg_campaign_by_ad_by_text_age_gender$reporting_starts %>% .[1]\nreporting_ends_c <- gg_campaign_by_ad_by_text_age_gender$reporting_ends %>% .[1]\n\n\ngg_campaign_by_ad_by_text_age_gender  %<>% mini_clean()\ngg_video_breakdowns  %<>% mini_clean()\n\n#functions to clean these specific data sets 'gg_campaign_by_ad_by_text_age_gender' and 'gg_campaign_by_ad_by_text':\nsource(here(\"gwwc\", \"giving_guides\", \"clean_gg_raw_data.R\"))\n\n#Many cleaning steps: audience, video_theme, campaign_theme, agetrin; releveling\ngg_campaign_by_ad_by_text_age_gender %<>%\n  rename_gg() %>%\ngg_make_cols() %>%\n  text_clean() %>%  # Shorter 'text treatment' column\n  dplyr::select(campaign_name, everything(), -campaign_name_1, -campaign_name_7) #campaign_name_7 was the same as campaign_name_1\n\ngg_video_breakdowns %<>%\n  rename_gg() %>%\ngg_make_cols()\n\n#gg_campaign_by_ad_by_text_age_gender %>% collapse::descr()\n\n\n\n\nCode\ngg_video_breakdowns %<>%\n  mutate(\n    video_theme = case_when(\n      str_det(image_video_and_slideshow, \"set_1|Animals\") ~ \"Animal\",\n      str_det(image_video_and_slideshow, \"set_2|Climate\") ~ \"Climate\",\n      str_det(image_video_and_slideshow, \"set_3|Poverty\") ~ \"Poverty\",\n      str_det(image_video_and_slideshow, \"Free Effective\") & video_theme==\"Cause-led (any)\" ~ \"Poverty\",\n      str_det(image_video_and_slideshow, \"factual_short|Factual Short\") ~ \"Factual short\",\n    TRUE ~   video_theme\n    ),\n    video_theme =  factor(video_theme),\n    video_theme = fct_relevel(video_theme, c(\"Animal\", \"Climate\", \"Poverty\", \"Factual short\", \"Factual long\", \"Branded (Factual)\"))\n  )\n\n\n\n\nCode\ncleaned_data_path <- list(\"gwwc\", \"gg_processed_data\")\n\n#export 'cleaned' data for others to play with immediately\nwrite.csv(gg_video_breakdowns, here(cleaned_data_path, \"gg_video_breakdowns.csv\"), row.names = FALSE)\nwrite.csv(gg_campaign_by_ad_by_text_age_gender, here(cleaned_data_path, \"gg_campaign_by_ad_by_text_age_gender.csv\"), row.names = FALSE)\n\nwrite_rds(gg_video_breakdowns, here(cleaned_data_path, \"gg_video_breakdowns.Rdata\"))\nwrite_rds(gg_campaign_by_ad_by_text_age_gender, here(cleaned_data_path, \"gg_campaign_by_ad_by_text_age_gender.Rdata\"))\n\n\n\n\n\n\n\n\nThis data should be publicly shareable; above, we ‘export’\n\n\n\n\n\nThis data is clearly not identifying individuals; it involves aggregates based on real or assumed characteristics … there is likely nothing that needs to be hidden here. We aim to share and integrate all the data in this repo, for a complete pipeline.\nIn the code above, we create several ‘cleaned data’ files for others to access in the Github repo\n\n\n\n\n\n\n\n\n\nPrevious version of data used … (moved)\n\n\n\n\n\nWe previously used data collapsed (breakdowns) by demography and ad set, into 2 files, which duplicated rows to represent the number of people reached: video breakdown, and text breakdown.csv. We now use the more ‘raw’ minimal version of the data, avoiding duplicating rows where possible.\nBelow, we also input some of the ‘old version’ of the data, with the duplicated rows, to accommodate the old-format of analysis … this will be removed when we switch over. The code above inputs and builds 2-4 related data frames (tibbles), which were constructed from the collapsed (aggregated) data by multiplying rows according to observation counts. I am not sure where this was done. Once we update the rest we will get rid of this. …\ne.g.,\ngwwc_vid_results: Observations of emails provided… by video content\nThis content/input has been moved to eamt_data_analysis/gwwc/giving_guides/archive_erin/erin_plots_stats_gg.qmd, at least for now"
  },
  {
    "objectID": "chapters/gwwc_gg.html#asking-and-answering-questions",
    "href": "chapters/gwwc_gg.html#asking-and-answering-questions",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.5 Asking and answering questions",
    "text": "1.5 Asking and answering questions\n\n\n\n\n\n\nThis dynamic document format allows us to ask and answer a series of questions\n\n\n\n\n\n\nUsing the data, with all coding steps shown\nIdeally, following a pre-defined (pre-analysis) plan\nUsing the data and statistics directly and automatically in the narrative\n\nAnd everything will be automatically adjusted if we bring in new data or adjust/correct features\n\n\n\n\n\n\nIn this context, how much does it cost to get a ’Result”, i.e., to get a person to give their email to receive a Giving Guide?\n\n\n\n\n\n\nCost per result (CpR) as the result of several processes…\n\n\n\n\n\nHow should we consider this outcome? At the base level the Cost per Result (‘CpR’) for a ‘segment’ (a particular ad version, audience, campaign, etc), comes from several interrelated processes:\n\nHow much FB charges us for this segment\nWho FB serves this segment to (what types of people, how many)\nHow many people in that segment click and then ‘convert’, yielding a result\n\nWe could try to model each of these processes, but it could be very involved, and we don’t fully observe or understand the second step, FB’s optimization algorithm.\n\n\n\n\n\n\n\n\n\nRambling about the unit of observation, and a possible multi-equation model\n\n\n\n\n\nI still want to model “cost per result” (or perhaps better “results per cost”) as a function of the different levers we can pull (audience filters, video content, message content, etc.). But there are challenges in consiring the ‘unit of observation’ and the outcome variability, for statistical inference.\nFundamentally, the data represents many rows of mostly 0’s (no result, no email left) with a few 1’s. Each of these rows has a set of design features; the ‘levers’ above, as well as some other features like demographics and calendar date (although FB makes it difficult/impossible to view everything together.)\nWe could examine the relationship between the features and the ‘probability an individual yields a result’. I’Cost’ could be one of those features, in something like a logit model. A transformation of the function $p(result) = a + b_1 cost (b_2 AdVersion + b_3 audience + b_4 AdVersion*audience +… ), perhaps.\nBut cost (cost per impression) is also a function of some of these characteristics. We could examine the relationship between cost and these features in a separate equation and somehow try to simultaneously estimate these … but it’s challenging.\n\n\n\n\n\n\n\n\n\nCpR as a black box…\n\n\n\n\n\nAlternatively, we could think of the CpR for a segment as just a ‘base outcome to model’, and treat it as a black box. This would suggest we have ‘only one CpR outcome per segment’, and each segment has different characteristics (‘features’ or ‘variables’), some in common. But that discards some important information: the mean values for segments with more observations (here, ‘reach’) can be expected to have less variance (lower standard error), all else equal.\n\n\n\n\n\n\n\n\n\nCpR as the average of a lot of black boxes…\n\n\n\n\n\nWe can do something intermediate – taking the aggregation into account, without fully building a structural model of the factors above. Within each segment, we can consider the ‘average cost per result’ outcome for each individual as the expected value of a random draw. Each individual has some ‘cost per impression’, and some ‘probability of a result’. The ratio of these is the individual’s ‘expected cost per result … which we can also abstract as just some random draw. This may be considered as a function of ’all the characteristics of the segment the individual is in’. The CpR for the segment is thus an average of the CpR for all the individuals in the segment, and we can use ‘regression weights’ (technically ‘inverse variance weights’; see discussion in Huntington-Klein’s book here) in our model to reflect this."
  },
  {
    "objectID": "chapters/gwwc_gg.html#analysis-and-visuals-moved-from-erins-work",
    "href": "chapters/gwwc_gg.html#analysis-and-visuals-moved-from-erins-work",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.4 Analysis and visuals (moved from Erin’s work)",
    "text": "1.4 Analysis and visuals (moved from Erin’s work)\n\n\nCode\n#summary(gwwc_vid_results$DV_costadj)\n#summary(gwwc_vid_results$DV)\n#summary(gwwc_vid_results$ave.cost.impr)\n\n\nData summary\n\nBelow, a few data summary bits (from Erin). I commented most of it out and will redo it using an automated and formatted ‘key summary statistics’ package.\n\n\n\nCode\ngwwc_vid_results %>% group_by(Age) %>% summarise(n=n()) %>% .kable()\n\n\n\n \n  \n    Age \n    n \n  \n \n\n  \n    25-34 \n    287,682 \n  \n  \n    13-17 \n    444 \n  \n  \n    18-24 \n    147,805 \n  \n  \n    35-44 \n    158,352 \n  \n  \n    45-54 \n    48,728 \n  \n  \n    55-64 \n    60,904 \n  \n  \n    65+ \n    66,198 \n  \n\n\n\n\n\nCode\ngwwc_vid_results %>% group_by(Gender) %>% summarise(n=n())  %>% .kable()\n\n\n\n \n  \n    Gender \n    n \n  \n \n\n  \n    female \n    573,705 \n  \n  \n    male \n    178,321 \n  \n  \n    unknown \n    18,087 \n  \n\n\n\n\n\nCode\n#print(gwwc_vid_results %>% group_by(Gender,Age) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=40)\n#print(gwwc_vid_results %>% group_by(Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=41)\n#print(gwwc_vid_results %>% group_by(Campaign.name,Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=100)\ngwwc_vid_results %>% group_by(audience) %>% summarise(n=n(),cost=mean(ave.cost.impr)*100) %>% .kable(digits=2)\n\n\n\n \n  \n    audience \n    n \n    cost \n  \n \n\n  \n    philanthropy \n    248,852 \n    2.20 \n  \n  \n    animal \n    187,212 \n    2.22 \n  \n  \n    climate \n    139,824 \n    1.81 \n  \n  \n    general \n    57,012 \n    1.30 \n  \n  \n    lookalike \n    67,359 \n    2.66 \n  \n  \n    poverty \n    69,404 \n    1.82 \n  \n  \n    retargeting \n    450 \n    2.50 \n  \n\n\n\n\n\nCode\ngwwc_vid_results %>% group_by(message) %>% summarise(n=n(),cost=mean(ave.cost.impr)*100) %>% .kable(digits=2)\n\n\n\n \n  \n    message \n    n \n    cost \n  \n \n\n  \n    Factual \n    291,027 \n    2.24 \n  \n  \n    Emotional \n    274,718 \n    2.37 \n  \n  \n    Hypercube \n    75,790 \n    1.76 \n  \n  \n    PPCo \n    128,578 \n    1.25 \n  \n\n\n\n\n\n### CHART DATA\n\n\nCode\n#print(gwwc_vid_results %>% group_by(audience,media) %>% #summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)"
  },
  {
    "objectID": "chapters/gwwc_gg.html#plots",
    "href": "chapters/gwwc_gg.html#plots",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.8 PLOTS",
    "text": "1.8 PLOTS\n\n1.8.1 PLOT: Cost adjusted DV (results) by video\n\n\n1.8.2 PLOT: DV (Results) by video\n\n\nCode\ngwwc_vid_results %>%\n   grpsumgg(media, DV, .1) %>%\n  ggplot(aes(x=media, y=mean_dv)) +\n  geom_bar(stat='identity', fill=\"#0072B2\",position=dodge) +\n  ylab('Results (%)')+\n  xlab('Video')+\n  ggtitle('Results by Video')+\n  scale_x_discrete(labels=vid_types)\n\n\n\n\n\n\n\n1.8.3 PLOT: Cost adjusted DV (results) by video and audience\n15\n\n\nCode\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>% group_by(media,audience) %>% #summarise(results=mean(DV_costadj),SE=std.error(DV_costadj),n=n()),n=50) %>% .kable(digits=2)\n\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>%\n  group_by(media, audience) %>%\n  summarise(mean_dv = mean(DV_costadj, na.rm=TRUE),\n            se_dv = sd(DV_costadj, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=audience, y=mean_dv, group=media, fill=media)) +\n  gg_gg_options +\n  labs(fill=\"Video\")+\n  scale_fill_brewer(palette=\"RdBu\")+\n  ylab('Results/$ spent')+\n  xlab('Audience')+\n  ggtitle('Results/$ spent by Video and Audience')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.25), oob = rescale_none, breaks=seq(0,.75, by=.25)) +\n  scale_x_discrete(labels=c(\"philanthropy\",\"animal\",\"climate\",\"general\",\"lookalike\",\"poverty\",\"retargeting\"))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\nCode\n#levels(gwwc_vid_results$audience)\n\n\n\n\n1.8.4 PLOT: DV (results) by video and audience\nQuestions/Notes: Removed the retargeting audience\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr > 0 &\n    audience != \"retargeting\") %>% group_by(media, audience) %>% summarise(\n      results = 100 * mean(DV),\n      SE = 100 * std.error(DV),\n      n = n()\n    ) %>% .kable(digits = 2) %>% .kable_styling()\n\n\n\n \n  \n    media \n    audience \n    results \n    SE \n    n \n  \n \n\n  \n    factual short \n    philanthropy \n    0.23 \n    0.02 \n    59,660 \n  \n  \n    factual short \n    animal \n    0.20 \n    0.01 \n    90,832 \n  \n  \n    factual short \n    climate \n    0.21 \n    0.01 \n    96,005 \n  \n  \n    factual short \n    general \n    0.10 \n    0.02 \n    15,559 \n  \n  \n    factual short \n    lookalike \n    0.39 \n    0.03 \n    34,207 \n  \n  \n    factual short \n    poverty \n    0.21 \n    0.02 \n    34,815 \n  \n  \n    animal \n    philanthropy \n    0.21 \n    0.02 \n    79,525 \n  \n  \n    animal \n    animal \n    0.28 \n    0.02 \n    80,642 \n  \n  \n    animal \n    general \n    0.14 \n    0.04 \n    10,542 \n  \n  \n    animal \n    lookalike \n    0.42 \n    0.07 \n    9,441 \n  \n  \n    climate \n    philanthropy \n    0.28 \n    0.04 \n    13,810 \n  \n  \n    climate \n    climate \n    0.11 \n    0.03 \n    14,083 \n  \n  \n    climate \n    general \n    0.16 \n    0.05 \n    7,445 \n  \n  \n    climate \n    lookalike \n    0.21 \n    0.08 \n    3,283 \n  \n  \n    factual long \n    philanthropy \n    0.16 \n    0.05 \n    6,923 \n  \n  \n    factual long \n    animal \n    0.15 \n    0.04 \n    8,729 \n  \n  \n    factual long \n    climate \n    0.19 \n    0.04 \n    9,542 \n  \n  \n    factual long \n    lookalike \n    0.72 \n    0.36 \n    557 \n  \n  \n    factual long \n    poverty \n    0.11 \n    0.05 \n    4,595 \n  \n  \n    hypercube \n    philanthropy \n    0.14 \n    0.03 \n    17,400 \n  \n  \n    hypercube \n    animal \n    0.07 \n    0.03 \n    6,988 \n  \n  \n    hypercube \n    climate \n    0.09 \n    0.02 \n    20,154 \n  \n  \n    hypercube \n    general \n    0.09 \n    0.02 \n    22,132 \n  \n  \n    hypercube \n    lookalike \n    0.25 \n    0.14 \n    1,194 \n  \n  \n    hypercube \n    poverty \n    0.08 \n    0.03 \n    7,835 \n  \n  \n    poverty \n    philanthropy \n    0.15 \n    0.01 \n    71,466 \n  \n  \n    poverty \n    general \n    0.08 \n    0.08 \n    1,327 \n  \n  \n    poverty \n    lookalike \n    0.24 \n    0.04 \n    18,652 \n  \n  \n    poverty \n    poverty \n    0.15 \n    0.03 \n    22,129 \n  \n\n\n\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>%\n  group_by(media, audience) %>%\n  summarise(mean_dv = 100*mean(DV, na.rm=TRUE),\n            se_dv = 100*sd(DV, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=audience, y=mean_dv, group=media, fill=media)) +\n  gg_gg_options +\n  labs(fill=\"Video\")+\n  scale_fill_brewer(palette=\"RdBu\")+\n  ylab('Results (%)')+\n  xlab('Audience')+\n  ggtitle('Results by Video and Audience')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,1.1),  oob = rescale_none,  breaks=seq(0,1.1, by=.1)) +\n  scale_x_discrete(labels=c(\"philanthropy\",\"animal\",\"climate\",\"general\",\"lookalike\",\"poverty\",\"retargeting\"))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\n\n\n1.8.5 PLOT: Cost adjusted DV (results) by audience\n\n\nCode\n#pirint(gwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>% group_by(audience) %>% summarise(results=mean(DV_costadj),SE=std.error(DV_costadj),n=n()),n=50)\n\n\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>%\n  group_by(audience) %>%\nsummarise(mean_dv = mean(DV_costadj, na.rm=TRUE),\n            se_dv = sd(DV_costadj, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=audience, y=mean_dv)) +\n  gg_gg_options +\n  ylab('Results/$ spent')+\n  xlab('Audience')+\n  ggtitle('Results/$ spent by Audience')+\n  scale_y_continuous(limits = c(0,.2),  breaks=seq(0,.2, by=.05)) +\n  scale_x_discrete(labels=c(\"philanthropy\",\"animal\"   ,\"climate\",\"general\",\"lookalike\",\"poverty\"))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\n\n\n1.8.6 PLOT: DV (Results) by audience\n\n\nCode\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>% group_by(audience) %>% summarise(results=100*mean(DV),SE=100*std.error(DV),n=n()),n=50)\n\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & audience !=\"retargeting\") %>%\n  group_by(audience) %>%\n  summarise(mean_dv = 100*mean(DV, na.rm=TRUE),\n            se_dv = 100*sd(DV, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=audience, y=mean_dv)) +\n  gg_gg_options +\n  ylab('Results (%)')+\n  xlab('Audience')+\n  ggtitle('Results by Audience')+\n  scale_y_continuous(limits = c(0,.4),  breaks=seq(0,.4, by=.05)) +\n  scale_x_discrete(labels=c(\"philanthropy\",\"animal\"   ,\"climate\",\"general\",\"lookalike\",\"poverty\"))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\n\n\n1.8.7 PLOT: Cost adjusted DV (results) by age and gender\n16\n\n\nCode\ngwwc_vid_results$Gender <- as.factor(gwwc_vid_results$Gender)\n#levels(gwwc_vid_results$Gender)\n\nclass(gwwc_vid_results$Age)\n\n\n[1] \"factor\"\n\n\nCode\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"18-24\")\n#levels(gwwc_vid_results$Age)\n\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0) %>% group_by(Age,Gender) %>% summarise(results=mean(DV_costadj),SE=std.error(DV_costadj),n=n()),n=50)\n\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & Age!=\"13-17\") %>%\n  group_by(Age, Gender) %>%\n  summarise(mean_dv = mean(DV_costadj, na.rm=TRUE),\n            se_dv = sd(DV_costadj, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=Age, y=mean_dv, group=Gender, fill=Gender)) +\n  gg_gg_options +\n  labs(fill=\"Gender\")+\n  scale_fill_brewer(palette=\"Paired\")+\n  ylab('Results/$ spent')+\n  xlab('Age')+\n  ggtitle('Results/$ spent by Age and Gender')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.35),  breaks=seq(0,.35, by=.1)) +\n  scale_x_discrete(labels=c(\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\" ))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\n\n\n1.8.8 PLOT: DV (results) gggender\n\n\nCode\ngwwc_vid_results$Gender <- as.factor(gwwc_vid_results$Gender)\n#levels(gwwc_vid_results$Gender)\n\n#class(gwwc_vid_results$Age)\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"18-24\")\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"13-17\")\n#levels(gwwc_vid_results$Age)\n\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0) %>% group_by(Age,Gender) %>% summarise(results=100*mean(DV),SE=std.error(100*DV),n=n()),n=50)\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & Age!=\"13-17\") %>%\n  group_by(Age, Gender) %>%\n  summarise(mean_dv = 100*mean(DV, na.rm=TRUE),\n            se_dv = 100*sd(DV, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=Age, y=mean_dv, group=Gender, fill=Gender)) +\n  gg_gg_options +\n  labs(fill=\"Gender\")+\n  scale_fill_brewer(palette=\"Paired\")+\n  ylab('Results (%)')+\n  xlab('Age')+\n  ggtitle('Results by Age and Gender')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.75),  breaks=seq(0,.75, by=.25)) +\n  scale_x_discrete(labels=c(\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\" ))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\n\n\n1.8.9 PLOT: Cost adjusted DV (results) by Video and Age\n\n\nCode\nclass(gwwc_vid_results$Age)\n\n\n[1] \"factor\"\n\n\nCode\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"18-24\")\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"13-17\")\nlevels(gwwc_vid_results$Age)\n\n\n[1] \"13-17\" \"18-24\" \"25-34\" \"35-44\" \"45-54\" \"55-64\" \"65+\"  \n\n\nCode\n#print(gwwc_vid_results %>% filter(ave.cost.impr>0) %>% group_by(Age,media) %>% summarise(results=mean(DV_costadj),SE=std.error(DV_costadj),n=n()),n=50)\n\n\ngwwc_vid_results %>% filter(ave.cost.impr>0 & Age!=\"13-17\") %>%\n  group_by(media, Age) %>%\n  summarise(mean_dv = mean(DV_costadj, na.rm=TRUE),\n            se_dv = sd(DV_costadj, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=Age, y=mean_dv, group=media, fill=media)) +\n  gg_gg_options +\n  labs(fill=\"Video\")+\n  scale_fill_brewer(palette=\"RdBu\")+\n  ylab('Results/$ spent')+\n  xlab('Age')+\n  ggtitle('Results/$ spent by Video and Age')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.2),  breaks=seq(0,.2, by=.05)) +\n  scale_x_discrete(labels=c(\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\"))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found\n\n\n\n\n\n\n\n1.8.10 PLOT: DV (results) by video and age\n\n\nCode\nclass(gwwc_vid_results$Age)\n\n\n[1] \"factor\"\n\n\nCode\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"18-24\")\ngwwc_vid_results$Age <- relevel(gwwc_vid_results$Age, ref=\"13-17\")\n#levels(gwwc_vid_results$Age)\n\ngwwc_vid_results %>% filter(ave.cost.impr>0) %>% group_by(Age,media) %>% summarise(results=100*mean(DV),SE=100*std.error(DV),n=n()) %>%\n  .kable(digits=2) %>%  .kable_styling()\n\n\n\n \n  \n    Age \n    media \n    results \n    SE \n    n \n  \n \n\n  \n    13-17 \n    factual short \n    0.00 \n    0.00 \n    176 \n  \n  \n    13-17 \n    animal \n    0.00 \n    0.00 \n    101 \n  \n  \n    13-17 \n    climate \n    0.00 \n    0.00 \n    20 \n  \n  \n    13-17 \n    factual long \n    0.00 \n    NA \n    1 \n  \n  \n    13-17 \n    hypercube \n    0.00 \n    0.00 \n    46 \n  \n  \n    13-17 \n    poverty \n    0.00 \n    0.00 \n    81 \n  \n  \n    18-24 \n    factual short \n    0.11 \n    0.01 \n    55,045 \n  \n  \n    18-24 \n    animal \n    0.12 \n    0.02 \n    35,453 \n  \n  \n    18-24 \n    climate \n    0.09 \n    0.03 \n    9,513 \n  \n  \n    18-24 \n    factual long \n    0.00 \n    0.00 \n    5,283 \n  \n  \n    18-24 \n    hypercube \n    0.12 \n    0.03 \n    18,632 \n  \n  \n    18-24 \n    poverty \n    0.14 \n    0.02 \n    23,823 \n  \n  \n    25-34 \n    factual short \n    0.15 \n    0.01 \n    124,020 \n  \n  \n    25-34 \n    animal \n    0.16 \n    0.02 \n    54,928 \n  \n  \n    25-34 \n    climate \n    0.17 \n    0.03 \n    17,904 \n  \n  \n    25-34 \n    factual long \n    0.08 \n    0.04 \n    5,161 \n  \n  \n    25-34 \n    hypercube \n    0.10 \n    0.02 \n    38,313 \n  \n  \n    25-34 \n    poverty \n    0.14 \n    0.02 \n    47,287 \n  \n  \n    35-44 \n    factual short \n    0.16 \n    0.02 \n    68,690 \n  \n  \n    35-44 \n    animal \n    0.23 \n    0.03 \n    34,263 \n  \n  \n    35-44 \n    climate \n    0.15 \n    0.05 \n    6,719 \n  \n  \n    35-44 \n    factual long \n    0.18 \n    0.07 \n    4,336 \n  \n  \n    35-44 \n    hypercube \n    0.09 \n    0.02 \n    18,794 \n  \n  \n    35-44 \n    poverty \n    0.20 \n    0.03 \n    25,492 \n  \n  \n    45-54 \n    factual short \n    0.26 \n    0.04 \n    17,482 \n  \n  \n    45-54 \n    animal \n    0.35 \n    0.04 \n    19,751 \n  \n  \n    45-54 \n    climate \n    0.24 \n    0.17 \n    851 \n  \n  \n    45-54 \n    factual long \n    0.15 \n    0.06 \n    4,548 \n  \n  \n    45-54 \n    poverty \n    0.30 \n    0.07 \n    6,090 \n  \n  \n    55-64 \n    factual short \n    0.35 \n    0.03 \n    28,557 \n  \n  \n    55-64 \n    animal \n    0.41 \n    0.04 \n    20,126 \n  \n  \n    55-64 \n    climate \n    0.33 \n    0.16 \n    1,221 \n  \n  \n    55-64 \n    factual long \n    0.17 \n    0.06 \n    4,848 \n  \n  \n    55-64 \n    poverty \n    0.20 \n    0.06 \n    6,150 \n  \n  \n    65+ \n    factual short \n    0.66 \n    0.04 \n    37,227 \n  \n  \n    65+ \n    animal \n    0.57 \n    0.06 \n    15,669 \n  \n  \n    65+ \n    climate \n    0.66 \n    0.16 \n    2,435 \n  \n  \n    65+ \n    factual long \n    0.40 \n    0.08 \n    6,179 \n  \n  \n    65+ \n    poverty \n    0.21 \n    0.07 \n    4,685 \n  \n\n\n\n\n\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr>0 & Age !=\"13-17\") %>%\n    group_by(media, Age) %>%\n  summarise(mean_dv = 100*mean(DV, na.rm=TRUE),\n            se_dv = 100*sd(DV, na.rm=TRUE)/sqrt(n())) %>%\n  ggplot(aes(x=Age, y=mean_dv, group=media, fill=media)) +\n  gg_gg_options +\n  labs(fill=\"Video\")+\n  scale_fill_brewer(palette=\"RdBu\")+\n  ylab('Results (%)')+\n  xlab('Age')+\n  ggtitle('Results by Video and Age')+\n  theme_apa(legend.font.size = 8,legend.use.title = TRUE)+\n  scale_y_continuous(limits = c(0,.85),  breaks=seq(0,.85, by=.25)) +\n  scale_x_discrete(labels=c(\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\"))\n\n\nError in FUN(X[[i]], ...): object 'ci_spread' not found"
  },
  {
    "objectID": "chapters/gwwc_gg.html#statistics-and-mi-needs-to-be-made-into-table",
    "href": "chapters/gwwc_gg.html#statistics-and-mi-needs-to-be-made-into-table",
    "title": "3  Giving What We Can: Giving guides",
    "section": "3.6 Statistics and mi– needs to be made into table",
    "text": "3.6 Statistics and mi– needs to be made into table\n\n3.6.1 Regressions with interactions\n\n\nCode\nsummary(lm(data = gwwc_vid_results, DV~Gender*Age+ave.cost.impr))\n\n\n\nCall:\nlm(formula = DV ~ Gender * Age + ave.cost.impr, data = gwwc_vid_results)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.04779 -0.00203 -0.00151 -0.00129  0.99914 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            -9.180e-04  3.006e-03  -0.305    0.760    \nGendermale              1.965e-04  4.810e-03   0.041    0.967    \nGenderunknown           4.097e-04  6.120e-03   0.067    0.947    \nAge18-24                1.497e-03  3.007e-03   0.498    0.619    \nAge25-34                1.799e-03  3.005e-03   0.599    0.549    \nAge35-44                1.874e-03  3.006e-03   0.623    0.533    \nAge45-54                2.607e-03  3.012e-03   0.865    0.387    \nAge55-64                2.712e-03  3.012e-03   0.900    0.368    \nAge65+                  4.702e-03  3.019e-03   1.557    0.119    \nave.cost.impr           4.306e-02  6.608e-03   6.516 7.25e-11 ***\nGendermale:Age18-24    -6.997e-05  4.817e-03  -0.015    0.988    \nGenderunknown:Age18-24 -4.670e-04  6.156e-03  -0.076    0.940    \nGendermale:Age25-34    -4.299e-04  4.814e-03  -0.089    0.929    \nGenderunknown:Age25-34 -7.873e-04  6.151e-03  -0.128    0.898    \nGendermale:Age35-44    -6.757e-06  4.818e-03  -0.001    0.999    \nGenderunknown:Age35-44 -8.994e-04  6.166e-03  -0.146    0.884    \nGendermale:Age45-54    -1.671e-03  4.845e-03  -0.345    0.730    \nGenderunknown:Age45-54  2.184e-03  6.270e-03   0.348    0.728    \nGendermale:Age55-64    -7.455e-04  4.836e-03  -0.154    0.877    \nGenderunknown:Age55-64  2.492e-04  6.247e-03   0.040    0.968    \nGendermale:Age65+      -1.479e-03  4.831e-03  -0.306    0.760    \nGenderunknown:Age65+   -9.135e-04  6.224e-03  -0.147    0.883    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04524 on 770091 degrees of freedom\nMultiple R-squared:  0.0009605, Adjusted R-squared:  0.0009332 \nF-statistic: 35.25 on 21 and 770091 DF,  p-value: < 2.2e-16\n\n\nCode\nsummary(lm(data = gwwc_vid_results,DV~Gender*Age))\n\n\n\nCall:\nlm(formula = DV ~ Gender * Age, data = gwwc_vid_results)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.00629 -0.00180 -0.00150 -0.00120  0.99895 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)  \n(Intercept)             3.049e-14  3.003e-03   0.000   1.0000  \nGendermale             -2.692e-14  4.810e-03   0.000   1.0000  \nGenderunknown           3.038e-14  6.119e-03   0.000   1.0000  \nAge18-24                1.132e-03  3.006e-03   0.376   0.7066  \nAge25-34                1.502e-03  3.004e-03   0.500   0.6172  \nAge35-44                1.706e-03  3.006e-03   0.568   0.5703  \nAge45-54                3.089e-03  3.011e-03   1.026   0.3050  \nAge55-64                3.507e-03  3.010e-03   1.165   0.2439  \nAge65+                  6.293e-03  3.010e-03   2.091   0.0365 *\nGendermale:Age18-24     6.977e-05  4.817e-03   0.014   0.9884  \nGenderunknown:Age18-24 -7.811e-05  6.156e-03  -0.013   0.9899  \nGendermale:Age25-34    -3.072e-04  4.814e-03  -0.064   0.9491  \nGenderunknown:Age25-34 -4.034e-04  6.151e-03  -0.066   0.9477  \nGendermale:Age35-44     9.669e-05  4.818e-03   0.020   0.9840  \nGenderunknown:Age35-44 -6.279e-04  6.166e-03  -0.102   0.9189  \nGendermale:Age45-54    -1.687e-03  4.845e-03  -0.348   0.7277  \nGenderunknown:Age45-54  2.235e-03  6.270e-03   0.356   0.7215  \nGendermale:Age55-64    -9.220e-04  4.836e-03  -0.191   0.8488  \nGenderunknown:Age55-64  2.439e-04  6.247e-03   0.039   0.9689  \nGendermale:Age65+      -2.110e-03  4.830e-03  -0.437   0.6623  \nGenderunknown:Age65+   -1.408e-03  6.224e-03  -0.226   0.8210  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04524 on 770092 degrees of freedom\nMultiple R-squared:  0.0009054, Adjusted R-squared:  0.0008794 \nF-statistic: 34.89 on 20 and 770092 DF,  p-value: < 2.2e-16\n\n\n\n\n3.6.2 Regressions with no interactions\njust demographics, not control\n\n\nCode\nsummary(data = lm(gwwc_vid_results,DV~Gender+Age))\n\n\nError in as.data.frame.default(data): cannot coerce class '\"formula\"' to a data.frame\n\n\njust demographic, controlling for cost\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nmeans and standard errors for age groups/gender\n\n\nCode\nprint(gwwc_vid_results %>% group_by(Gender,Age) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)\n\n\n# A tibble: 21 × 7\n# Groups:   Gender [3]\n   Gender  Age   results      SE      n   cost      CPR\n   <fct>   <fct>   <dbl>   <dbl>  <int>  <dbl>    <dbl>\n 1 female  13-17   0     0          227 0.0213 Inf     \n 2 female  18-24   0.113 0.0107   98953 0.0129   0.114 \n 3 female  25-34   0.150 0.00843 211071 0.0144   0.0960\n 4 female  35-44   0.171 0.0118  121915 0.0174   0.102 \n 5 female  45-54   0.309 0.0276   40467 0.0325   0.105 \n 6 female  55-64   0.351 0.0265   49900 0.0398   0.113 \n 7 female  65+     0.629 0.0350   51172 0.0583   0.0926\n 8 male    13-17   0     0          145 0.0168 Inf     \n 9 male    18-24   0.120 0.0165   44107 0.0115   0.0960\n10 male    25-34   0.119 0.0130   71149 0.0127   0.106 \n11 male    35-44   0.180 0.0234   32727 0.0153   0.0847\n12 male    45-54   0.140 0.0443    7134 0.0276   0.197 \n13 male    55-64   0.259 0.0516    9671 0.0311   0.120 \n14 male    65+     0.418 0.0558   13388 0.0390   0.0933\n15 unknown 13-17   0     0           72 0.0118 Inf     \n16 unknown 18-24   0.105 0.0471    4745 0.0124   0.117 \n17 unknown 25-34   0.110 0.0448    5462 0.0138   0.126 \n18 unknown 35-44   0.108 0.0539    3710 0.0142   0.132 \n19 unknown 45-54   0.532 0.217     1127 0.0242   0.0454\n20 unknown 55-64   0.375 0.167     1333 0.0302   0.0804\n21 unknown 65+     0.488 0.172     1638 0.0372   0.0763\n\n\n\n\nCode\nhist(gwwc_vid_results$DV_costadj[gwwc_vid_results$DV_costadj>0])\n\n\n\n\n\nCode\nhist(gwwc_vid_results$DV_costadj[gwwc_vid_results$DV_costadj>=0])\n\n\n\n\n\n\n\n3.6.3 DEMOGRAPHICS WITH CONTROLS FOR VIDEO AND COST\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\nsummary(lm(gwwc_vid_results, DV_costadj~Gender+Age))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\n\n3.6.3.1 AUDIENCES\nmain effects\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nNEW DV\n\n\nCode\nsummary(lm(gwwc_vid_results,DV_costadj~Gender+Age+audience))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #interactions\n  summary(lm(gwwc_vid_results,DV~Gender*audience+ave.cost.impr+Age))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n## NEW DV\n    summary(lm(gwwc_vid_results,DV_costadj~Gender*audience+Age))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  summary(lm(gwwc_vid_results,DV~Age*audience+ave.cost.impr+Gender))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #means for audience\n  print(gwwc_vid_results %>% group_by(audience) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)\n\n\n# A tibble: 7 × 6\n  audience     results      SE      n   cost    CPR\n  <fct>          <dbl>   <dbl>  <int>  <dbl>  <dbl>\n1 philanthropy   0.195 0.00885 248852 0.0220 0.112 \n2 animal         0.229 0.0110  187212 0.0222 0.0973\n3 climate        0.178 0.0113  139824 0.0181 0.102 \n4 general        0.112 0.0140   57012 0.0130 0.116 \n5 lookalike      0.344 0.0226   67359 0.0266 0.0773\n6 poverty        0.171 0.0157   69404 0.0182 0.106 \n7 retargeting    0.667 0.384      450 0.0250 0.0376\n\n\n\n\n3.6.3.2 MESSAGES\nno controls\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~message))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #control for cost only\n  summary(lm(gwwc_vid_results,DV~message+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #check results with campaign\n  summary(lm(gwwc_vid_results,DV~Campaign.name))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #check results with campaign and cost control\n  summary(lm(gwwc_vid_results,DV~Campaign.name+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nwith controls\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience+message))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #interactions\n  #with audience\n  summary(lm(gwwc_vid_results,DV~message*audience+ave.cost.impr+Age+Gender))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #with Gender\n  summary(lm(gwwc_vid_results,DV~message*Gender+ave.cost.impr+Age+audience))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\n  #with Age (emotional much worse with ages 65+)\n  summary(lm(gwwc_vid_results,DV~message*Age+ave.cost.impr+Age+audience))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\ninteraction with age and campaign restriction\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~message*agetrin+message*restriction18_39+ave.cost.impr+Age+Gender))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~message*agetrin+message*restriction18_39+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nin just early campaigns\n\n\nCode\nsummary(lm(subset(data,restriction18_39==0),DV~message*agetrin+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': object 'restriction18_39' not found\n\n\n\n\n\n3.6.4 MEDIA\nno controls\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~media))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% group_by(media) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results)\n\n\n# A tibble: 6 × 6\n  media         results      SE      n   cost    CPR\n  <fct>           <dbl>   <dbl>  <int>  <dbl>  <dbl>\n1 factual short   0.223 0.00820 331287 0.0186 0.0834\n2 animal          0.250 0.0118  180327 0.0274 0.110 \n3 climate         0.186 0.0219   38703 0.0160 0.0862\n4 factual long    0.171 0.0237   30359 0.0378 0.221 \n5 hypercube       0.104 0.0117   75790 0.0176 0.169 \n6 poverty         0.165 0.0121  113647 0.0155 0.0939\n\n\ncontrol for cost only\n\n\nCode\nsummary(lm(gwwc_vid_results,DV~media+ave.cost.impr))\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': cannot coerce class '\"formula\"' to a data.frame"
  },
  {
    "objectID": "chapters/gwwc_gg.html#new-dv",
    "href": "chapters/gwwc_gg.html#new-dv",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.10 NEW DV",
    "text": "1.10 NEW DV\n\n\nCode\n#lm(gwwc_vid_results,DV_costadj~media))####THIS IS GOOD\n\n\nwith controls\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience+media)\n\n\n\n1.10.1 NEW DV\n\n\nCode\n#lm(gwwc_vid_results,DV_costadj~Gender+Age+audience+media)\n\n\ninteractions\n\n\nCode\n#lm(gwwc_vid_results,DV~media*Age+media*Gender+media*audience+ave.cost.impr)\n#lm(gwwc_vid_results,DV_costadj~media*Age+media*Gender+media*audience)\n#lm(gwwc_vid_results,DV~media*Age+media*Gender+media*audience)\n#lm(gwwc_vid_results,DV_costadj~Age+Gender+media*audience)\n\n\nwith audience\n\n\nCode\n#lm(gwwc_vid_results,DV~media*audience+ave.cost.impr+Age+Gender)\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% group_by(audience,media) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results) %>%\n.kable() %>% .kable_styling()\n\n\n\n \n  \n    audience \n    media \n    results \n    SE \n    n \n    cost \n    CPR \n  \n \n\n  \n    philanthropy \n    factual short \n    0.2278935 \n    0.0195196 \n    59,677 \n    0.0212306 \n    0.0931603 \n  \n  \n    philanthropy \n    animal \n    0.2124797 \n    0.0163273 \n    79,537 \n    0.0287906 \n    0.1354982 \n  \n  \n    philanthropy \n    climate \n    0.2748644 \n    0.0445292 \n    13,825 \n    0.0194358 \n    0.0707105 \n  \n  \n    philanthropy \n    factual long \n    0.1588907 \n    0.0478727 \n    6,923 \n    0.0442424 \n    0.2784455 \n  \n  \n    philanthropy \n    hypercube \n    0.1436699 \n    0.0287142 \n    17,401 \n    0.0165272 \n    0.1150360 \n  \n  \n    philanthropy \n    poverty \n    0.1496734 \n    0.0144587 \n    71,489 \n    0.0146207 \n    0.0976841 \n  \n  \n    animal \n    factual short \n    0.2025473 \n    0.0149169 \n    90,843 \n    0.0177818 \n    0.0877908 \n  \n  \n    animal \n    animal \n    0.2802197 \n    0.0186139 \n    80,651 \n    0.0264827 \n    0.0945071 \n  \n  \n    animal \n    factual long \n    0.1489118 \n    0.0412723 \n    8,730 \n    0.0331970 \n    0.2229308 \n  \n  \n    animal \n    hypercube \n    0.0715512 \n    0.0319895 \n    6,988 \n    0.0176674 \n    0.2469200 \n  \n  \n    climate \n    factual short \n    0.2051549 \n    0.0146018 \n    96,025 \n    0.0167376 \n    0.0815853 \n  \n  \n    climate \n    climate \n    0.1063830 \n    0.0274543 \n    14,100 \n    0.0135738 \n    0.1275933 \n  \n  \n    climate \n    factual long \n    0.1886397 \n    0.0444232 \n    9,542 \n    0.0362073 \n    0.1919389 \n  \n  \n    climate \n    hypercube \n    0.0942601 \n    0.0216151 \n    20,157 \n    0.0195252 \n    0.2071421 \n  \n  \n    general \n    factual short \n    0.0963824 \n    0.0248746 \n    15,563 \n    0.0096248 \n    0.0998600 \n  \n  \n    general \n    animal \n    0.1422880 \n    0.0367142 \n    10,542 \n    0.0134842 \n    0.0947667 \n  \n  \n    general \n    climate \n    0.1611171 \n    0.0464761 \n    7,448 \n    0.0100953 \n    0.0626583 \n  \n  \n    general \n    hypercube \n    0.0948852 \n    0.0206963 \n    22,132 \n    0.0162078 \n    0.1708143 \n  \n  \n    general \n    poverty \n    0.0753580 \n    0.0753580 \n    1,327 \n    0.0111831 \n    0.1484000 \n  \n  \n    lookalike \n    factual short \n    0.3886843 \n    0.0336381 \n    34,218 \n    0.0254869 \n    0.0655722 \n  \n  \n    lookalike \n    animal \n    0.4234148 \n    0.0668094 \n    9,447 \n    0.0398878 \n    0.0942050 \n  \n  \n    lookalike \n    climate \n    0.2129601 \n    0.0804179 \n    3,287 \n    0.0257438 \n    0.1208857 \n  \n  \n    lookalike \n    factual long \n    0.7181329 \n    0.3580964 \n    557 \n    0.0782406 \n    0.1089500 \n  \n  \n    lookalike \n    hypercube \n    0.2512563 \n    0.1449412 \n    1,194 \n    0.0249665 \n    0.0993667 \n  \n  \n    lookalike \n    poverty \n    0.2412093 \n    0.0359149 \n    18,656 \n    0.0206915 \n    0.0857822 \n  \n  \n    poverty \n    factual short \n    0.2124178 \n    0.0246672 \n    34,837 \n    0.0185498 \n    0.0873270 \n  \n  \n    poverty \n    factual long \n    0.1088139 \n    0.0486419 \n    4,595 \n    0.0349859 \n    0.3215200 \n  \n  \n    poverty \n    hypercube \n    0.0765697 \n    0.0312495 \n    7,836 \n    0.0180028 \n    0.2351167 \n  \n  \n    poverty \n    poverty \n    0.1535960 \n    0.0263218 \n    22,136 \n    0.0143694 \n    0.0935529 \n  \n  \n    retargeting \n    factual short \n    0.0000000 \n    0.0000000 \n    124 \n    0.0254032 \n    Inf \n  \n  \n    retargeting \n    animal \n    0.6666667 \n    0.6666667 \n    150 \n    0.0304000 \n    0.0456000 \n  \n  \n    retargeting \n    climate \n    0.0000000 \n    0.0000000 \n    43 \n    0.0200000 \n    Inf \n  \n  \n    retargeting \n    factual long \n    8.3333333 \n    8.3333333 \n    12 \n    0.0933333 \n    0.0112000 \n  \n  \n    retargeting \n    hypercube \n    0.0000000 \n    0.0000000 \n    82 \n    0.0131707 \n    Inf \n  \n  \n    retargeting \n    poverty \n    2.5641026 \n    2.5641026 \n    39 \n    0.0128205 \n    0.0050000 \n  \n\n\n\n\n\nwith Gender\n\n\nCode\n#lm(gwwc_vid_results,DV~media*Gender+ave.cost.impr+Age+audience)\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% group_by(Gender, media) %>% summarise(\n  results = mean(DV) * 100,\n  SE = std.error(DV) * 100,\n  n = n(),\n  cost = mean(ave.cost.impr),\n  CPR = cost / results\n)\n\n\n\ninteraction with age and campaign restriction - old people really hated factual long\n\n\nCode\n#lm(gwwc_vid_results,DV~media*agetrin+media*restriction18_39+ave.cost.impr+Age+Gender))\n#lm(gwwc_vid_results,DV~media*agetrin+media*restriction18_39+ave.cost.impr))\n\n\nin just early campaigns\n\n\nCode\n#subset(gwwc_vid_results,restriction18_39==0),DV~media*agetrin+ave.cost.impr))\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% filter(restriction18_39 == 0) %>% group_by(Age, media) %>% summarise(\n  results = mean(DV) * 100,\n  SE = std.error(DV) * 100,\n  n = n(),\n  cost = mean(ave.cost.impr),\n  CPR = cost / results\n)"
  },
  {
    "objectID": "chapters/gwwc_gg.html#statistics-and-models-needs-to-be-made-into-tables",
    "href": "chapters/gwwc_gg.html#statistics-and-models-needs-to-be-made-into-tables",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.9 Statistics and models – needs to be made into tables",
    "text": "1.9 Statistics and models – needs to be made into tables\n\n1.9.1 Regressions with interactions\n\n\nCode\n#lm(data = gwwc_vid_results, DV~Gender*Age+ave.cost.impr)\n#lm(data = gwwc_vid_results,DV~Gender*Age))\n\n\n\n\n1.9.2 Regressions with no interactions\njust demographics, not control\n\n\nCode\n#data = lm(gwwc_vid_results,DV~Gender+Age)\n\n\njust demographic, controlling for cost\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr)\n\n\nmeans and standard errors for age groups/gender\n\n\nCode\ngwwc_vid_results %>% group_by(Gender,Age) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results) %>%\n  .kable() %>% .kable_styling()\n\n\n\n \n  \n    Gender \n    Age \n    results \n    SE \n    n \n    cost \n    CPR \n  \n \n\n  \n    female \n    13-17 \n    0.0000000 \n    0.0000000 \n    227 \n    0.0213216 \n    Inf \n  \n  \n    female \n    18-24 \n    0.1131850 \n    0.0106890 \n    98,953 \n    0.0128517 \n    0.1135455 \n  \n  \n    female \n    25-34 \n    0.1501864 \n    0.0084290 \n    211,071 \n    0.0144178 \n    0.0959994 \n  \n  \n    female \n    35-44 \n    0.1706107 \n    0.0118197 \n    121,915 \n    0.0174212 \n    0.1021111 \n  \n  \n    female \n    45-54 \n    0.3088937 \n    0.0275859 \n    40,467 \n    0.0325183 \n    0.1052736 \n  \n  \n    female \n    55-64 \n    0.3507014 \n    0.0264643 \n    49,900 \n    0.0397964 \n    0.1134766 \n  \n  \n    female \n    65+ \n    0.6292504 \n    0.0349566 \n    51,172 \n    0.0582582 \n    0.0925835 \n  \n  \n    male \n    13-17 \n    0.0000000 \n    0.0000000 \n    145 \n    0.0167586 \n    Inf \n  \n  \n    male \n    18-24 \n    0.1201623 \n    0.0164958 \n    44,107 \n    0.0115342 \n    0.0959887 \n  \n  \n    male \n    25-34 \n    0.1194676 \n    0.0129504 \n    71,149 \n    0.0127057 \n    0.1063529 \n  \n  \n    male \n    35-44 \n    0.1802793 \n    0.0234496 \n    32,727 \n    0.0152608 \n    0.0846508 \n  \n  \n    male \n    45-54 \n    0.1401738 \n    0.0442989 \n    7,134 \n    0.0275820 \n    0.1967700 \n  \n  \n    male \n    55-64 \n    0.2585048 \n    0.0516368 \n    9,671 \n    0.0311354 \n    0.1204440 \n  \n  \n    male \n    65+ \n    0.4182850 \n    0.0557807 \n    13,388 \n    0.0390365 \n    0.0933250 \n  \n  \n    unknown \n    13-17 \n    0.0000000 \n    0.0000000 \n    72 \n    0.0118056 \n    Inf \n  \n  \n    unknown \n    18-24 \n    0.1053741 \n    0.0471048 \n    4,745 \n    0.0123688 \n    0.1173800 \n  \n  \n    unknown \n    25-34 \n    0.1098499 \n    0.0448255 \n    5,462 \n    0.0138191 \n    0.1258000 \n  \n  \n    unknown \n    35-44 \n    0.1078167 \n    0.0538865 \n    3,710 \n    0.0142102 \n    0.1318000 \n  \n  \n    unknown \n    45-54 \n    0.5323869 \n    0.2168629 \n    1,127 \n    0.0241792 \n    0.0454167 \n  \n  \n    unknown \n    55-64 \n    0.3750938 \n    0.1674950 \n    1,333 \n    0.0301575 \n    0.0804000 \n  \n  \n    unknown \n    65+ \n    0.4884005 \n    0.1723061 \n    1,638 \n    0.0372466 \n    0.0762625 \n  \n\n\n\n\n\n\n\nCode\nhist(gwwc_vid_results$DV_costadj[gwwc_vid_results$DV_costadj>0])\n\n\n\n\n\nCode\nhist(gwwc_vid_results$DV_costadj[gwwc_vid_results$DV_costadj>=0])\n\n\n\n\n\n\n\n1.9.3 DEMOGRAPHICS WITH CONTROLS FOR VIDEO AND COST\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr)\n#lm(gwwc_vid_results, DV_costadj~Gender+Age)\n\n\n\n1.9.3.1 AUDIENCES\nmain effects\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience)\n\n\nNEW DV\n\n\nCode\n#lm(gwwc_vid_results,DV_costadj~Gender+Age+audience)\n\n  #interactions\n  #lm(gwwc_vid_results,DV~Gender*audience+ave.cost.impr+Age)\n\n## NEW DV\n    #lm(gwwc_vid_results,DV_costadj~Gender*audience+Age)\n  #lm(gwwc_vid_results,DV~Age*audience+ave.cost.impr+Gender)\n\n  #means for audience\ngwwc_vid_results %>%\n  group_by(audience) %>%\n  summarise(\n    results=mean(DV)*100,\n    SE=std.error(DV)*100,\n    n=n(),\n    cost=mean(ave.cost.impr),\n    CPR=cost/results) %>%\n    .kable %>%\n      .kable_styling()\n\n\n\n \n  \n    audience \n    results \n    SE \n    n \n    cost \n    CPR \n  \n \n\n  \n    philanthropy \n    0.1952968 \n    0.0088502 \n    248,852 \n    0.0219596 \n    0.1124424 \n  \n  \n    animal \n    0.2286178 \n    0.0110380 \n    187,212 \n    0.0222447 \n    0.0973009 \n  \n  \n    climate \n    0.1780810 \n    0.0112754 \n    139,824 \n    0.0181491 \n    0.1019149 \n  \n  \n    general \n    0.1122571 \n    0.0140244 \n    57,012 \n    0.0129917 \n    0.1157312 \n  \n  \n    lookalike \n    0.3444232 \n    0.0225737 \n    67,359 \n    0.0266180 \n    0.0772828 \n  \n  \n    poverty \n    0.1714599 \n    0.0157043 \n    69,404 \n    0.0182429 \n    0.1063975 \n  \n  \n    retargeting \n    0.6666667 \n    0.3840420 \n    450 \n    0.0250444 \n    0.0375667 \n  \n\n\n\n\n\n\n\n1.9.3.2 MESSAGES\nno controls\n\n\nCode\n#lm(gwwc_vid_results,DV~message\n  #control for cost only\n  #lm(gwwc_vid_results,DV~message+ave.cost.impr)\n  #check results with campaign\n  #lm(gwwc_vid_results,DV~Campaign.name)\n  #check results with campaign and cost control\n  #lm(gwwc_vid_results,DV~Campaign.name+ave.cost.impr)\n\n\nwith controls\n\n\nCode\n#lm(gwwc_vid_results,DV~Gender+Age+ave.cost.impr+audience+message)\n\n#interactions\n#with audience\n#lm(gwwc_vid_results,DV~message*audience+ave.cost.impr+Age+Gender)\n#with Gender\n#lm(gwwc_vid_results,DV~message*Gender+ave.cost.impr+Age+audience)\n#with Age (emotional much worse with ages 65+)\n#lm(gwwc_vid_results,DV~message*Age+ave.cost.impr+Age+audience)\n\n\ninteraction with age and campaign restriction\n\n\nCode\n#lm(gwwc_vid_results,DV~message*agetrin+message*restriction18_39+ave.cost.impr+Age+Gender)\n#lm(gwwc_vid_results,DV~message*agetrin+message*restriction18_39+ave.cost.impr)\n\n\nin just early campaigns\n\n\nCode\n#lm(subset(data,restriction18_39==0),DV~message*agetrin+ave.cost.impr)\n\n\n\n\n\n1.9.4 MEDIA\nno controls\n\n\nCode\n#lm(gwwc_vid_results,DV~media)\n\n\nmeans and SEs\n\n\nCode\ngwwc_vid_results %>% group_by(media) %>% summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results)\n\n\n# A tibble: 6 × 6\n  media         results      SE      n   cost    CPR\n  <fct>           <dbl>   <dbl>  <int>  <dbl>  <dbl>\n1 factual short   0.223 0.00820 331287 0.0186 0.0834\n2 animal          0.250 0.0118  180327 0.0274 0.110 \n3 climate         0.186 0.0219   38703 0.0160 0.0862\n4 factual long    0.171 0.0237   30359 0.0378 0.221 \n5 hypercube       0.104 0.0117   75790 0.0176 0.169 \n6 poverty         0.165 0.0121  113647 0.0155 0.0939\n\n\ncontrol for cost only\n\n\nCode\n#lm(gwwc_vid_results,DV~media+ave.cost.impr)"
  },
  {
    "objectID": "chapters/gwwc_gg.html#analysis-and-visuals",
    "href": "chapters/gwwc_gg.html#analysis-and-visuals",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.7 Analysis and visuals",
    "text": "1.7 Analysis and visuals\n14\n\n\nCode\n##gwwc_vid_results$DV_costadj)\n##gwwc_vid_results$DV)\n##gwwc_vid_results$ave.cost.impr)\n\n\nData summary\n\nBelow, a few data summary bits (from Erin). I commented most of it out and will redo it using an automated and formatted ‘key summary statistics’ package.\nI may also present the data in a dashboard for self-service.\n\n\n\nCode\n#datatable(gwwc_vid_results)\n\n\n\n\nCode\n#print(gwwc_vid_results %>% group_by(Gender,Age) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=40)\n\n#gwwc_vid_results %>% group_by(audience) %>% summarise(n=n(), cost=mean(ave.cost.impr)*100) %>% .kable(digits=2, caption=\"Average cost per impression (in pennies)\") %>%  .kable_styling()\n\n#gwwc_vid_results %>% group_by(message) %>% summarise(n=n(),cost=mean(ave.cost.impr)*100) %>% .kable(digits=2, caption=\"Average cost per impression (in pennies)\") %>%  .kable_styling()\n\n\n\n\nCode\n### CHART DATA\n\n#print(gwwc_vid_results %>% group_by(audience,media) %>% #summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)"
  },
  {
    "objectID": "chapters/gwwc_gg.html#notes-from-the-trial-description",
    "href": "chapters/gwwc_gg.html#notes-from-the-trial-description",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.2 Notes from the trial description",
    "text": "1.2 Notes from the trial description\n“In the original version of our test, we had 1 video for the factual appeal and 3 videos for the cause led approach - 1 for global health and development, 1 for animal welfare and 1 for climate change.”\n“We targeted our ads to audiences we thought were likely to engage based on their interests and demographics, and targeted the cause led videos to a relevant audience, i.e. climate change message to climate change audience.”\n“We also had various text above the videos that were displayed and optimised.”\nDetails in Gitbook HERE and Gdoc here\n\n\nCode\nknitr::include_url(\"https://effective-giving-marketing.gitbook.io/untitled/partner-organizations-and-trials/gwwc/giving-guides-+\")"
  },
  {
    "objectID": "chapters/gwwc_gg.html#the-trial",
    "href": "chapters/gwwc_gg.html#the-trial",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.1 The trial",
    "text": "1.1 The trial\nSee full description in the gitbook here.\nContext: Facebook advertisements on a range of audiences\n\nEffective Giving Guide Lead Generation campaign … ran late November 2021 - January 2022. The objective of this campaign was to see whether a factual [‘who researches giving’ or ‘magnitude of impact differences’] or cause-led approach was more cost-effective at getting people to fill out a form and give us their email in order to download our Effective Giving Guide.\n\nThe page they were directed to,  “Learn how to give more effectively allowed you to download the guide only after leaving your email.\n\nTreatments (text \\(\\times\\) video)\nThere were two dimensions of treatment content:\n\nThe texts displayed above the videos\n\n\n\n\n\n\n\nTexts\n\n\n\n\n\nBigger difference next year: Want to make a bigger difference next year? Start with our Effective Giving Guide and learn how to make a remarkable impact just by carefully choosing the charities you give to.\n100x impact: Did you know that the best charities can have a 100x greater impact? Download our free Effective Giving Guide for the best tips on doing the most good this holiday season.\n6000 people: Giving What We Can has helped 6,000+ people make a bigger impact on the causes they care about most. Download our free guide and learn how you can do the same.\nCause list: Whether we’re moved by animal welfare, the climate crisis, or worldwide humanitarian efforts, our community is united by one thing: making the biggest impact we can. Make a bigger difference in the world through charitable giving. Start by downloading our Effective Giving Guide. You’ll learn how to approach charity research and smart giving. And be sure to share it with others who care about making a greater impact on the causes closest to their hearts.\nLearn: Use our free guide to learn how to make a bigger impact on the causes you care about most.\nOnly 3% research: Only 3% of donors give based on charity effectiveness yet the best charities can be 100x more impactful. That’s incredible! Check out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes.\nOverwhelming: It can be overwhelming with so many problems in the world. Fortunately, we can do a lot to help, if we give effectively. Check out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes.\n\n\n\n\n\n\n\n\n\nCheck against data export of texts\n\n\n\n\n\nGiving What We Can has helped 6,000+ people make a bigger impact on the causes they care about most. Download our free guide and learn how you can do the same., It can be overwhelming with so many problems in the world. Fortunately, we can do a lot to help, if we give effectively.\nCheck out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes., Use our free guide to learn how to make a bigger impact on the causes you care about most., Want to make a bigger difference next year? Start with our Effective Giving Guide and learn how to make a remarkable impact just by carefully choosing the charities you give to., Whether we’re moved by animal welfare, the climate crisis, or worldwide humanitarian efforts, our community is united by one thing: making the biggest impact we can.\nMake a bigger difference in the world through charitable giving. Start by downloading our Effective Giving Guide. You’ll learn how to approach charity research and smart giving. And be sure to share it with others who care about making a greater impact on the causes closest to their hearts., Did you know that the best charities can have a 100x greater impact? Download our free Effective Giving Guide for the best tips on doing the most good this holiday season., Only 3% of donors give based on charity effectiveness yet the best charities can be 100x more impactful. That’s incredible!\nCheck out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes.\n\n\n\n\nThe Video ads theme and content\n\n\n\n\n\n\n\n“Facts”\n\n\n\n\n\n\nCharity research facts short video (8 seconds): Only 3% of donors research charity effectiveness, yet the best charities can 100x your impact, learn how to give effectively \nCharity research facts long video (22 seconds): Trivial things we search (shows someone searching how to do Gangnam style), things we should research (shows someone searching how to donate effectively), only 3% of donors research charity effectiveness, yet the best charities can 100x your impact, learn how to give effectively. Slower paced music compared to the short video and cause videos.  \n\n\n\n\n\n\n\n\n\n\n“Cause focus”\n\n\n\n\n\n\nClimate change (15 seconds): Care about climate change? You don’t have to renounce all your possessions, But you could give to effective environmental charities, Learn how to maximize your charitable impact, Download the Effective Giving Guide \nAnimal welfare (16 seconds): Care about animals? You don’t have to adopt 100 cats, But you could give to effective animal charities, Learn how to maximize your charitable impact, Download the Effective Giving Guide \nPoverty (16 seconds): Want to help reduce global poverty? You don’t have to build a village, But you could give to effective global development charities, Learn how to maximize your charitable impact, Download the Effective Giving Guide \n\n\n\n\n\n\n\n\n\n\nArguments, rich content from “Brand Video”\n\n\n\n\n\n\nBrand Video (1 min 22 seconds): Animated and voiceover video that explains how GWWC can help maximize charitable impact (support, community, and information) and the problems GWWC addresses (good intentions don’t always produce the desired outcomes, there are millions of charities that have varying degrees of impact and some can even cause harm). CTA: Check out givingwhatwecan.org to learn how you can become an effective giver.\n\n\n\n\n\n\nFurther detail, links\n\n\n\n\n\n\nNotes from the trial description\n\n\n\n\n\n“In the original version of our test, we had 1 video for the factual appeal and 3 videos for the cause led approach - 1 for global health and development, 1 for animal welfare and 1 for climate change.”\n“We targeted our ads to audiences we thought were likely to engage based on their interests and demographics, and targeted the cause led videos to a relevant audience, i.e. climate change message to climate change audience.”\n“We also had various text above the videos that were displayed and optimized.”\n\n\n\nDetails in Gitbook HERE (and embedded below) and Gdoc here\n\n\nCode\nknitr::include_url(\"https://effective-giving-marketing.gitbook.io/untitled/partner-organizations-and-trials/gwwc/giving-guides-+\")"
  },
  {
    "objectID": "chapters/gwwc_gg.html#implementation-and-treatment-assignment-key-details",
    "href": "chapters/gwwc_gg.html#implementation-and-treatment-assignment-key-details",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.2 Implementation and treatment assignment: key details",
    "text": "1.2 Implementation and treatment assignment: key details\n\n\n\n\n\n\nTreatment assignment order, dates\n\n\n\n\n\nThe treatment assignment was determined by Facebook’s algorithm. Video content was manipulated across three split tests.\nTest 1 (Nov 30, 2021 – Dec 8, 2021) displayed either the long factual video or a cause focus video. In the cause focus condition, cause-specific audiences for animal rights, climate change, and poverty (based on their behavior on Facebook) were shown the relevant cause video.\nTest 2 (add dates) was the same as Test 1 but used the short factual video instead of the cause-focus videos.\nTest 3 (add dates) was the same as Test 2 but had a new version of the videos (with Luke just holding up signs with the words). This test was also restricted to 18-35 year olds.\nTest 4: The Hypercube video was displayed in a separate “Hypercube” campaign which was tested against another campaign that allowed the algorithm to optimize between the ‘short factual’ and ‘cause focus’ videos (although not allowing each cause-specific audience to see the ads for other cause areas).\nIn all tests, the text content displayed above the video was determined by Facebook’s algorithm. Balance across variations was determined to equate budgets across split tests; otherwise, according to Facebook’s algorithm. All variation was done at the level of the impression.\nThe videos were adapted across the trials as we learned. First, we updated the factual video to be shorter for Trial 2, and then we tried videos of Luke holding up signs spelling out the voiceover in Trial 3 for all videos."
  },
  {
    "objectID": "chapters/gwwc_gg.html#descriptives",
    "href": "chapters/gwwc_gg.html#descriptives",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.4 Descriptives",
    "text": "1.4 Descriptives\n\n1.4.1 Implemented treatments, ‘reach’\nFirst we illustrate ‘where, when, and to whom’ the different campaigns and treatments were shown (‘people reached’ on Facebook).\n\n\n\n\n\n\nWe use ‘reach’ as our metric throughout’; essentially ‘unique impressions’\n\n\n\n\n\nAccording to Facebook (https://business.facebook.com/adsmanager/ accessed 5 Aug 2022), reach is:\n\nThe number of people who saw your ads at least once. Reach is different from impressions, which may include multiple views of your ads by the same people.\n\nIn all of our figures below we use the reach outcome rather than the ‘impressions’ outcome, although we sometimes refer to it as ‘impressions’, because it is a clearer way of describing it.\n\n\n\nThe sequential campaigns involved different sets of videos.\n\n\nCode\n(\n  reach_campaign_theme <- gg_video_breakdowns %>%\n  dplyr::select(campaign_name, video_theme, reach) %>%\n   uncount(weights = .$reach) %>%\n    dplyr::select(-reach) %>%\n   tabyl(campaign_name, video_theme) %>%\n    dplyr::select(campaign_name, Animal, Climate, Poverty, everything()) %>%\n  .kable(caption = \"Campaign names and video themes: unique impressions\") %>%\n  .kable_styling()\n)\n\n\n\nCampaign names and video themes: unique impressions\n \n  \n    campaign_name \n    Animal \n    Climate \n    Poverty \n    Factual short \n    Factual long \n    Hypercube (factual) \n  \n \n\n  \n    Giving Guide 2021 - Cause-led \n    81,298 \n    5,272 \n    33,027 \n    0 \n    0 \n    0 \n  \n  \n    Giving Guide 2021 – Cause-led V3 \n    37,680 \n    3,882 \n    60,346 \n    0 \n    0 \n    0 \n  \n  \n    Giving Guide 2021 – Factual \n    0 \n    0 \n    0 \n    2,333 \n    25,316 \n    0 \n  \n  \n    Giving Guide 2021 – Factual V2 \n    0 \n    0 \n    0 \n    103,329 \n    0 \n    0 \n  \n  \n    Giving Guide 2021 – Factual V3 \n    0 \n    0 \n    0 \n    112,203 \n    0 \n    0 \n  \n  \n    Giving Guide 2021 – Hypercube Brand Video \n    0 \n    0 \n    0 \n    0 \n    0 \n    56,694 \n  \n  \n    Giving Guide 2021 – PPCo Creatives \n    23,037 \n    23,238 \n    2,383 \n    62,116 \n    0 \n    0 \n  \n\n\n\n\n\nCode\nreach_campaign_audience <- gg_campaign_by_ad_by_text_age_gender %>% #created but not shown for now\n  dplyr::select(campaign_name, audience, reach) %>%\n   uncount(weights = .$reach) %>%\n    dplyr::select(-reach) %>%\n   tabyl(campaign_name, audience) %>%\n  .kable(caption = \"Campaign names and audiences: unique impressions\") %>%\n  .kable_styling()\n\n\n\n\n\n\n\n\nThese videos had different versions\n\n\n\n\n\n\n\nCode\n(\n  versions_of_videos <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(video_theme, version, reach) %>%\n   uncount(weights = .$reach) %>%\n    dplyr::select(-reach) %>%\n   table %>%\n  .kable(caption = \"Versions of videos: unique impressions\") %>%\n  .kable_styling()\n)\n\n\n\nVersions of videos: unique impressions\n \n  \n      \n    V1 \n    V2 - factual shortened \n    V3 - sometimes Luke \n    Video/creatives \n  \n \n\n  \n    Animal \n    40,852 \n    0 \n    20,593 \n    0 \n  \n  \n    Cause-led (any) \n    79,624 \n    0 \n    75,570 \n    117,888 \n  \n  \n    Climate \n    1,779 \n    0 \n    339 \n    0 \n  \n  \n    Factual long \n    29,589 \n    0 \n    0 \n    0 \n  \n  \n    Factual short \n    0 \n    109,262 \n    120,244 \n    0 \n  \n  \n    Hypercube (factual) \n    0 \n    0 \n    0 \n    66,393 \n  \n  \n    Poverty \n    7,906 \n    0 \n    12,017 \n    0 \n  \n\n\n\n\n\n\n\n\nWhich videos were shown to which audiences?\nSome audiences were profiled as being associated with a certain cause (through their Facebook interests or activities): in ‘cause-focused’ campaigns they were shown videos for their profiled cause. In campaigns that were not cause-focused, they were shown general interest videos. However, those associated with one cause were never shown videos for other causes.\nAudiences not associated with a cause included the ‘General’ audience, the Philanthropy (interested in charity) audience, a GWWC ‘Lookalike’ audience, and a Retargeted audience: these audiences were shown either the more general-interest videos or particular cause videos.5 This is illustrated in the table below.\n\n\n\nCode\nvideo_levels <- c(\"Animal\", \"Climate\", \"Poverty\", \"Factual short\",  \"Factual long\", \"Branded (Factual)\", \"Total\")\n\naudience_levels <- c(\"Animal\", \"Climate\", \"Global Poverty\", \"Philanthropy\", \"General audience\", \"Lookalikes\", \"Retargeting\")\n\n\nadorn_opts <- function(df) {\n  df %>% \n    adorn_percentages(\"all\") %>%\n    adorn_totals(where = c(\"row\", \"col\")) %>%\n    adorn_pct_formatting(digits = 2) \n}\n\n(\nreach_video_audience <- gg_video_breakdowns %>%\n    dplyr::select(video_theme, audience, reach) %>%\n    uncount(weights = .$reach) %>%\n    dplyr::select(-reach) %>%\n    tabyl(video_theme, audience) %>%\n    adorn_opts() %>% \n    dplyr::select(video_theme, Animal, Climate, `Global Poverty`, everything()) %>%\n   mutate(video_theme =  factor(video_theme, levels = video_levels)) %>%\n  arrange(video_theme)  %>%\n    .kable(caption = \"Video themes by audience: share of unique impressions\", digits=3) %>%\n  .kable_styling()\n)\n\n\n\nVideo themes by audience: share of unique impressions\n \n  \n    video_theme \n    Animal \n    Climate \n    Global Poverty \n    General audience \n    Lookalikes \n    Philanthropy \n    Retargeting \n    Total \n  \n \n\n  \n    Animal \n    9.77% \n    0.00% \n    0.00% \n    1.35% \n    1.31% \n    10.02% \n    0.01% \n    22.47% \n  \n  \n    Climate \n    0.00% \n    1.80% \n    0.00% \n    0.98% \n    0.45% \n    1.88% \n    0.01% \n    5.12% \n  \n  \n    Poverty \n    0.00% \n    0.00% \n    3.04% \n    0.18% \n    2.66% \n    9.26% \n    0.00% \n    15.15% \n  \n  \n    Factual short \n    11.84% \n    12.53% \n    4.88% \n    2.11% \n    4.73% \n    8.19% \n    0.01% \n    44.29% \n  \n  \n    Factual long \n    1.22% \n    1.19% \n    0.64% \n    0.00% \n    0.08% \n    0.88% \n    0.00% \n    4.00% \n  \n  \n    Total \n    23.78% \n    17.78% \n    9.60% \n    7.30% \n    9.39% \n    32.11% \n    0.04% \n    100.00% \n  \n  \n    NA \n    0.95% \n    2.26% \n    1.05% \n    2.67% \n    0.16% \n    1.88% \n    0.01% \n    8.97% \n  \n\n\n\n\n\n\nBelow (in fold), we see that the second treatment dimension – the text presented along with the video – was allowed to vary independently of the video (but these are not ‘statistically independent’).\n\n\n\n\n\n\nVideo themes by text treatment\n\n\n\n\n\n\n\nCode\nvideo_levels_gg <- c(\"Animal\", \"Climate\", \"Poverty\", \"Cause-led (any)\", \"Factual short\",  \"Factual long\", \"Branded (Factual)\", \"Total\")\n\n(\n  reach_video_text <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(video_theme, text_treat, reach) %>%\n   uncount(weights = .$reach) %>%\n    dplyr::select(-reach) %>%\n        tabyl(video_theme, text_treat) %>%\n       adorn_opts() %>% \n   mutate(video_theme =  factor(video_theme, levels = video_levels_gg)) %>%\n  arrange(video_theme)  %>%\n  .kable(caption = \"Video themes by text treatment: unique impressions\", digits=3) %>%\n  .kable_styling()\n)\n\n\n\nVideo themes by text treatment: unique impressions\n \n  \n    video_theme \n    100x impact \n    6000+ people \n    Bigger difference \n    Cause list \n    Learn \n    Only 3% research \n    Overwhelming \n    Total \n  \n \n\n  \n    Animal \n    0.00% \n    2.13% \n    3.36% \n    1.08% \n    1.26% \n    0.00% \n    1.18% \n    9.01% \n  \n  \n    Climate \n    0.00% \n    0.04% \n    0.05% \n    0.04% \n    0.13% \n    0.00% \n    0.05% \n    0.31% \n  \n  \n    Poverty \n    0.00% \n    0.40% \n    0.83% \n    1.01% \n    0.37% \n    0.00% \n    0.32% \n    2.92% \n  \n  \n    Cause-led (any) \n    4.66% \n    8.59% \n    5.94% \n    3.49% \n    6.79% \n    3.39% \n    7.19% \n    40.04% \n  \n  \n    Factual short \n    9.51% \n    5.39% \n    7.37% \n    0.00% \n    4.73% \n    6.64% \n    0.00% \n    33.65% \n  \n  \n    Factual long \n    0.61% \n    0.83% \n    0.94% \n    0.00% \n    1.28% \n    0.68% \n    0.00% \n    4.34% \n  \n  \n    Total \n    17.47% \n    18.81% \n    20.19% \n    5.62% \n    16.15% \n    13.04% \n    8.74% \n    100.00% \n  \n  \n    NA \n    2.69% \n    1.43% \n    1.71% \n    0.00% \n    1.59% \n    2.32% \n    0.00% \n    9.73% \n  \n\n\n\n\n\nNote (again) that we cannot identify all of the video treatments in the same dataset with text treatments; thus, some are characterized as ‘cause-led (any)’. This is a limitation of the Facebook interface.\n\n\n\nNote that treatment shares are not equal. In fact, as the first table in this sectionshows, they are not even equal within each campaign. This is because Facebook optimizes to show more succesful videos and text more than less succesful versions.6\nAs shown in the fold below, the set of text treatments varied across campaigns:\n\n\n\n\n\n\nText treatments by campaign\n\n\n\n\n\nBelow, we present the text treatments as shares of each campaign’s unique impressions. We see that the text treatments varied as shares of the treatments in each campaign. Some texts were swapped for other texts in later campaigns. But even among campaigns that used the same overall set of texts, there was some dramatic variation E.g., the ‘100x impact’ was favored heavily in the ‘Factual V2’ campaign, while the other ‘Factual’ campaigns used this much less frequently. This presumably resulted from it performing better in the earliest hours of the Factual V2 trial, and Facebook’s algorithm thus favoring it.\n\n\nCode\n(\n  reach_text_campaign <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(campaign_name, text_treat, reach) %>%\n   uncount(weights = .$reach) %>%\n    dplyr::select(-reach) %>%\n tabyl(campaign_name, text_treat) %>%\n    adorn_percentages(\"row\") %>%\n     adorn_totals(where = c(\"col\")) %>%\n    adorn_pct_formatting(digits = 2) %>%\n  .kable(caption = \"Text treatments as shares of unique impressions by campaign\", digits=3) %>%\n  .kable_styling()\n)\n\n\n\nText treatments as shares of unique impressions by campaign\n \n  \n    campaign_name \n    100x impact \n    6000+ people \n    Bigger difference \n    Cause list \n    Learn \n    Only 3% research \n    Overwhelming \n    Total \n  \n \n\n  \n    Cause-led \n    0.00% \n    24.99% \n    27.61% \n    15.45% \n    13.15% \n    0.00% \n    18.79% \n    100.00% \n  \n  \n    Cause-led V3 \n    0.00% \n    23.91% \n    11.08% \n    16.76% \n    15.88% \n    0.00% \n    32.36% \n    100.00% \n  \n  \n    Factual \n    14.05% \n    19.08% \n    21.65% \n    0.00% \n    29.49% \n    15.73% \n    0.00% \n    100.00% \n  \n  \n    Factual V2 \n    28.16% \n    10.41% \n    21.63% \n    0.00% \n    11.88% \n    27.93% \n    0.00% \n    100.00% \n  \n  \n    Factual V3 \n    28.37% \n    21.14% \n    22.14% \n    0.00% \n    16.04% \n    12.31% \n    0.00% \n    100.00% \n  \n  \n    Hypercube Brand Video \n    27.61% \n    14.65% \n    17.55% \n    0.00% \n    16.37% \n    23.82% \n    0.00% \n    100.00% \n  \n  \n    PPCo Creatives \n    26.94% \n    14.95% \n    18.16% \n    0.00% \n    20.34% \n    19.61% \n    0.00% \n    100.00% \n  \n\n\n\n\n\n\n\n\n\n\n1.4.2 Demographics\n\n\nCode\n(\n  reach_age_gender <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(age, gender, reach) %>%\n   uncount(weights = .$reach) %>%\n    dplyr::select(-reach) %>%\n  tabyl(age, gender) %>%\n       adorn_opts() %>% \n  .kable(caption = \"Unique impressions: shares by Age and Gender\", digits=2) %>%\n  .kable_styling()\n)\n\n\n\nUnique impressions: shares by Age and Gender\n \n  \n    age \n    female \n    male \n    unknown \n    Total \n  \n \n\n  \n    13-17 \n    0.03% \n    0.02% \n    0.01% \n    0.05% \n  \n  \n    18-24 \n    13.02% \n    5.78% \n    0.63% \n    19.43% \n  \n  \n    25-34 \n    27.50% \n    9.32% \n    0.68% \n    37.50% \n  \n  \n    35-44 \n    15.71% \n    4.27% \n    0.47% \n    20.45% \n  \n  \n    45-54 \n    5.21% \n    0.95% \n    0.15% \n    6.30% \n  \n  \n    55-64 \n    6.42% \n    1.26% \n    0.16% \n    7.84% \n  \n  \n    65+ \n    6.44% \n    1.78% \n    0.20% \n    8.42% \n  \n  \n    Total \n    74.32% \n    23.39% \n    2.29% \n    100.00% \n  \n\n\n\n\n\nAs can be clearly seen above, within all age groups, the ads were disproportionally shown to women. Relative to the overall Facebook population our data skews very slightly younger.7\n\n\n\n1.4.3 Outcomes: overview\nBelow, we present the dates of each campaign, along with start dates and results:\n\n\n\nCode\nbase_results_sum <- function(df) {\n    df %>%\n     dplyr::summarize(\n  Cost = sum(round(amount_spent_usd,0)),\n      `reach`=sum(reach),\n      `Link clicks`=sum(link_clicks, na.rm = TRUE),\n      Results=sum(results, na.rm = TRUE),\n      `$/ impr.` = round(Cost/reach,3),\n      `$/ click` = round(Cost/ `Link clicks`,1),\n      `$/ result` = round(Cost/Results,1),\n      `Results/ 1k impr.` = round(Results*1000/reach,1)\n)\n     }\n\n(\n  campaign_date_outcomes <-  gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(campaign_name, starts, ends) %>%\n    rename('Campaign' = campaign_name) %>%\n    filter(reach>200) %>%\n    base_results_sum %>%\n    arrange(starts) %>%\n    .kable(caption = \"Results by Campaign and start date\") %>%\n    .kable_styling() %>%\n    add_footnote(\"'False start' campaign dates with less than 200 reach are excluded\")\n)\n\n\n\nResults by Campaign and start date\n \n  \n    Campaign \n    starts \n    ends \n    Cost \n    reach \n    Link clicks \n    Results \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    Cause-led \n    2021-11-30 \n    2021-12-20 \n    4,451 \n    113,399 \n    1,111 \n    407 \n    0.039 \n    4.0 \n    10.9 \n    3.6 \n  \n  \n    Factual \n    2021-11-30 \n    2021-12-08 \n    484 \n    10,752 \n    94 \n    19 \n    0.045 \n    5.1 \n    25.5 \n    1.8 \n  \n  \n    Factual V2 \n    2021-12-08 \n    2021-12-20 \n    3,401 \n    94,168 \n    1,362 \n    417 \n    0.036 \n    2.5 \n    8.2 \n    4.4 \n  \n  \n    Cause-led V3 \n    2021-12-23 \n    2022-01-04 \n    1,422 \n    101,892 \n    408 \n    164 \n    0.014 \n    3.5 \n    8.7 \n    1.6 \n  \n  \n    Factual V3 \n    2021-12-23 \n    2022-01-04 \n    1,415 \n    112,041 \n    496 \n    174 \n    0.013 \n    2.9 \n    8.1 \n    1.6 \n  \n  \n    Hypercube Brand Video \n    2022-01-07 \n    2022-01-17 \n    1,022 \n    51,911 \n    206 \n    65 \n    0.020 \n    5.0 \n    15.7 \n    1.3 \n  \n  \n    PPCo Creatives \n    2022-01-07 \n    2022-01-17 \n    1,027 \n    79,241 \n    327 \n    106 \n    0.013 \n    3.1 \n    9.7 \n    1.3 \n  \n  \n    PPCo Creatives \n    2022-01-07 \n    2022-01-18 \n    366 \n    24,106 \n    96 \n    30 \n    0.015 \n    3.8 \n    12.2 \n    1.2 \n  \n\n\n\na 'False start' campaign dates with less than 200 reach are excluded\n\n\n\n\n\n\n\nThe results vary substantially by campaign, but this could be attributed to a range of factors, including different sets of videos and texts in each campaign, different versions of videos presented on these dates, and changes in audience filters. As these campaigns were administered on different dates, there may also be uncontrolled differences in the population seeing our ads.\n\n\nOutcomes for the most comparable trials and A/B tests\nThe campaigns run on the same dates are the most comparable, and in some cases, were explicitly set up as A/B tests.\n\n\n\n\n\n\nA/B trial setups\n\n\n\n\n\nTest 1 (Nov 30, 2021 – Dec 8, 2021) displayed either the long factual video or a cause focus video. In the cause focus condition, cause-specific audiences for animal rights, climate change, and poverty (based on their behavior on Facebook) were shown the relevant cause video.\n(Note: the ‘Only 3% research’ and ‘100x impact’ messages were not shown )\nTest 2 (Dec 8 - 20, 2021) was the same as Test 1 but used the short factual video instead of the cause-focus videos.\nTest 3 (Dec 23, 2021 - Jan 4, 2022) was the same as Test 2 but had a new version of the videos (with Luke just holding up signs with the words). This test was also restricted to 18-35 year olds.\nTest 4: The brand video was displayed in a separate “brand video” campaign which was tested against another campaign that allowed the algorithm to optimize between the short factual and cause-focus videos (although not allowing each cause-specific audience to see the ads for other cause areas).\n\n\n\nAs noted, some campaigns were set up explicitly as A/B trials. Below, we focus specifically on the comparable groups in each.\n\n\nCode\n(\n  campaign_date_outcomes_comp_1_2 <-  gg_campaign_by_ad_by_text_age_gender %>%\n    filter(starts<= \"2021-12-08\") %>% \n    filter(!str_det(text_treat, \"100x impact|Overwhelming|Only 3% research|Cause list\")) %>%\n    filter(audience == \"Philanthropy\" | audience ==\"Lookalikes\") %>%\n    group_by(video_theme, audience) %>%\n    filter(reach>100) %>%\n    base_results_sum %>%\n     dplyr::select(-Cost, -`Results`, -`Link clicks`) %>%\n    arrange(audience, -`Results/ 1k impr.`) %>% \n    .kable(caption = \"'Comparable' Parts of Tests 1 & 2\") %>%\n    .kable_styling() \n)\n\n\n\n'Comparable' Parts of Tests 1 & 2\n \n  \n    video_theme \n    audience \n    reach \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    Factual short \n    Lookalikes \n    5,415 \n    0.038 \n    2.5 \n    7.4 \n    5.2 \n  \n  \n    Cause-led (any) \n    Lookalikes \n    3,332 \n    0.046 \n    4.6 \n    9.5 \n    4.8 \n  \n  \n    Factual short \n    Philanthropy \n    6,716 \n    0.040 \n    3.1 \n    9.0 \n    4.5 \n  \n  \n    Cause-led (any) \n    Philanthropy \n    42,459 \n    0.041 \n    4.3 \n    12.4 \n    3.3 \n  \n  \n    Factual long \n    Philanthropy \n    3,532 \n    0.054 \n    9.0 \n    31.7 \n    1.7 \n  \n\n\n\n\n\nThe table above is limited to the campaigns starting on or before 2021-12-08: the ‘tests 1 and 2’. It is limited to Philanthropy and Lookalike audiences, the only audiences that saw all videos. It is limited to text (message) treatments that were shown across all these campaigns (“6000+ people”, “Bigger difference”, and “Learn”). Note the extremely poor performance of the ‘Factual long’ message. The Factual short message slightly outperformed the Cause-led messages overall.8 The Lookalike audience somewhat overperformed the Philanthropy audience, particularly with the cause-led videos.\nNext we consider “Test 3”, starting on 2021-12-23. As noted, this had a new version of the videos, and new age restrictions\n\n\nCode\n(\n  campaign_date_outcomes_comp_3 <-  gg_campaign_by_ad_by_text_age_gender %>%\n    filter(starts== \"2021-12-23\") %>% \n    filter(!str_det(text_treat, \"100x impact|Overwhelming|Only 3% research|Cause list\")) %>%\n    filter(audience == \"Philanthropy\" | audience ==\"Lookalikes\") %>%\n    group_by(video_theme, audience) %>%\n    filter(reach>100) %>%\n    base_results_sum %>%\n     dplyr::select(-Cost, -`Results`, -`Link clicks`) %>%\n    arrange(audience, -`Results/ 1k impr.`) %>% \n    .kable(caption = \"'Comparable' Parts of Tests 3\") %>%\n    .kable_styling() \n)\n\n\n\n'Comparable' Parts of Tests 3\n \n  \n    video_theme \n    audience \n    reach \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    Cause-led (any) \n    Lookalikes \n    5,758 \n    0.018 \n    2.5 \n    10.5 \n    1.7 \n  \n  \n    Factual short \n    Lookalikes \n    8,609 \n    0.016 \n    3.9 \n    9.3 \n    1.7 \n  \n  \n    Cause-led (any) \n    Philanthropy \n    28,074 \n    0.013 \n    4.2 \n    9.4 \n    1.4 \n  \n  \n    Factual short \n    Philanthropy \n    13,832 \n    0.012 \n    3.4 \n    10.8 \n    1.1 \n  \n\n\n\n\n\nThis has the same filters as the previous table: only Philanthropy and Lookalike audiences9 and only those text treatments shown to all. Here both audiences, and both sets of messages perform roughtly the same on a results-per-cost basis.\n\nFocus: Test 4, videos and audiences\nFinally, we focus on test 4, which incorporates the branded video. Here all text treatments could be paired with each of the videos, and each were given to each audience. Thus, we can ‘include a lot’ and this table is large (thus the ‘datatables’ format).10\n\n\nCode\ncampaign_date_outcomes_comp_4_vid <-  gg_video_breakdowns %>%\n    filter(starts== \"2022-01-07\") %>% \n    group_by(video_theme, audience) %>%\n    filter(audience!=\"Retargeting\") %>%\n    base_results_sum %>%\n     dplyr::select(-Cost, -`Results`, -`Link clicks`) %>%\n    arrange(audience, `$/ result`) %>% \n    dplyr::select(audience, everything())\n\ncampaign_date_outcomes_comp_4_vid %>% \n        DT::datatable(caption = \"Tests 4 (roughly comparable); blank cells indicate NA/no results\") \n\n\n\n\n\n\n\n\nWithin each audience11\nFor the Philanthropy audience, the Climate and Poverty videos and the Factual Short videos did about equally well – about 8-9 USD per result. The Branded video did slightly worse. The Animal video which performed very poorly on this audience!\nFor the General audience, the Climate video did best, achieving a result at close to 6 dollars. The Animal and Factual videos did somewhat worse, and the Poverty and Brand videos did substantially worse on a results per cost basis.\nFactual short versus Branded videos\nThe cost per result for the Factual Short video was fairly constant across audiences (except the Lookalikes, who performed veyr poorly with this video). The Branded video performed so/so on the Lookalikes and Philanthropy audiences, but extremely poorly on the General and cause audiences.\nCause videos:\n\nAnimals: did approximately equally well (about 2 results per 1k impressions and 9-11 dollars per result) on all audiences except the Philanthropy audience.\nClimate: Surprisingly poor performance for the climate audience (but performed well with theGeneral audience, and OK with the Philanthropy and Lookalike audiences\nPoverty: This video apparently had poor performance overall, leading FB’s algorithm to largely drop it. It seems to have not appealed to any audience except the Philanthropy audience, where it did marginally OK.\n\nSorting by ‘$/results overall’\nThe best audience-video combinations were:\n\n\nCode\ncampaign_date_outcomes_comp_4_vid %>% filter(`$/ result`<=9.1) %>% dplyr::select(audience, video_theme, `$/ result`) %>%  .kable() %>% .kable_styling()\n\n\n\n \n  \n    audience \n    video_theme \n    $/ result \n  \n \n\n  \n    General audience \n    Climate \n    6.2 \n  \n  \n    Global Poverty \n    Factual short \n    7.8 \n  \n  \n    Lookalikes \n    Climate \n    9.0 \n  \n  \n    Philanthropy \n    Climate \n    8.4 \n  \n  \n    Philanthropy \n    Poverty \n    9.0 \n  \n\n\n\n\n\n… each of which cost at or below 9 dollars per result\nThe worst audience-video combinations were:\n\n\nCode\ncampaign_date_outcomes_comp_4_vid %>% filter(`$/ result`>20 |  is.na(`$/ result`) ) %>% dplyr::select(audience, video_theme, `$/ result`) %>%  .kable() %>% .kable_styling()\n\n\n\n \n  \n    audience \n    video_theme \n    $/ result \n  \n \n\n  \n    Animal \n    Hypercube (factual) \n    24.8 \n  \n  \n    Climate \n    Hypercube (factual) \n    20.7 \n  \n  \n    Global Poverty \n    Hypercube (factual) \n    23.3 \n  \n  \n    Global Poverty \n    Poverty \n    Inf \n  \n  \n    Lookalikes \n    Poverty \n    Inf \n  \n  \n    Lookalikes \n    Factual short \n    Inf \n  \n  \n    Philanthropy \n    Animal \n    36.5 \n  \n\n\n\n\n\n… each of which cost over 20 dollars per result (or had no results, suggesting even higher costs).\nComparing audiences in Test 4\n\n\n\nHere the General and Philanthropy audiences performed about equally well, while the cause audiences performed somewhat worse, particularly the Poverty audience.\n\n\nCode\ncampaign_date_outcomes_comp_4_aud <-  gg_video_breakdowns %>%\n    filter(starts== \"2022-01-07\") %>% \n      group_by(audience) %>%\n    filter(audience!=\"Retargeting\") %>%\n    base_results_sum %>%\n    mutate(`Video type` = \"All\") %>% \n     dplyr::select(-Cost, -`Results`, -`Link clicks`) %>%\n     dplyr::select(audience, `Video type`, everything()) %>% \n      arrange(`Video type`, `$/ result`)\n\n\n\ncampaign_date_outcomes_comp_4_aud_vt <-  gg_video_breakdowns %>%\n    mutate(`Video type` = if_else(str_det(video_theme, \"Factual|factual\"), \"Non-cause\", \"Cause\")) %>% \n    filter(starts== \"2022-01-07\") %>% \n      group_by(`Video type`, audience) %>%\n    filter(audience!=\"Retargeting\") %>%\n    base_results_sum %>%\n     dplyr::select(-Cost, -`Results`, -`Link clicks`) %>%\n    arrange(`Video type`, `$/ result`) %>% \n    dplyr::select(audience, everything())\n\ncampaign_date_outcomes_comp_4_aud_vt_all <- bind_rows(campaign_date_outcomes_comp_4_aud, campaign_date_outcomes_comp_4_aud_vt)\n\ncampaign_date_outcomes_comp_4_aud_vt_all %>% \n        DT::datatable(caption = \"Tests 4 by audience and video type\") \n\n\n\n\n\n\n\n\nFocus: Test 4, Texts and audiences\n\n\nCode\ncampaign_date_outcomes_comp_4_text_pool <-  gg_campaign_by_ad_by_text_age_gender %>%\n    filter(starts== \"2022-01-07\") %>% \n    group_by(text_treat) %>%\n    filter(audience!=\"Retargeting\") %>%\n    base_results_sum %>%\n     dplyr::select(-Cost, -`Results`, -`Link clicks`) %>%\n    arrange(`$/ result`) \n\ncampaign_date_outcomes_comp_4_text_pool %>% \n        DT::datatable(caption = \"Tests 4: Performance by text; blank cells indicate NA/no results\") \n\n\n\n\n\n\nCode\nworst_to_best <- campaign_date_outcomes_comp_4_text_pool[[5,5]]/campaign_date_outcomes_comp_4_text_pool[[1,5]]\n\n\nAbove, pooling across all audiences (except Retargeting) and weighted towards ‘those people in each audience who got each message’, we see the “Only 3% research” message performed best per dollar, closely followed by the “100x impact” and “Bigger difference” messages. “Learn” did substantially worse, and “6000+ people” the worst, costing 1.84 times as much as the best message.\nNext, we considering these messages by audience, for this trial.\n\n\nCode\ncampaign_date_outcomes_comp_4_text <-  gg_campaign_by_ad_by_text_age_gender %>%\n    filter(starts== \"2022-01-07\") %>% \n    group_by(text_treat, audience) %>%\n    filter(audience!=\"Retargeting\") %>%\n    base_results_sum %>%\n     dplyr::select(-Cost, -`Results`, -`Link clicks`) %>%\n    arrange(audience, `$/ result`) %>% \n    dplyr::select(audience, everything())\n\ncampaign_date_outcomes_comp_4_text %>% \n        DT::datatable(caption = \"Tests 4: Performance by audience and text; blank cells indicate NA/no results\") \n\n\n\n\n\n\nSome messages show strong heterogeneity across audiences, while others are fairly consistent. The “Only 3%” message does well on the Animal and Philanthropy audiences, OK on the General audience, but does very poorly on the other audiences. The second best overall message, “100x impact” does so/so on all audiences. “Learn” shows some variation, doing pretty well on Poverty and Lookalike audiences, OK on Animal audiences, but poorly on the General, Philanthropy and Climate audiences. The “6000+ people” and “Bigger Difference” messages perform poorly on nearly all audiences, doing at best-OK on a few audiences\n\n\nOther ‘outcome by group’ comparisons across several trials\nNext, we show the results by age and gender. As our age filters changed over time, we do this first for the earlier trials, when all age groups were included.\n\n\nCode\n(\n  age_outcomes_pre_12_09 <- gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(age) %>%\n        filter(reach>500, starts<= \"2021-12-08\") %>%\n    base_results_sum() %>%\n    .kable(caption = \"Results by Age: Campaigns starting on or before Dec 8 2021\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Age: Campaigns starting on or before Dec 8 2021\n \n  \n    age \n    Cost \n    reach \n    Link clicks \n    Results \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    18-24 \n    275 \n    14,690 \n    48 \n    20 \n    0.019 \n    5.7 \n    13.8 \n    1.4 \n  \n  \n    25-34 \n    585 \n    26,970 \n    162 \n    75 \n    0.022 \n    3.6 \n    7.8 \n    2.8 \n  \n  \n    35-44 \n    625 \n    22,876 \n    156 \n    64 \n    0.027 \n    4.0 \n    9.8 \n    2.8 \n  \n  \n    45-54 \n    970 \n    25,525 \n    246 \n    98 \n    0.038 \n    3.9 \n    9.9 \n    3.8 \n  \n  \n    55-64 \n    1,625 \n    36,157 \n    475 \n    150 \n    0.045 \n    3.4 \n    10.8 \n    4.1 \n  \n  \n    65+ \n    2,758 \n    43,547 \n    1,097 \n    319 \n    0.063 \n    2.5 \n    8.6 \n    7.3 \n  \n\n\n\n\n\nWhile 12 older age groups yield more results per impression, they are also more expensive. This approximately balances out, although the age 18-24 group is particularly costly per result!\nIn later trials we only targeted the younger age groups; the cost per results were similar to earlier trials , and fairly close among the younger age groups (see fold).\n\n\n\n\n\n\nBy age, later trials\n\n\n\n\n\n\n\nCode\n(\n  age_outcomes_post_12_09 <- gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(age) %>%\n        filter(reach>500, starts > \"2021-12-08\") %>%\n    base_results_sum() %>%\n    .kable(caption = \"Results by Age: Campaigns starting on or after Dec 23 2021\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Age: Campaigns starting on or after Dec 23 2021\n \n  \n    age \n    Cost \n    reach \n    Link clicks \n    Results \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    18-24 \n    802 \n    67,114 \n    221 \n    87 \n    0.012 \n    3.6 \n    9.2 \n    1.3 \n  \n  \n    25-34 \n    2,505 \n    175,595 \n    754 \n    270 \n    0.014 \n    3.3 \n    9.3 \n    1.5 \n  \n  \n    35-44 \n    1,016 \n    63,882 \n    315 \n    108 \n    0.016 \n    3.2 \n    9.4 \n    1.7 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote on change in table style\n\n\n\n\n\nThe tables above make it clear how the relevant ‘per dollar’ and ’per unique impression results are calculated. In the following tables we present slightly fewer columns, for readability.\n\n\n\nWomen gave their emails at a somewhat higher rate overall, but their (unique) impressions were a bit more costly. Thus cost per result roughly balanced out. Nonetheless, this might be somewhat informative for other contexts; women might be a particularly promising audience, all else equal.\n\n\nCode\n(\n  gender_outcomes <- gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(gender) %>%\n    base_results_sum() %>%\n dplyr::select(-Cost, -`Results`, -`Link clicks`) %>%\n    .kable(caption = \"Results by Gender\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Gender\n \n  \n    gender \n    reach \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    female \n    506,889 \n    0.025 \n    3.4 \n    10.1 \n    2.5 \n  \n  \n    male \n    159,525 \n    0.018 \n    3.5 \n    10.2 \n    1.8 \n  \n  \n    unknown \n    15,642 \n    0.015 \n    2.1 \n    7.1 \n    2.2 \n  \n\n\n\n\n\nNext we describe the outcomes by our video treatments, focusing on the philanthropy-interested audience only, for comparability.\n\n\nCode\nvideo_outcomes_phil_0 <- gg_video_breakdowns %>%\n    filter(audience==\"Philanthropy\") %>%\n    group_by(video_theme) %>%\n    base_results_sum() \n\n(\nvideo_outcomes_phil <- video_outcomes_phil_0 %>% \n     dplyr::select(-Cost, -`Results`, -`Link clicks`) %>%\n    arrange(video_theme) %>%\n    .kable(caption = \"Results by Video theme for 'Philanthropy' audience\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Video theme for 'Philanthropy' audience\n \n  \n    video_theme \n    reach \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    Animal \n    63,347 \n    0.036 \n    4.4 \n    13.5 \n    2.7 \n  \n  \n    Climate \n    11,854 \n    0.023 \n    2.8 \n    7.0 \n    3.2 \n  \n  \n    Poverty \n    58,548 \n    0.018 \n    3.5 \n    9.8 \n    1.8 \n  \n  \n    Factual short \n    51,761 \n    0.024 \n    3.0 \n    9.3 \n    2.6 \n  \n  \n    Factual long \n    5,561 \n    0.055 \n    6.8 \n    27.8 \n    2.0 \n  \n  \n    Hypercube (factual) \n    11,902 \n    0.024 \n    4.3 \n    11.6 \n    2.1 \n  \n\n\n\n\n\nCode\nbot_table <- function(df,  outvar, outcol) {\n  df %>% \n    dplyr::arrange({{outvar}}) %>%\n    dplyr::select({{outcol}}) %>% \n    mutate_if(is.factor, as.character) %>%\n    .[[1,1]] \n  } \n\ntop_table <- function(df, outcol, outvar) {\n  df %>%\n    dplyr::arrange(-{{outvar}}) %>%\n    dplyr::select({{outcol}}) %>%\n    mutate_if(is.factor, as.character) %>%\n    .[[1,1]]\n}\n\n\n# { ov <- {{outvar}}\n# ifelse(reverse,\n#          dplyr::arrange(ov),\n#    dplyr::arrange(-ov)\n#   )} %>% \n\n#   \n#   dplyr::arrange({{outvar}}),\n #         dplyr::arrange(-{{outvar}}))} %>% \n\ntop_vid_phil <- video_outcomes_phil_0 %>% bot_table( outvar=`$/ result`, outcol=video_theme)\nbot_vid_phil <- video_outcomes_phil_0 %>% top_table( outvar=`$/ result`, outcol=video_theme)\n\n\nThe Climate video performed particularly well on the philanthropy-interested audience filter, while “Factual long” performed the worst.13\nNext, we compare the text treatments for the later campaigns only. The earlier and later campaigns had a slightly different set of texts; combining across these indeed risks confounding multiple dimensions.\n\n\nCode\noutcomes_by_text <- gg_campaign_by_ad_by_text_age_gender %>%\n    filter(str_det(campaign_name, \"factual|hyper\")) %>%\n    group_by(text_treat) %>%\n    base_results_sum() \n\noutcomes_by_text %>%   \n   dplyr::select(-Cost, -`Results`, -`Link clicks`) %>%\n    .kable(caption = \"Results by text; later campaigns\") %>%\n    .kable_styling()\n\n\n\nResults by text; later campaigns\n \n  \n    text_treat \n    reach \n    $/ impr. \n    $/ click \n    $/ result \n    Results/ 1k impr. \n  \n \n\n  \n    100x impact \n    87,369 \n    0.025 \n    3.1 \n    9.6 \n    2.6 \n  \n  \n    6000+ people \n    52,165 \n    0.021 \n    3.9 \n    14.7 \n    1.4 \n  \n  \n    Bigger difference \n    68,308 \n    0.023 \n    3.5 \n    10.1 \n    2.3 \n  \n  \n    Learn \n    51,860 \n    0.024 \n    3.8 \n    13.6 \n    1.8 \n  \n  \n    Only 3% research \n    65,786 \n    0.026 \n    2.3 \n    7.0 \n    3.7 \n  \n\n\n\n\n\nCode\ntop_text_later <- outcomes_by_text %>% bot_table( outvar=`$/ result`, outcol=text_treat)\nbot_text_later <- outcomes_by_text %>% top_table( outvar=`$/ result`, outcol=text_treat)\n\n\nThe “Only 3% research” message performed particularly well on a cost-per-result basis, while 6000+ people performed the worst\nWe next consider results by audience, focusing on the non-cause treatments and cause treatments separately for comparability.\n\n\n\nCode\naudience_outcomes_all <- gg_video_breakdowns %>%\n         filter(audience!=\"Retargeting\" & audience!=\"General audience\")  %>% #latter filter because they were only in the final trial\n  mutate(`Video type` = \"All\") %>% \n    group_by(`Video type`, audience) %>%\n    base_results_sum %>%\n   dplyr::select(-Cost, -`Results`, -`Link clicks`) %>%\n    arrange(`Video type`, `$/ result`)\n\naudience_outcomes_vt <- gg_video_breakdowns %>%\n         filter(audience!=\"Retargeting\" & audience!=\"General audience\")  %>% #latter filter because they were only in the final trial\n  mutate(`Video type` = if_else(str_det(video_theme, \"Factual|factual\"), \"Non-cause\", \"Cause\")) %>% \n    group_by(`Video type`, audience) %>%\n    base_results_sum %>%\n   dplyr::select(-Cost, -`Results`, -`Link clicks`) %>%\n    arrange(`Video type`, `$/ result`)\n\n\naudience_outcomes_vt_all <- bind_rows(audience_outcomes_all, audience_outcomes_vt)\n\n\naudience_outcomes_vt_all %>%\n    DT::datatable(caption = \"Results by audience; cause vs non-cause (and overall\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant caveat: bias from divergent delivery here\n\n\n\n\n\nThe above table is somewhat misleading because of the divergent delivery issue. Here, the Global Poverty audience seemed to have done well with videos targeting their oewn cause. However, in each campaign Facebook serves videos less to audiences when they perform poorly on these videos. And in the most comparable (4th) campaign, this combination did so poorly that FB seems to have not administered it much, which makes it not count towards the overall total!\n\n\n\n\n\n\n\n\n\nFormat note\n\n\n\n\n\nThe table above is presented with the Datatables package/function. This allows sorting, filtering, etc. We can present more tables in this format if it is preferable."
  },
  {
    "objectID": "chapters/gwwc_gg.html#implementation-treatment-assignment-key-details",
    "href": "chapters/gwwc_gg.html#implementation-treatment-assignment-key-details",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.2 Implementation & treatment assignment: key details",
    "text": "1.2 Implementation & treatment assignment: key details\n\n\n\n\n\n\nTreatment assignment order, dates\n\n\n\n\n\nThe treatment assignment was determined by Facebook’s algorithm. Video content was manipulated across three split tests.\nTest 1 (Nov 30, 2021 – Dec 8, 2021, campaigns: “Cause-Led” and “Factual”) displayed either the long factual video or a cause focus video. In the cause focus condition, cause-specific audiences for animal rights, climate change, and poverty (based on their behavior on Facebook) were shown the relevant cause video.\nTest 2 (Starting December 8, campaign “Factual V2”?) was the same as Test 1 but used the short factual video instead of the cause-focus videos.\nTest 3 (Starting December 23, campaign “Cause-led V3” and “Factual V3” (?)): was the same as Test 2 but had a new version of the videos (with Luke just holding up signs with the words). This test was also restricted to 18-35 (or 18-44) year olds.1\nTest 4: (Starting December 23, “Brand Video” and “PPCo”) The Brand Video was displayed in a separate campaign which was tested against another campaign that allowed the algorithm to optimize between the ‘short factual’ and ‘cause focus’ videos (although not allowing each cause-specific audience to see the ads for other cause areas).\nIn all tests, the text content displayed above the video was determined by Facebook’s algorithm. Balance across variations was determined to equate budgets across split tests; otherwise, according to Facebook’s algorithm. All variation was done at the level of the impression.\nThe videos were adapted across the trials as we learned. First, we updated the factual video to be shorter for Trial 2, and then we tried videos of Luke holding up signs spelling out the voiceover in Trial 3 for all videos."
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html",
    "href": "chapters/testformat_gwwc_gg.html",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "",
    "text": "Note\n\n\n\nThis chapter should align with a (forthcoming) EA Forum post, which will be linked here (and vice-versa)."
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#the-trial",
    "href": "chapters/testformat_gwwc_gg.html#the-trial",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.1 The trial",
    "text": "2.1 The trial\nSee full description in the gitbook here.\nContext: Facebook advertisements on a range of audiences\n\nEffective Giving Guide Lead Generation campaign … ran late November 2021 - January 2022. The objective of this campaign was to see whether a factual [‘who researches giving’ or ‘magnitude of impact differences’] or cause-led approach was more cost-effective at getting people to fill out a form and give us their email in order to download our Effective Giving Guide.\n\n\n2.1.1 Treatments (text \\(\\times\\) video)\nThere were two dimensions of treatment content:\n\nThe texts displayed above the videos\n\n\n\n\n\n\n\nTexts\n\n\n\n\n\nBigger difference next year: Want to make a bigger difference next year? Start with our Effective Giving Guide and learn how to make a remarkable impact just by carefully choosing the charities you give to.\n100x impact: Did you know that the best charities can have a 100x greater impact? Download our free Effective Giving Guide for the best tips on doing the most good this holiday season.\n6000 people: Giving What We Can has helped 6,000+ people make a bigger impact on the causes they care about most. Download our free guide and learn how you can do the same.\nCause list: Whether we’re moved by animal welfare, the climate crisis, or worldwide humanitarian efforts, our community is united by one thing: making the biggest impact we can. Make a bigger difference in the world through charitable giving. Start by downloading our Effective Giving Guide. You’ll learn how to approach charity research and smart giving. And be sure to share it with others who care about making a greater impact on the causes closest to their hearts.\nLearn: Use our free guide to learn how to make a bigger impact on the causes you care about most.\nOnly 3% research: Only 3% of donors give based on charity effectiveness yet the best charities can be 100x more impactful. That’s incredible! Check out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes.\nOverwhelming: It can be overwhelming with so many problems in the world. Fortunately, we can do a lot to help, if we give effectively. Check out the Effective Giving Guide 2021. It’ll help you find the most impactful charities across a range of causes.\n\n\n\n\n\n\n\n\n\nArguments, rich content from “Hypercube”\n\n\n\n\n\n\nHypercube (1 min 22 seconds): Animated and voiceover video that explains how GWWC can help maximize charitable impact (support, community, and information) and the problems GWWC addresses (good intentions don’t always produce the desired outcomes, there are millions of charities that have varying degrees of impact and some can even cause harm). CTA: Check out givingwhatwecan.org to learn how you can become an effective giver.\n\n\n\n\n\n\nFurther detail, links\n\n\n\n\n\n\nNotes from the trial description\n\n\n\n\n\n“In the original version of our test, we had 1 video for the factual appeal and 3 videos for the cause led approach - 1 for global health and development, 1 for animal welfare and 1 for climate change.”\n“We targeted our ads to audiences we thought were likely to engage based on their interests and demographics, and targeted the cause led videos to a relevant audience, i.e. climate change message to climate change audience.”\n“We also had various text above the videos that were displayed and optimized.”\n\n\n\nDetails in Gitbook HERE (and embedded below) and Gdoc here\n\n\nCode\nknitr::include_url(\"https://effective-giving-marketing.gitbook.io/untitled/partner-organizations-and-trials/gwwc/giving-guides-+\")"
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#implementation-treatment-assignment-key-details",
    "href": "chapters/testformat_gwwc_gg.html#implementation-treatment-assignment-key-details",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.2 Implementation & treatment assignment: key details",
    "text": "2.2 Implementation & treatment assignment: key details\n\n\n\n\n\n\nTreatment assignment order, dates\n\n\n\n\n\nThe treatment assignment was determined by Facebook’s algorithm. Video content was manipulated across three split tests.\nTest 1 (Nov 30, 2021 – Dec 8, 2021, campaigns: “Cause-Led” and “Factual”) displayed either the long factual video or a cause focus video. In the cause focus condition, cause-specific audiences for animal rights, climate change, and poverty (based on their behavior on Facebook) were shown the relevant cause video.\nTest 2 (add dates) was the same as Test 1 but used the short factual video instead of the cause-focus videos.\nTest 3 (add dates) was the same as Test 2 but had a new version of the videos (with Luke just holding up signs with the words). This test was also restricted to 18-35 year olds.\nTest 4: The Hypercube video was displayed in a separate “Hypercube” campaign which was tested against another campaign that allowed the algorithm to optimize between the ‘short factual’ and ‘cause focus’ videos (although not allowing each cause-specific audience to see the ads for other cause areas).\nIn all tests, the text content displayed above the video was determined by Facebook’s algorithm. Balance across variations was determined to equate budgets across split tests; otherwise, according to Facebook’s algorithm. All variation was done at the level of the impression.\nThe videos were adapted across the trials as we learned. First, we updated the factual video to be shorter for Trial 2, and then we tried videos of Luke holding up signs spelling out the voiceover in Trial 3 for all videos."
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#build-source-data-input-and-cleaning-code",
    "href": "chapters/testformat_gwwc_gg.html#build-source-data-input-and-cleaning-code",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.3 Build: Source data input and cleaning code",
    "text": "2.3 Build: Source data input and cleaning code\n\n\n\n\n\n\nAccessing, downloading, inputting data\n\n\n\n\n\nSee:\nAccessing and bringing down simple results HERE; (Public access version here)\n\n\n\n\n\n\n\n\n\n\nData structure\n\n\n\n\n\n\ntext: Which text was shown along with the video\nage (a range of ages)\ngender (female, male, unknown)\n\n\n\n\n\n\nCode\nraw_data_path <- list(\"gwwc\", \"gg_raw_data_shareable\")\n\n#already input above: gg_campaign_by_ad_by_text\n\n#Version allowing demographic breakdown:\ngg_campaign_by_ad_by_text_age_gender <- read_csv(here(raw_data_path, \"gg-campaign-by-ad-set-text-age-gender.csv\"), show_col_types=FALSE) %>%\n  #dplyr::select(-\"Campaign name...4\") %>% #duplicate columns?\n mini_clean()\n\n#Version with information on cause videos shown (even to those in 'general' groups):\n\ngg_video_breakdowns <- read_csv(here(raw_data_path, \"gg-image-video-breakdowns.csv\"), show_col_types=FALSE)\n\n#capture and remove columns that are the same everywhere\nattribution_setting_c <- gg_campaign_by_ad_by_text_age_gender$attribution_setting %>% .[1]\nreporting_starts_c <- gg_campaign_by_ad_by_text_age_gender$reporting_starts %>% .[1]\nreporting_ends_c <- gg_campaign_by_ad_by_text_age_gender$reporting_ends %>% .[1]\n\n\ngg_campaign_by_ad_by_text_age_gender  %<>% mini_clean()\ngg_video_breakdowns  %<>% mini_clean()\n\n#functions to clean these specific data sets 'gg_campaign_by_ad_by_text_age_gender' and 'gg_campaign_by_ad_by_text':\nsource(here(\"gwwc\", \"giving_guides\", \"clean_gg_raw_data.R\")) \n\n#Many cleaning steps: audience, video_theme, campaign_theme, agetrin; releveling\ngg_campaign_by_ad_by_text_age_gender %<>%\n  rename_gg() %>%\ngg_make_cols() %>% \n  vid_clean() %>%  # Video rename and stuff\n  text_clean() %>%  # Shorter 'text treatment' column\n  relevel_gwwc_gg_raw() %>% \n  dplyr::select(campaign_name, everything(), -campaign_name_1, -campaign_name_7) #campaign_name_7 was the same as campaign_name_1\n\ngg_video_breakdowns %<>%\n  rename_gg() %>%\ngg_make_cols()  %>% \n    vid_clean()  # Video rename and stuff\n\n\n#gg_campaign_by_ad_by_text_age_gender %>% collapse::descr()\n\n\n\n\nCode\ngg_video_breakdowns %<>%\n  mutate(\n    video_theme = case_when(\n      str_det(image_video_and_slideshow, \"set_1|Animals\") ~ \"Animal\",\n      str_det(image_video_and_slideshow, \"set_2|Climate\") ~ \"Climate\",\n      str_det(image_video_and_slideshow, \"set_3|Poverty|Free Effective\") ~ \"Poverty\",\n      str_det(image_video_and_slideshow, \"factual\") ~ \"Factual\",\n      TRUE ~ video_theme\n    ),\n    video_theme =  factor(video_theme), \n    video_theme = fct_relevel(video_theme, c(\"Animal\", \"Climate\", \"Poverty\", \"Factual\", \"Factual or optimized mix\")) \n  )\n\n\n\n\n\n\n\n\nThis data should be publicly shareable.\n\n\n\n\n\nThis data is clearly not identifying individuals; it involves aggregates based on real or assumed characteristics … there is likely nothing that needs to be hidden here. We aim to share and integrate all the data in this repo, for a complete pipeline.\n\n\n\n\n\n\n\n\n\nPrevious version of data used … (updating)\n\n\n\n\n\nWe previously used data collapsed (breakdowns) by demography and ad set, into 2 files, which duplicated rows to represent the number of impressions: video breakdown, and text breakdown.csv. We now use the more ‘raw’ minimal version of the data, avoiding duplicating rows where possible.\nBelow, we also input the ‘old version’ of the data, with the duplicated rows, to accommodate the old-format of analysis. The code above inputs and builds 2-4 related data frames (tibbles), which were constructed from the collapsed (aggregated) data by multiplying rows according to observation counts. I am not sure where this was done. Once we update the rest we will get rid of this.\ngwwc_text_clicks: Observations of link clicks … by texts above video gwwc_vid_clicks: … by video content\n(We focus on the email results because we expect the ‘clicks’ are less meaningful.)\ngwwc_text_results: Observations of emails provided … by texts above video gwwc_vid_results: … by video content\nThe files:\ntextdata_dv_linkclicks.csv, videodata_dv_results.csv, textdata_dv_results.csv , and videodata_dv_linkclicks.csv\nare gitignored because of size."
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#descriptives",
    "href": "chapters/testformat_gwwc_gg.html#descriptives",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.4 Descriptives",
    "text": "2.4 Descriptives\n\n2.4.1 Implemented treatments, impressions\nFirst we illustrate ‘where, when, and to whom’ the different campaigns and treatments were shown (Facebook ‘impressions’).\nThe sequential campaigns involved different sets of videos, and these videos had different versions:\n\n\nCode\n(\n  impressions_campaign_theme <- gg_video_breakdowns %>%\n  dplyr::select(campaign_name, video_theme, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n   tabyl(campaign_name, video_theme) %>%\n    dplyr::select(campaign_name, Animal, Climate, Poverty, everything()) %>% \n  .kable(caption = \"Campaign names and video themes: Impressions\") %>%\n  .kable_styling()\n)\n\n\n\nCampaign names and video themes: Impressions\n \n  \n    campaign_name \n    Animal \n    Climate \n    Poverty \n    Factual \n    Factual or optimized mix \n  \n \n\n  \n    Giving Guide 2021 - Cause-led \n    106,870 \n    6,494 \n    36,306 \n    0 \n    0 \n  \n  \n    Giving Guide 2021 – Cause-led V3 \n    45,856 \n    4,478 \n    74,714 \n    0 \n    0 \n  \n  \n    Giving Guide 2021 – Factual \n    0 \n    0 \n    0 \n    32,818 \n    0 \n  \n  \n    Giving Guide 2021 – Factual V2 \n    0 \n    0 \n    0 \n    120,530 \n    0 \n  \n  \n    Giving Guide 2021 – Factual V3 \n    0 \n    0 \n    0 \n    137,679 \n    0 \n  \n  \n    Giving Guide 2021 – Hypercube Brand Video \n    0 \n    0 \n    1,571 \n    0 \n    74,219 \n  \n  \n    Giving Guide 2021 – PPCo Creatives \n    27,595 \n    27,735 \n    2,629 \n    70,619 \n    0 \n  \n\n\n\n\n\nSome audiences were profiled as associated with a certain cause (through their Facebook interests or activities): in ‘cause-focused’ campaigns they were shown videos for their profiled cause. In campaigns that were not cause-focused, they were shown general interest videos. However, those associated with one cause were never shown videos for other causes.\nAudience not åssociated with a cause included the ‘General’ audience, the Philanthropy (interested in charity) audience, a GWWC ‘Lookalike’ audience, and a Retargeted (?) audience: these were shown either the more general-interest videos or particular cause videos. Unfortunately, for these groups, when they were shown a cause-related video, we have not been able to extract the data on which cause-specific video they saw. This is illustrated in the table below.\n\nOutset content…\n\n\nCode\nvideo_levels <- c(\"Animal\", \"Climate\", \"Poverty\", \"Cause-led (any)\", \"Factual\", \"Factual or optimized mix\", \"Total\")\n  \n(\nimpressions_video_audience <- gg_video_breakdowns %>%\n    dplyr::select(video_theme, audience, impressions) %>%\n    uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n    tabyl(video_theme, audience) %>% \n    adorn_percentages(\"all\") %>%\n    adorn_totals(where = c(\"row\", \"col\")) %>% \n    adorn_pct_formatting(digits = 2) %>% \n    dplyr::select(video_theme, Animal, Climate, `Global Poverty`, `Philanthropy`, everything()) %>% \n   mutate(video_theme =  factor(video_theme, levels = video_levels)) %>%\n  arrange(video_theme)  %>% \n    .kable(caption = \"Video themes by audience: share of impressions\", digits=3) %>%\n  .kable_styling()\n)\n\n\n\nVideo themes by audience: share of impressions\n \n  \n    video_theme \n    Animal \n    Climate \n    Global Poverty \n    Philanthropy \n    General audience \n    Lookalikes \n    Retargeting \n    Total \n  \n \n\n  \n    Animal \n    10.47% \n    0.00% \n    0.00% \n    10.33% \n    1.37% \n    1.23% \n    0.02% \n    23.41% \n  \n  \n    Climate \n    0.00% \n    1.83% \n    0.00% \n    1.80% \n    0.97% \n    0.43% \n    0.01% \n    5.03% \n  \n  \n    Poverty \n    0.01% \n    0.05% \n    2.88% \n    9.36% \n    0.22% \n    2.43% \n    0.01% \n    14.96% \n  \n  \n    Factual \n    12.93% \n    13.71% \n    5.12% \n    8.65% \n    2.02% \n    4.52% \n    0.02% \n    46.96% \n  \n  \n    Factual or optimized mix \n    0.90% \n    2.57% \n    1.01% \n    2.18% \n    2.83% \n    0.15% \n    0.01% \n    9.64% \n  \n  \n    Total \n    24.31% \n    18.16% \n    9.01% \n    32.31% \n    7.40% \n    8.75% \n    0.06% \n    100.00% \n  \n\n\n\n\n\n\nThe second treatment dimension – text presented along with the video – was allowed to vary independently of the video:\n\n\nCode\n(\n  impressions_video_text <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(video_theme, text_treat, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n   table %>%\n        prop.table() %>% \n        addmargins() %>% \n  .kable(caption = \"Video themes by text treatment: Impressions\", digits=3) %>%\n  .kable_styling()\n)\n\n\n\nVideo themes by text treatment: Impressions\n \n  \n      \n    100x impact \n    6000+ people \n    Bigger difference \n    Cause list \n    Learn \n    Only 3% research \n    Overwhelming \n    Sum \n  \n \n\n  \n    Animal \n    0.000 \n    0.022 \n    0.037 \n    0.011 \n    0.012 \n    0.000 \n    0.012 \n    0.094 \n  \n  \n    Cause-led (any) \n    0.046 \n    0.087 \n    0.057 \n    0.034 \n    0.066 \n    0.033 \n    0.075 \n    0.398 \n  \n  \n    Climate \n    0.000 \n    0.000 \n    0.000 \n    0.000 \n    0.001 \n    0.000 \n    0.000 \n    0.003 \n  \n  \n    Factual \n    0.105 \n    0.060 \n    0.084 \n    0.000 \n    0.058 \n    0.071 \n    0.000 \n    0.378 \n  \n  \n    Factual or optimized mix \n    0.029 \n    0.014 \n    0.017 \n    0.000 \n    0.015 \n    0.024 \n    0.000 \n    0.098 \n  \n  \n    Poverty \n    0.000 \n    0.004 \n    0.008 \n    0.010 \n    0.003 \n    0.000 \n    0.003 \n    0.028 \n  \n  \n    Sum \n    0.180 \n    0.188 \n    0.202 \n    0.056 \n    0.157 \n    0.128 \n    0.090 \n    1.000 \n  \n\n\n\n\n\nCode\n(\n  impressions_video_text <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(campaign_name, text_treat, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n   table %>%\n        prop.table() %>% \n        addmargins() %>% \n  .kable(caption = \"Text treatments by campaign: Impressions\", digits=3) %>%\n  .kable_styling()\n)\n\n\n\nText treatments by campaign: Impressions\n \n  \n      \n    100x impact \n    6000+ people \n    Bigger difference \n    Cause list \n    Learn \n    Only 3% research \n    Overwhelming \n    Sum \n  \n \n\n  \n    Cause-led \n    0.000 \n    0.050 \n    0.056 \n    0.029 \n    0.025 \n    0.000 \n    0.035 \n    0.194 \n  \n  \n    Cause-led V3 \n    0.000 \n    0.040 \n    0.017 \n    0.027 \n    0.024 \n    0.000 \n    0.055 \n    0.162 \n  \n  \n    Factual \n    0.006 \n    0.008 \n    0.009 \n    0.000 \n    0.013 \n    0.007 \n    0.000 \n    0.043 \n  \n  \n    Factual V2 \n    0.046 \n    0.015 \n    0.034 \n    0.000 \n    0.018 \n    0.044 \n    0.000 \n    0.157 \n  \n  \n    Factual V3 \n    0.053 \n    0.037 \n    0.041 \n    0.000 \n    0.028 \n    0.020 \n    0.000 \n    0.179 \n  \n  \n    Hypercube Brand Video \n    0.029 \n    0.014 \n    0.017 \n    0.000 \n    0.015 \n    0.024 \n    0.000 \n    0.098 \n  \n  \n    PPCo Creatives \n    0.046 \n    0.024 \n    0.029 \n    0.000 \n    0.034 \n    0.033 \n    0.000 \n    0.167 \n  \n  \n    Sum \n    0.180 \n    0.188 \n    0.202 \n    0.056 \n    0.157 \n    0.128 \n    0.090 \n    1.000 \n  \n\n\n\n\n\n(Note, above that we cannot identify all of the video treatments in the same dataset with text treatments; this is a limitation of the Facebook interface)\nHowever, note that treatment shares are not equal. In fact, as the second table above shows, they are not even equal within each campaign. This is because Facebook optimizes to show videos and text more, the more successful they are.1\n\n\n2.4.2 Demographics\n\n\nCode\n(\n  impressions_age_gender <- gg_campaign_by_ad_by_text_age_gender %>%\n  dplyr::select(age, gender, impressions) %>%\n   uncount(weights = .$impressions) %>%\n    dplyr::select(-impressions) %>%\n   table %>%\n    prop.table() %>% \n    addmargins() %>% \n  .kable(caption = \"Impressions by Age and Gender\", digits=2) %>%\n  .kable_styling()\n)\n\n\n\nImpressions by Age and Gender\n \n  \n      \n    female \n    male \n    unknown \n    Sum \n  \n \n\n  \n    25-34 \n    0.27 \n    0.09 \n    0.01 \n    0.37 \n  \n  \n    13-17 \n    0.00 \n    0.00 \n    0.00 \n    0.00 \n  \n  \n    18-24 \n    0.13 \n    0.06 \n    0.01 \n    0.19 \n  \n  \n    35-44 \n    0.16 \n    0.04 \n    0.00 \n    0.21 \n  \n  \n    45-54 \n    0.05 \n    0.01 \n    0.00 \n    0.06 \n  \n  \n    55-64 \n    0.06 \n    0.01 \n    0.00 \n    0.08 \n  \n  \n    65+ \n    0.07 \n    0.02 \n    0.00 \n    0.09 \n  \n  \n    Unknown \n    0.00 \n    0.00 \n    0.00 \n    0.00 \n  \n  \n    Sum \n    0.74 \n    0.23 \n    0.02 \n    1.00 \n  \n\n\n\n\n\nAs can be clearly seen above, within all age groups, the ad was disproportionally shown to women. Relative to the overall Facebook population our data skews very slightly younger.2\nTEST MARGIN CONTENT\n\n\nCode\nknitr::kable(\n  mtcars[1:6, 1:3]\n)\n\n\n\n\n \n  \n      \n    mpg \n    cyl \n    disp \n  \n \n\n  \n    Mazda RX4 \n    21.0 \n    6 \n    160 \n  \n  \n    Mazda RX4 Wag \n    21.0 \n    6 \n    160 \n  \n  \n    Datsun 710 \n    22.8 \n    4 \n    108 \n  \n  \n    Hornet 4 Drive \n    21.4 \n    6 \n    258 \n  \n  \n    Hornet Sportabout \n    18.7 \n    8 \n    360 \n  \n  \n    Valiant \n    18.1 \n    6 \n    225 \n  \n\n\n\n\n\n\n2.4.3 Outcomes\n\n\nCode\nbase_results_sum <- function(df) {\n    df %>%\n     dplyr::summarize(\n  Cost = sum(round(amount_spent_usd,0)),\n      Impressions=sum(impressions),\n      `Link clicks`=sum(link_clicks, na.rm = TRUE),\n      Results=sum(results, na.rm = TRUE),\n      `$/impr.` = round(Cost/Impressions,3),\n      `$/click` = round(Cost/ `Link clicks`,1),\n      `$/result` = round(Cost/Results,1),\n      `Results/1k impr.` = round(Results*1000/Impressions,1)\n)\n     }\n\n(\n  campaign_date_outcomes <-  gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(campaign_name, starts) %>%\n    rename('Campaign' = campaign_name) %>%\n    filter(impressions>200) %>%\n    base_results_sum %>%\n    arrange(starts) %>%\n    .kable(caption = \"Results by Campaign and start date\") %>%\n    .kable_styling() %>%\n    add_footnote(\"'False start' campaign dates with less than 200 impressions are excluded\")\n)\n\n\n\nResults by Campaign and start date\n \n  \n    Campaign \n    starts \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/impr. \n    $/click \n    $/result \n    Results/1k impr. \n  \n \n\n  \n    Cause-led \n    2021-11-30 \n    4,502 \n    133,035 \n    1,119 \n    410 \n    0.034 \n    4.0 \n    11.0 \n    3.1 \n  \n  \n    Factual \n    2021-11-30 \n    494 \n    12,917 \n    95 \n    20 \n    0.038 \n    5.2 \n    24.7 \n    1.5 \n  \n  \n    Factual V2 \n    2021-12-08 \n    3,414 \n    105,062 \n    1,368 \n    420 \n    0.032 \n    2.5 \n    8.1 \n    4.0 \n  \n  \n    Cause-led V3 \n    2021-12-23 \n    1,438 \n    118,942 \n    416 \n    167 \n    0.012 \n    3.5 \n    8.6 \n    1.4 \n  \n  \n    Factual V3 \n    2021-12-23 \n    1,424 \n    129,666 \n    498 \n    176 \n    0.011 \n    2.9 \n    8.1 \n    1.4 \n  \n  \n    Hypercube Brand Video \n    2022-01-07 \n    1,030 \n    60,845 \n    207 \n    65 \n    0.017 \n    5.0 \n    15.8 \n    1.1 \n  \n  \n    PPCo Creatives \n    2022-01-07 \n    1,397 \n    113,374 \n    428 \n    137 \n    0.012 \n    3.3 \n    10.2 \n    1.2 \n  \n\n\n\na 'False start' campaign dates with less than 200 impressions are excluded\n\n\n\n\n\n\n\n\nCode\n(\n  age_outcomes <- gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(age) %>%\n        filter(impressions>500) %>%\n    base_results_sum() %>%\n    .kable(caption = \"Results by Age\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Age\n \n  \n    age \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/impr. \n    $/click \n    $/result \n    Results/1k impr. \n  \n \n\n  \n    25-34 \n    3,146 \n    234,768 \n    928 \n    350 \n    0.013 \n    3.4 \n    9.0 \n    1.5 \n  \n  \n    18-24 \n    1,147 \n    98,585 \n    288 \n    114 \n    0.012 \n    4.0 \n    10.1 \n    1.2 \n  \n  \n    35-44 \n    1,694 \n    104,346 \n    491 \n    176 \n    0.016 \n    3.5 \n    9.6 \n    1.7 \n  \n  \n    45-54 \n    984 \n    30,399 \n    253 \n    101 \n    0.032 \n    3.9 \n    9.7 \n    3.3 \n  \n  \n    55-64 \n    1,677 \n    43,354 \n    498 \n    153 \n    0.039 \n    3.4 \n    11.0 \n    3.5 \n  \n  \n    65+ \n    2,812 \n    51,897 \n    1,122 \n    321 \n    0.054 \n    2.5 \n    8.8 \n    6.2 \n  \n\n\n\n\n\nCode\n(\n  gender_outcomes <- gg_campaign_by_ad_by_text_age_gender %>%\n    group_by(gender) %>%\n    base_results_sum() %>%\n    .kable(caption = \"Results by Gender\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Gender\n \n  \n    gender \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/impr. \n    $/click \n    $/result \n    Results/1k impr. \n  \n \n\n  \n    female \n    12,699 \n    573,727 \n    3,754 \n    1,259 \n    0.022 \n    3.4 \n    10.1 \n    2.2 \n  \n  \n    male \n    2,930 \n    178,313 \n    834 \n    288 \n    0.016 \n    3.5 \n    10.2 \n    1.6 \n  \n  \n    unknown \n    241 \n    18,073 \n    116 \n    34 \n    0.013 \n    2.1 \n    7.1 \n    1.9 \n  \n\n\n\n\n\nCost per click by audience (non-cause treatments):\n\n\nCode\n(\n  video_outcomes_phil <- gg_video_breakdowns %>%\n    filter(audience==\"Philanthropy\") %>%\n    group_by(video_theme) %>% \n    base_results_sum() %>%\n    arrange(video_theme) %>% \n    .kable(caption = \"Results by Video theme for 'Philanthropy' audience\") %>%\n    .kable_styling()\n)\n\n\n\nResults by Video theme for 'Philanthropy' audience\n \n  \n    video_theme \n    Cost \n    Impressions \n    Link clicks \n    Results \n    $/impr. \n    $/click \n    $/result \n    Results/1k impr. \n  \n \n\n  \n    Animal \n    2,288 \n    79,531 \n    516 \n    169 \n    0.029 \n    4.4 \n    13.5 \n    2.1 \n  \n  \n    Climate \n    267 \n    13,829 \n    97 \n    38 \n    0.019 \n    2.8 \n    7.0 \n    2.7 \n  \n  \n    Poverty \n    1,056 \n    72,115 \n    298 \n    109 \n    0.015 \n    3.5 \n    9.7 \n    1.5 \n  \n  \n    Factual \n    1,571 \n    66,600 \n    468 \n    147 \n    0.024 \n    3.4 \n    10.7 \n    2.2 \n  \n  \n    Factual or optimized mix \n    278 \n    16,777 \n    65 \n    23 \n    0.017 \n    4.3 \n    12.1 \n    1.4 \n  \n\n\n\n\n\nAbove, we compare the text treatments for the later campaigns only. The earlier and later campaigns had a slightly different set of texts; combining across these risks confounding. By ad text and by video:\n\n\nCode\n(\n  audience_outcomes <- gg_video_breakdowns %>%\n    group_by(audience) %>%\n    filter(video_theme== \"Animated\" | video_theme== \"Factual\" ) %>%\n    base_results_sum() %>%\n    DT::datatable(caption = \"Results by audience for non-cause videos\") \n)\n\n\n\n\n\n\nAbove, we look at the performance of different audiences. As cause-specific audiences tend to be presented particular cause videos, we focus only on non-cause-related videos here for greater comparability.\nFormat note: The table above is presented with the Datatables package/function. This allows sorting, filtering, etc. We can present more tables in this format if it is preferrable."
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#asking-and-answering-questions",
    "href": "chapters/testformat_gwwc_gg.html#asking-and-answering-questions",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.5 Asking and answering questions",
    "text": "2.5 Asking and answering questions\n\n\n\n\n\n\nThis dynamic document format allows us to ask and answer a series of questions\n\n\n\n\n\n\nUsing the data, with all coding steps shown\nIdeally, following a pre-defined (pre-analysis) plan\nUsing the data and statistics directly and automatically in the narrative\n\nAnd everything will be automatically adjusted if we bring in new data or adjust/correct features\n\n\n\n\n\n\nIn this context, how much does it cost to get a ’Result”, i.e., to get a person to give their email to receive a Giving Guide?\n\n\n\n\n\n\nCost per result (CpR) as the result of several processes…\n\n\n\n\n\nHow should we consider this outcome? At the base level the Cost per Result (‘CpR’) for a ‘segment’ (a particular ad version, audience, campaign, etc), comes from several interrelated processes:\n\nHow much FB charges us for this segment\nWho FB serves this segment to (what types of people, how many)\nHow many people in that segment click and then ‘convert’, yielding a result\n\nWe could try to model each of these processes, but it could be very involved, and we don’t fully observe or understand the second step, FB’s optimization algorithm.\n\n\n\n\n\n\n\n\n\nCpR as a black box…\n\n\n\n\n\nAlternatively, we could think of the CpR for a segment as just a ‘base outcome to model’, and treat it as a sort of black box. This would suggests we have ‘only one CpR coutcome per segment’, and each segment has different characteristics (‘features’ or ‘variables’), some in common. But that discards some important information: the mean values for segments with more observations (here, ‘impressions’) can be expected to have less variance (lower standard error), all else equal.\n\n\n\n\n\n\n\n\n\nCpR as the average of a lot of black boxes…\n\n\n\n\n\nWe can do something intermediate – taking the aggregation into account, without fully building a structural model of the factors above. Within each segment, we can consider the ‘average cost per result’ outcome for each individual as the expected value of a random draw. Each individual has some ‘cost per impression’, and some ‘probability of a result’. The ratio of these is the individual’s ‘expected cost per result … which we can also abstract as just some random draw. This may be considered as a function of ’all the characteristics of the segment the individual is in’. The CpR for the segment is thus an average of the CpR for all the individuals in the segment, and we can use ‘regression weights’ (technically ‘inverse variance weights’; see discussion in Huntington-Klein’s book here) in our model to reflect this.\n\n\n\n\n\n\n\n\n\n\nModeling goals/discussion/todo\n\n\n\n\n\n\nPresent mean/Bayesian updating:\n\n\nOverall cost/result\n\nand for different audiences\nrandom effects?\n\npresent posterior distribution and intervals\n\n\nModel (multivariable regression):\n\nCost/result as a function of\n\ncampaign (i.e., time of launch)\nmessage\nvideo\naudience\ngender\nage\n\nLinear and log-linear\nRandom effects (how?)\nPresent a set of estimates for the mean and 80% CI for cost/result for key groups\n\n\n\n\n\nCode\nsummarise_stuff <- function(df) {\n  df %>%\n     summarise(\n      amount_spent_usd = sum(amount_spent_usd), \n      impressions=sum(impressions),\n      link_clicks = sum(link_clicks, na.rm = TRUE),\n      results = sum(results, na.rm = TRUE),\n      cost_per_impression = amount_spent_usd/impressions,\n      cost_per_click = amount_spent_usd/link_clicks,\n      results = ifelse(is.na(results), 0, results ),\n      results_per_100usd = results/(amount_spent_usd/100),\n      results_per_1k_impressions = results*1000/impressions) \n}\n\nmodel_data_0 <- gg_campaign_by_ad_by_text_age_gender %>%\n  filter(audience!=\"Retargeting\") %>%\n  ungroup() %>%\n    group_by(video_theme, text_treat, audience) %>% #starts, \n    #filter(impressions>200) %>%\n    summarise_stuff() %>%\n  ungroup() %>% \n  as.tibble() %>% \n  mutate(\n    across(c(video_theme, text_treat, audience), #starts, \n      as.factor )\n    )\n\nmodel_data_start <- gg_campaign_by_ad_by_text_age_gender %>%\n  filter(audience!=\"Retargeting\") %>%\n  ungroup() %>%\n    group_by(video_theme, text_treat, audience, starts) %>% #starts, \n    #filter(impressions>200) %>%\n        summarise_stuff() %>%\n  ungroup() %>% \n  as.tibble() %>% \n  mutate(\n    across(c(video_theme, text_treat, audience, starts), #starts, \n      as.factor )\n    )\n\nmodel_data <- gg_campaign_by_ad_by_text_age_gender %>%\n    filter(audience!=\"Retargeting\") %>%\n  ungroup() %>%\n    group_by(video_theme, text_treat, audience, gender, agetrin) %>% #starts, \n    #filter(impressions>200) %>%\n        summarise_stuff() %>%\n  ungroup() %>% \n  as.tibble() %>% \n  mutate(\n    across(c(video_theme, text_treat, audience, gender, agetrin), #starts, \n      as.factor )\n    )\n\nRp100usd_vid_text_audience0 <- model_data_0 %>%  \n  lm(\n    results_per_100usd ~ 1 + video_theme + text_treat + audience,\n    data = ., \n    weights = impressions) \n  \n\nRp100usd_vid_text_audience_starts <- model_data_start %>%  \n  lm(\n    results_per_100usd ~ 1 + starts + video_theme + text_treat + audience,\n    data = ., \n    weights = impressions) \n  \n\nRp100usd_vid_text_audience_demo <- model_data %>%  \n  lm(\n    results_per_100usd ~ 1 + video_theme + text_treat + audience + gender + agetrin,\n    data = ., \n    weights = impressions) \n\n#Do NOT do this: Rp100usd_vid_text_audience0$df.residual <- sum(model_data_0$impressions) - length(coef(Rp100usd_vid_text_audience0))\n\nhuxtable::huxreg(Rp100usd_vid_text_audience0, Rp100usd_vid_text_audience_starts, Rp100usd_vid_text_audience_demo)\n\n\n\n\n(1)(2)(3)\n\n(Intercept)12.999 ***10.438 ***12.217 ***\n\n(1.748)   (1.949)   (1.720)   \n\nvideo_themeCause-led (any)-2.266    -1.302    -2.528    \n\n(1.366)   (1.659)   (1.345)   \n\nvideo_themeClimate-1.582    1.839    -0.790    \n\n(5.148)   (5.627)   (4.989)   \n\nvideo_themeFactual-1.500    -3.165 *  -1.285    \n\n(1.268)   (1.485)   (1.232)   \n\nvideo_themeFactual or optimized mix-6.514 ***-5.123 *  -7.076 ***\n\n(1.598)   (2.068)   (1.580)   \n\nvideo_themePoverty0.496    1.269    0.916    \n\n(2.350)   (2.600)   (2.288)   \n\ntext_treat6000+ people-3.546 ***-3.060 ** -2.934 ** \n\n(0.991)   (1.122)   (0.960)   \n\ntext_treatBigger difference-1.250    0.007    -0.754    \n\n(0.960)   (1.070)   (0.931)   \n\ntext_treatCause list-1.190    -1.769    -1.505    \n\n(1.509)   (1.745)   (1.462)   \n\ntext_treatLearn-2.340 *  -1.553    -2.068 *  \n\n(1.002)   (1.109)   (0.971)   \n\ntext_treatOnly 3% research2.144 *  2.692 *  2.581 *  \n\n(1.040)   (1.138)   (1.008)   \n\ntext_treatOverwhelming-1.632    -1.794    -0.600    \n\n(1.297)   (1.561)   (1.256)   \n\naudienceAnimal-0.365    0.336    -0.563    \n\n(1.021)   (1.170)   (1.000)   \n\naudienceClimate-0.377    0.126    -0.940    \n\n(0.902)   (1.071)   (0.882)   \n\naudienceGeneral audience0.690    1.319    0.624    \n\n(1.215)   (1.452)   (1.186)   \n\naudienceGlobal Poverty-0.621    -0.497    -1.366    \n\n(1.303)   (1.472)   (1.265)   \n\naudienceLookalikes2.579 *  1.197    2.080 *  \n\n(1.085)   (1.191)   (1.052)   \n\nstarts2021-12-08        4.718 ***        \n\n        (1.259)           \n\nstarts2021-12-23        4.790 ***        \n\n        (0.888)           \n\nstarts2022-01-07        0.262            \n\n        (1.384)           \n\ngendermale                0.209    \n\n                (0.645)   \n\ngenderunknown                -0.312    \n\n                (1.779)   \n\nagetrin0                1.048    \n\n                (0.842)   \n\nagetrin1                1.351    \n\n                (0.707)   \n\nN104        185        772        \n\nR20.445    0.355    0.092    \n\nlogLik-282.883    -576.659    -3209.739    \n\nAIC601.767    1195.318    6463.478    \n\n *** p < 0.001;  ** p < 0.01;  * p < 0.05.\n\n\n\n\nNote: the N (and R-sq?) values above are incorrect; these are the number of groups not the number of baseline observations.\n3\n\n\nWhich pre-defined audience yields a Result at the lowest cost? How does this cost vary by audience?\n\nRefer to models/estimates above\n\n\n\nWhich pre-defined audience yields the highest ‘rate of Result’? How does this vary by audience?\nNote, this is not the same as the previous question because some audiences are more costly to target on Facebook.\n\nRe-run above models for ‘results per impression’\n\nImportant caveat: this does not tell us the effect ‘on a particular group’, because of FB’s optimization algorithms.\nInteractions/separate models for ‘vary by audience’.\n\n\nWhich video yields a Result at the highest rate/lowest cost?\n\nRefer to models/estimates above, coefficient on ‘video’\n\n4\n\nHow does the ‘best video’ vary by audience?\n\nInclude interactions in above model\nRun model separately for each group (or allowing everything to interact) for robustness\nAlso consider ‘what did FB serve to each group’, assuming it is optimizing.\n\n\n\nAggregating: Which category of videos yields a result at the highest rate/lowest cost? (“Facts”, “Cause focus”, or “Arguments, rich content”)\n\nAbove, pooling videos of similar type. (Random effects models?)\n\n\n\n\nWhich message yields a Result at the highest rate/lowest cost?\n5\nSub-questions\n\nHow does the ‘best message’ vary by audience?\n\n\n\n\n\n\nOther questions (less interest or less feasible)\n\n\n\n\n\n\nDo the message treatments ‘interact’ with the video treatments (i.e., are their synergies and better pairings)?\nDo some videos lead to higher click rates?\nDo some videos lead to higher watch rates?\n\n\n\n\n\n\n\n2.5.1 Defining the ‘outcomes of interest’ (as objects)\n\n\n\nNext, we define the ‘features of interest’ and the ‘controls’\n\n\nCode\n#features and controls\n#geog <- c(\"where_live_cat\", \"city_cat\")\n#key_demog <- c(\"ln_age\", \"not_male_cat\", \"student_cat\", \"race_cat\", geog)\n#key_demog_n <- c(\"age_d2sd\", \"not_male_cat\", \"student_cat\", \"race_cat\", geog)"
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#analysis-and-visuals",
    "href": "chapters/testformat_gwwc_gg.html#analysis-and-visuals",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.6 Analysis and visuals",
    "text": "2.6 Analysis and visuals\n6\n\n\nCode\n##gwwc_vid_results$DV_costadj)\n##gwwc_vid_results$DV)\n##gwwc_vid_results$ave.cost.impr)\n\n\nData summary\n\nBelow, a few data summary bits (from Erin). I commented most of it out and will redo it using an automated and formatted ‘key summary statistics’ package.\nI may also present the data in a dashboard for self-service.\n\n\n\nCode\n#datatable(gwwc_vid_results)\n\n\n\n\nCode\ngwwc_vid_results %>% group_by(Age) %>% summarise(n=n()) %>% .kable() %>%  .kable_styling()\n\n\nError in group_by(., Age): object 'gwwc_vid_results' not found\n\n\nCode\ngwwc_vid_results %>% group_by(Gender) %>% summarise(n=n())  %>% .kable() %>%  .kable_styling()\n\n\nError in group_by(., Gender): object 'gwwc_vid_results' not found\n\n\nCode\n#print(gwwc_vid_results %>% group_by(Gender,Age) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=40)\n#print(gwwc_vid_results %>% group_by(Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=41)\n#print(gwwc_vid_results %>% group_by(Campaign.name,Ad.Set.Name) %>% summarise(n=n(),cost=mean(ave.cost.impr)),n=100)\n\n\n\n\nCode\n### CHART DATA\n\n#print(gwwc_vid_results %>% group_by(audience,media) %>% #summarise(results=mean(DV)*100,SE=std.error(DV)*100,n=n(),cost=mean(ave.cost.impr),CPR=cost/results),n=50)"
  },
  {
    "objectID": "chapters/testformat_gwwc_gg.html#plots",
    "href": "chapters/testformat_gwwc_gg.html#plots",
    "title": "2  FORMAT TESTING Giving What We Can: Giving guides",
    "section": "2.7 PLOTS",
    "text": "2.7 PLOTS\n\n\nCode\n#Plot options in common\n\nlimits <- aes(ymax = mean_dv + (se_dv), ymin = mean_dv - (se_dv))\ndodge <- position_dodge(width = 0.9)\n\nvid_types <-\n  c(\"factual short\",\n    \"animal\",\n    \"climate\",\n    \"factual long\",\n    \"hypercube\",\n    \"poverty\")\n\ngg_gg_options <- list(geom_bar(stat = 'identity', position=dodge),\n  geom_errorbar(limits, position=dodge,  width=0.05),\n  jtools::theme_apa(),\n  theme(legend.position=\"none\"),\n  geom_text(aes(label = paste(\"$\",mean_dv %>% round(.,2)), y=5), position = position_dodge(.9), size=4, color=\"white\"),\n  theme(text=element_text(size=10))\n)\n\ngrpsumgg <- function(df, gvar, var) {\n  df %>%\n  group_by({{gvar}}) %>%\n  summarise(mean_dv = mean({{var}}, na.rm=TRUE),\n            se_dv = sd({{var}}, na.rm=TRUE)/sqrt(n()))\n}\n\n\n\n2.7.1 PLOT: Cost adjusted DV (results) by video\n\n\nCode\ngwwc_vid_results %>%\n    filter(ave.cost.impr > 0) %>%\n    group_by(media) %>%\n    summarise(\n    `Results per $ (adjusted)` = mean(DV_costadj),\n    SE = std.error(DV_costadj),\n    n = n()\n  ) %>%\n  arrange(-`Results per $ (adjusted)`) %>%\n  .kable(digits = 3) %>%\n  .kable_styling()\n\n\nError in filter(., ave.cost.impr > 0): object 'gwwc_vid_results' not found\n\n\n\n\nCode\ngwwc_vid_results %>%\n  grpsumgg(media, DV_costadj) %>%\n  ggplot(aes(x=media, y=mean_dv)) +\n  gg_gg_options +\n  geom_bar(stat='identity',fill=\"#0072B2\", position=dodge) +\n  ylab('Results/$ spent') +\n  xlab('Video') +\n  ggtitle('Results/$ spent by Video') +\n  scale_y_continuous(limits = c(0,.2),  breaks=seq(0,.2, by=.05)) +\n  scale_x_discrete(labels=vid_types)\n\n\nError in group_by(., {: object 'gwwc_vid_results' not found\n\n\n\n\n2.7.2 PLOT: DV (Results) by video\n\n\nCode\ngwwc_vid_results %>% filter(ave.cost.impr > 0) %>%\n  group_by(media) %>%\n  summarise(\n  results = 100 * mean(DV),\n  SE = 100 * std.error(DV),\n  n = n()\n) %>%\n  .kable(digits = 2) %>%\n  .kable_styling()\n\n\nError in filter(., ave.cost.impr > 0): object 'gwwc_vid_results' not found\n\n\nCode\ngwwc_vid_results %>%\n   grpsumgg(media, DV) %>%\n  ggplot(aes(x=media, y=mean_dv)) +\n  geom_bar(stat='identity', fill=\"#0072B2\",position=dodge) +\n  ylab('Results (%)')+\n  xlab('Video')+\n  ggtitle('Results by Video')+\n  scale_x_discrete(labels=vid_types)\n\n\nError in group_by(., {: object 'gwwc_vid_results' not found"
  },
  {
    "objectID": "chapters/gwwc_gg.html#modeling-cost-per-result-and-results-per-dollar-possible-reference-literature",
    "href": "chapters/gwwc_gg.html#modeling-cost-per-result-and-results-per-dollar-possible-reference-literature",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.10 Modeling ‘cost per result’ and ‘results per dollar’: possible reference literature",
    "text": "1.10 Modeling ‘cost per result’ and ‘results per dollar’: possible reference literature\nSodomka, Eric, Sébastien Lahaie, and Dustin Hillard. “A predictive model for advertiser value-per-click in sponsored search.” Proceedings of the 22nd international conference on World Wide Web. 2013.\nChris Bow Kaggle vignette"
  },
  {
    "objectID": "chapters/gwwc_gg.html#building-a-set-of-models-to-do",
    "href": "chapters/gwwc_gg.html#building-a-set-of-models-to-do",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.6 Building a set of models (to do)",
    "text": "1.6 Building a set of models (to do)\nNOTE 11 Aug 2022: adjusting this from another context - WIP\n\n\nCode\n#THE content belo \n#targets:\nbin_out <- c(\"d_don_1k\", \"d_don_10pct\")\n\nnum_out <- c('donation_usd', 'don_av2_yr', 'l_don_usd', \"l_don_av_2yr\", \"don_share_inc_imp_bc5k\", \"donation_plan_usd\")\ntargets <- c(bin_out, num_out)\ntargets_short <- c(\"don_av2_yr\", \"don_share_inc_imp_bc5k\", \"d_don_1k\")\n\n#Note -- don_av2_yr is the right one for qpoisson as it already expresses things in exponents. l_don_av2_yr was the one to use in the loglinear model, which we are not emphasizing\n\ntargets_short_names <- c(\"Log (Avg don +1)\", \"Don/Income\", \"Donated 1k+\")\n\n\n\n\nCode\n#imputing and normalization\n\n\n\n\nCode\n#labeling for model output\n\nkey_eas_all_labels <- c( #note these are converted to a list with as.list before assigning them\n    donation_usd = \"Donation (USD)\",\n    l_don_usd = \"Log Don. (USD)\",\n    l_don_av_2yr = \"Log Don. 'avg.'\",\n    ln_age = \"Log age\",\n    don_av2_yr = \"Don. 'avg'\",\n    donation_plan_usd = \"Don. plan (USD)\")\n\n\n\n\nCode\nfeat_list = list(\n  c(key_demog, feat_income_employ, controls),\n  c(key_demog, feat_income_employ, controls, robust_controls),\n  c(key_demog, feat_income_employ, feat_gwwc_etg, controls) )\n\nfeat_names = c(\"Baseline\", \"Robust controls\",  \"Base + EtG & GWWC\")\n\n\n\n\nCode\nrhs_vars_list <- rep(feat_list, length(targets_short))\n\noutcome_vars_list <- rep(as.list(targets_short), each=length(feat_list))\n\ndfs <- rep(list(eas_all_s_rl_imp), length(outcome_vars_list))\n\n\n\n\nCode\n## Create dataframe for modeling\n(linear_models <- make_model_df(rhs_vars_list, outcome_vars_list, dfs))\n\n\n\n\nCode\nlinear_models <- linear_models %>%\n  mutate(\n    lm_fit = fit_models(\n      linear_models, \"formulas\", \"dfs\", fun = fit_lm)\n    )\n\n# Extract coefficients, fitted and residuals\nmodel_feat_names <- rep(c(feat_names), times= length(targets_short))\nmodel_oc_names <- rep(c(targets_short_names), each= length(feat_names))\nmodel_names <- paste(model_oc_names, model_feat_names, sep = \": \")\n\n\n\n\n\n\n\n\nModeling goals/discussion/todo\n\n\n\n\n\n*Rethinking (5 Aug 2022): Cost per result may not be the best outcome to model as a first pass. We might better model results per impression and put in a cost adjustment later. See\n\nPresent mean/Bayesian updating:\n\n\nOverall cost/result\n\nand for different audiences\nrandom effects?\n\npresent posterior distribution and intervals\n\nOr a stripped down ‘simulation approach’?\n\nModel (multivariable regression):\n\nCost/result as a function of\n\ncampaign (i.e., time of launch)\nmessage\nvideo\naudience\ngender\nage\n\nLinear and log-linear\nRandom effects (how?)\nPresent a set of estimates for the mean and 80% CI for cost/result for key groups\n\n\n\n\n\nCode\n#set base levels before doing modeling\n\ngg_campaign_by_ad_by_text_age_gender$age <- factor( gg_campaign_by_ad_by_text_age_gender$age,\n  ordered = FALSE )\n\ngg_campaign_by_ad_by_text_age_gender$age <- relevel( gg_campaign_by_ad_by_text_age_gender$age,\n  ref=\"18-24\")\n\ngg_campaign_by_ad_by_text_age_gender$audience <- factor( gg_campaign_by_ad_by_text_age_gender$audience,\n  ordered = FALSE )\n\ngg_campaign_by_ad_by_text_age_gender$audience <- relevel( gg_campaign_by_ad_by_text_age_gender$audience,\n  ref=\"Philanthropy\")\n\n\n\n\nCode\nsummarise_stuff <- function(df) {\n  df %>%\n     summarise(\n      amount_spent_usd = sum(amount_spent_usd),\n      reach=sum(reach),\n      link_clicks = sum(link_clicks, na.rm = TRUE),\n      results = sum(results, na.rm = TRUE),\n      cost_per_impression = amount_spent_usd/reach,\n      cost_per_click = amount_spent_usd/link_clicks,\n      results = ifelse(is.na(results), 0, results ),\n      results_per_100usd = results/(amount_spent_usd/100),\n      results_per_1k_reach = results*1000/reach)\n}\n\nmodel_data_0 <- gg_campaign_by_ad_by_text_age_gender %>%\n  filter(audience!=\"Retargeting\") %>%\n  ungroup() %>%\n    group_by(video_theme, text_treat, audience) %>% #starts,\n    #filter(reach>200) %>%\n    summarise_stuff() %>%\n  ungroup() %>%\n  as.tibble() %>%\n  mutate(\n    across(c(video_theme, text_treat, audience), #starts,\n      as.factor )\n    )\n\nmodel_data_start <- gg_campaign_by_ad_by_text_age_gender %>%\n  filter(audience!=\"Retargeting\") %>%\n  ungroup() %>%\n    group_by(video_theme, text_treat, audience, starts) %>% #starts,\n    #filter(reach>200) %>%\n        summarise_stuff() %>%\n  ungroup() %>%\n  as.tibble() %>%\n  mutate(\n    across(c(video_theme, text_treat, audience, starts), #starts,\n      as.factor )\n    )\n\nmodel_data <- gg_campaign_by_ad_by_text_age_gender %>%\n    filter(audience!=\"Retargeting\") %>%\n  ungroup() %>%\n    group_by(video_theme, text_treat, audience, gender, agetrin) %>% #starts,\n    #filter(reach>200) %>%\n        summarise_stuff() %>%\n  ungroup() %>%\n  as.tibble() %>%\n  mutate(\n    across(c(video_theme, text_treat, audience, gender, agetrin), #starts,\n      as.factor )\n    )\n\nRp100usd_vid_text_audience0 <- model_data_0 %>%\n  lm(\n    results_per_100usd ~ 1 + video_theme + text_treat + audience,\n    data = .,\n    weights = reach)\n\n\nRp100usd_vid_text_audience_starts <- model_data_start %>%\n  lm(\n    results_per_100usd ~ 1 + starts + video_theme + text_treat + audience,\n    data = .,\n    weights = reach)\n\n\nRp100usd_vid_text_audience_demo <- model_data %>%\n  lm(\n    results_per_100usd ~ 1 + video_theme + text_treat + audience + gender + agetrin,\n    data = .,\n    weights = reach)\n\n#Do NOT do this: Rp100usd_vid_text_audience0$df.residual <- sum(model_data_0$reach) - length(coef(Rp100usd_vid_text_audience0))\n\nhuxtable::huxreg(Rp100usd_vid_text_audience0, Rp100usd_vid_text_audience_starts, Rp100usd_vid_text_audience_demo)\n\n\n\n\n(1)(2)(3)\n\n(Intercept)12.402 ***10.855 ***11.836 ***\n\n(1.608)   (1.976)   (1.611)   \n\nvideo_themeCause-led (any)-2.292    -1.287    -2.441    \n\n(1.260)   (1.682)   (1.260)   \n\nvideo_themeClimate-1.862    2.010    -0.919    \n\n(4.758)   (5.719)   (4.689)   \n\nvideo_themeFactual long-7.290 ***-6.227 ** -7.669 ***\n\n(1.638)   (2.007)   (1.619)   \n\nvideo_themeFactual short-0.003    -1.869    0.125    \n\n(1.189)   (1.647)   (1.174)   \n\nvideo_themeHypercube (factual)-6.552 ***-5.167 *  -6.976 ***\n\n(1.472)   (2.088)   (1.478)   \n\nvideo_themePoverty0.018    1.248    0.686    \n\n(2.135)   (2.594)   (2.112)   \n\ntext_treat6000+ people-2.806 ** -2.959 ** -2.358 ** \n\n(0.912)   (1.130)   (0.899)   \n\ntext_treatBigger difference-0.658    -0.008    -0.276    \n\n(0.886)   (1.081)   (0.873)   \n\ntext_treatCause list-0.435    -1.647    -0.876    \n\n(1.385)   (1.760)   (1.364)   \n\ntext_treatLearn-1.512    -1.306    -1.305    \n\n(0.924)   (1.121)   (0.910)   \n\ntext_treatOnly 3% research2.361 *  2.744 *  2.793 ** \n\n(0.957)   (1.151)   (0.943)   \n\ntext_treatOverwhelming-0.926    -1.487    -0.083    \n\n(1.203)   (1.593)   (1.185)   \n\naudienceAnimal-0.442    0.307    -0.578    \n\n(0.932)   (1.174)   (0.928)   \n\naudienceClimate-0.091    0.109    -0.805    \n\n(0.830)   (1.081)   (0.824)   \n\naudienceGeneral audience0.938    1.420    0.799    \n\n(1.117)   (1.464)   (1.108)   \n\naudienceGlobal Poverty-0.277    -0.349    -1.261    \n\n(1.180)   (1.465)   (1.165)   \n\naudienceLookalikes1.985 *  1.075    1.459    \n\n(0.990)   (1.191)   (0.975)   \n\nstarts2021-12-08        2.915            \n\n        (1.532)           \n\nstarts2021-12-23        3.559 **         \n\n        (1.072)           \n\nstarts2022-01-07        -0.300            \n\n        (1.411)           \n\ngendermale                0.558    \n\n                (0.604)   \n\ngenderunknown                -0.459    \n\n                (1.686)   \n\nagetrin0                0.770    \n\n                (0.794)   \n\nagetrin1                1.014    \n\n                (0.667)   \n\nN129        185        991        \n\nR20.509    0.366    0.115    \n\nlogLik-360.487    -574.434    -4238.915    \n\nAIC758.974    1192.867    8523.830    \n\n *** p < 0.001;  ** p < 0.01;  * p < 0.05.\n\n\n\n\nNote: the N (and R-sq?) values above are incorrect; these are the number of groups not the number of baseline observations.\n11\n\nWhich pre-defined audience yields a Result at the lowest cost? How does this cost vary by audience?\n\nRefer to models/estimates above\n\n\n\nCode\nlimits <- aes(ymax = mean_dv + (se_dv), ymin = mean_dv - (se_dv))\ndodge <- position_dodge(width = 0.9)\n\n\ngg_gg_options <- list(geom_bar(stat = 'identity', position=dodge),\n  geom_errorbar(limits, position=dodge,  width=0.25, color=\"red\"),\n  jtools::theme_apa(),\n  theme(legend.position=\"none\"),\n  geom_text(aes(label = paste(\"$\", mean_dv %>% round(.,2)), y=5), position = position_dodge(.9), size=4, color=\"white\"),\n  theme(text=element_text(size=10))\n)\n  \n\nlimits <- aes(ymax = mean_dv , ymin = mean_dv)\ndodge <- position_dodge(width = 0.9)\n\n\n\n(\n  result_by_age <-  gg_campaign_by_ad_by_text_age_gender %>%\n        mutate(results_per_100usd = results/(amount_spent_usd/100)) %>%\n     uncount(weights = .$reach) %>%\n   group_by(age) %>%\n  summarise(mean_dv = mean(results_per_100usd, na.rm=TRUE)) %>% \n  ggplot(aes(x=age, mean_dv)) +\n  geom_bar(stat='identity',fill=\"#0072B2\", position=dodge) +\n  ylab('Results/$ spent') +\n  xlab('Video') +\n  ggtitle('Results/$ spent by Age') \n#+  scale_x_discrete(labels=vid_types)\n)\n\n\n\n\n\n\n\nWhich pre-defined audience yields the highest ‘rate of Result’? How does this vary by audience?\nNote, this is not the same as the previous question because some audiences are more costly to target on Facebook.\n\nRe-run above models for ‘results per impression’\n\nImportant caveat: this does not tell us the effect ‘on a particular group’, because of FB’s optimization algorithms; see discussion here.\nInteractions/separate models for ‘vary by audience’.\n\n\nWhich video yields a Result at the highest rate/lowest cost?\n\n\nCode\n#Plot options in common\n\n#limits <- aes(ymax = mean_dv + (ci_spread), ymin = mean_dv - (ci_spread))\ndodge <- position_dodge(width = 0.9)\n\nvid_types <-\n  c(\"factual short\",\n    \"animal\",\n    \"climate\",\n    \"factual long\",\n    \"hypercube\",\n    \"poverty\")\n\n\n\ngrpsumgg <- function(df, gvar, var, ci_ends) {\n  df %>%\n  group_by({{gvar}}) %>%\n  summarise(mean_dv = mean({{var}}, na.rm=TRUE),\n            se_dv = sd({{var}}, na.rm=TRUE)/sqrt(n()),\n            ci_spread = qt(1 - (ci_ends / 2), n() - 1) * se_dv)\n}\n\n\n\n\nCode\ngg_video_breakdowns %>%\n        mutate(results_per_100usd = results/(amount_spent_usd/100)) %>%\n     uncount(weights = .$reach) %>%\n   group_by(video_theme) %>%\n  summarise(mean_dv = mean(results_per_100usd, na.rm=TRUE)) %>% \n  #grpsumgg(video_theme, results_per_100usd, 0.1) %>%\n  ggplot(aes(x=video_theme, mean_dv)) +\n  geom_bar(stat='identity',fill=\"#0072B2\", position=dodge) +\n  #gg_gg_options +\n  ylab('Results/$ spent') +\n  xlab('Video') +\n  #ggtitle('Results/$ spent by Video, 90% CIs') +\n  ggtitle('Results/$ spent by Video') +\n  scale_x_discrete(labels=vid_types)\n\n\n\n\n\nCode\n# gwwc_vid_results %>%\n#   grpsumgg(media, DV_costadj, 0.1) %>%\n#   ggplot(aes(x=media, y=mean_dv)) +\n#   geom_bar(stat='identity',fill=\"#0072B2\", position=dodge) +\n#   gg_gg_options +\n#   ylab('Results/$ spent') +\n#   xlab('Video') +\n#   ggtitle('Results/$ spent by Video, 90% CIs') +\n#   scale_y_continuous(limits = c(0,.2),  breaks=seq(0,.2, by=.05)) +\n#   scale_x_discrete(labels=vid_types)\n# \n\n\n\nRefer to models/estimates above, coefficient on ‘video’\n\n12\n\nHow does the ‘best video’ vary by audience?\n\nInclude interactions in above model\nRun model separately for each group (or allowing everything to interact) for robustness\nAlso consider ‘what did FB serve to each group’, assuming it is optimizing.\n\n\n\nAggregating: Which category of videos yields a result at the highest rate/lowest cost? (“Facts”, “Cause focus”, or “Arguments, rich content”)\n\nAbove, pooling videos of similar type. (Random effects models?)\n\n\n\n\nWhich message yields a Result at the highest rate/lowest cost?\n13\nSub-questions\n\nHow does the ‘best message’ vary by audience?\n\n\n\n\n\n\nOther questions (less interest or less feasible)\n\n\n\n\n\n\nDo the message treatments ‘interact’ with the video treatments (i.e., are their synergies and better pairings)?\nDo some videos lead to higher click rates?\nDo some videos lead to higher watch rates?"
  },
  {
    "objectID": "chapters/gwwc_gg.html#modelingsimulating-cis-for-results-by-group",
    "href": "chapters/gwwc_gg.html#modelingsimulating-cis-for-results-by-group",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.8 Modeling/simulating CIs for results by group",
    "text": "1.8 Modeling/simulating CIs for results by group\n\n\n\n\n\n\nSimulation-based: Sketched proposal\n\n\n\n\n\n\nAssume the ‘cost per impression’ (CpI) is fixed for each group or segment – take that as exogenous and something we adjust for at the end15\nMake some assumptions about the distribution of the probability of a result from an impression for each individual in each group \\(g\\); call this \\(P_{ig}\\). E.g., each outcome \\(r_i \\in \\{0,1\\}\\) is drawn with probability \\(P_{ig}\\). We see the average of these draws.\n\nA close-to-correct simplification might yield that the group-specific results per impression (RpI) is the average value of \\(P_{ig}\\) for the group, call this \\(P_g\\). We can make some intuitive assumptions about the variance of \\(P_{ig}\\) around \\(P_g\\) within each group.\nSo we would have something like: \\(P_{ig} \\sim \\beta\\) distribution with a mean of RpI (results per impression for the group), and some reasonable variation.\n\nLet \\(N_g\\) be the number of impressions we see per group.\n\nIn each simulation replication, simulate \\(N_g\\) draws of \\(P_{ig}\\) for each individual in each group \\(g\\).\nNext ‘flip an unfair coin for each individual’, where the coin has probability \\(P_{ig}\\) of a result. This yields \\(N_g\\) draws of the 0/1 outcome \\(r_i(g)\\) for each group\n\nLook at the distribution of results for each group across many simulations. This can easily be converted to the distribution of RpI for each group, or, assuming CpI is fixed, the distribution of ‘cost per result’ (or results per cost) for each group.\n\nThis gives us our confidence intervals.\nThe above is a bit ad-hoc (but less than our previous work). I suspect the procedure comes close to something that could give us something Bayesian.\n\n\n\n\n\n\n\n\n\nAdjusting the above to Jamie’s suggestions … for a 2 step simulation\n\n\n\n\n\n\nDraw \\(P_{gci}\\) — the probability of a click for person \\(i\\) in group \\(g\\) for each individual (impression) in each group which might have a mean at the empirical click rate for this group, \\(C_g/N_g\\), where \\(N_g\\) is the number of impressions in group \\(g\\)\nSimulate clicks by group with \\(N_g\\) coin flips each w/ draws from the \\(P_{gci}\\) probability vector \\(\\rightarrow\\) \\(C^k_g\\) simulated clicks for group \\(g\\) in simulation \\(k\\)\nDraw \\(P_{gri|c}\\): ‘probability of result given click’ for individual \\(i\\) in group \\(g\\)\n\nwhich might have a mean at the empirical results/clicks for this group\n\nSimulate results by group with \\(C^k_g\\) draws with vector of probabilities \\(P_{gri|c}\\) \\(\\rightarrow\\) \\(R^k_g\\) simulated results for group \\(g\\) in simulation \\(k\\)\n\nMy concern in general with these hurdle models is when they make inferences that depended on independence across hurdles. Here, I would be concerned if it depends on the probabilities \\(P_{gc}\\) and \\(P_{gr|c}\\) being independent.\nTo me it seems plausible that for higher draws of \\(P_c\\) we tend to have lower values of \\(P_{r|c}\\) … e.g., people (and groups) who click on everything rarely convert when they click.\nBut I don’t think that the simulation posed above itself suffers from this problem. If one group has a high click rate and a low ‘conversions per click’ rate, I think this would be reflected in the means of the distributions of \\(P\\)’s I use for the simulation above.\nAs long as we don’t try to make (overly strong inferences) from the differences in \\(P_{gr|c}\\) by group \\(g\\) itself, I think we are OK. So the ‘two step’ simulation could indeed be better here."
  },
  {
    "objectID": "chapters/gwwc_gg.html#erins-work-moved",
    "href": "chapters/gwwc_gg.html#erins-work-moved",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.8 Erin’s work (moved)",
    "text": "1.8 Erin’s work (moved)\n\n1.8.1 PLOTS (Erin)\nMoved to archive: eamt_data_analysis/gwwc/giving_guides/archive_erin/erin_plots_stats_gg.qmd; will re-incoprporate and adjust\n\n\n1.8.2 Models, statistics and crosstabs (Erin)\nMoved to archive: ../erin_plots_stats_gg.qmd"
  },
  {
    "objectID": "chapters/gwwc_gg.html#bayesian-cis-from-jamies-work-in-fb-ad-analysis.r",
    "href": "chapters/gwwc_gg.html#bayesian-cis-from-jamies-work-in-fb-ad-analysis.r",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.10 Bayesian CIs – from Jamie’s work in fb ad analysis.R",
    "text": "1.10 Bayesian CIs – from Jamie’s work in fb ad analysis.R\ngoogle drive link\n\n\nCode\nlibrary(pacman)\np_load(brms, install=FALSE)\nlibrary(brms)\np_load(tidybayes, install=FALSE)\nlibrary(tidybayes)\n\n\n\n\nCode\nsum_results <- function(df) {\n    df %>%\n     summarise(\n    results = sum(results, na.rm = TRUE),\n    spend = sum(amount_spent_usd, na.rm = TRUE),\n    clicks = sum(link_clicks, na.rm = TRUE),\n    impressions = sum(impressions, na.rm = TRUE),\n    reach = sum(reach, na.rm = TRUE)\n  )\n}\n\n# collapse into the categories of interest\ngg_video_breakdowns_col <- gg_video_breakdowns %>%\n  group_by(video_theme, audience) %>%\n  #group_by(video_theme, audience, starts) %>%\nsum_results\n#%>%   mutate(starts = as.factor(starts))\n#rem: we are just summing outcomes, so no weights are needed here\n\n\n… checking some reasonable priors by looking at percent age conversion rate with different numbers\n\n\n\nCode\nclicks_per_reach_video_aud <- as.formula(\"clicks | trials(reach) ~ video_theme + audience + video_theme:audience \")\n\n# +  starts\n\nresults_per_click_video_aud <- as.formula(\"results | trials(clicks) ~ video_theme + audience + video_theme:audience  \")\n\n\n## passing a list\narg.list <- list(init = 0,\n                  chains = 4,\n                  cores = 4,\n                  iter = 2500,\n                  warmup = 500,\n                  backend = \"cmdstanr\",\n                  seed = 1010,\n    silent=2,  refresh = 0)\n\n\nclicks_logit <-  do.call(\"brm\", c(list(data =gg_video_breakdowns_col, \n  formula = clicks_per_reach_video_aud,\n                  family = binomial(\"logit\"),\n                  control = list(adapt_delta = 0.99, max_treedepth = 15),\n                  prior = c(prior(normal(-3.5, 2), #DR: where do the priors come from?  \n                    class = Intercept),\n                            prior(normal(0, 1), class = b))),\n                  arg.list,                  \n  list(threads = threading(8)))\n)\n\n\nRunning MCMC with 4 parallel chains, with 8 thread(s) per chain...\n\nChain 1 finished in 3.4 seconds.\nChain 3 finished in 4.6 seconds.\nChain 4 finished in 4.6 seconds.\nChain 2 finished in 7.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 4.9 seconds.\nTotal execution time: 7.2 seconds.\n\n\nCode\nresults_logit <-  do.call(\"brm\", c(list(data = gg_video_breakdowns_col, \n  formula = results_per_click_video_aud,\n                  family = binomial(\"logit\"),\n                  control = list(adapt_delta = 0.99, max_treedepth = 15),\n                  prior = c(prior(normal(-3.5, 2), #DR: where do the priors come from?  \n                    class = Intercept),\n                            prior(normal(0, 1), class = b))),\n                  arg.list,                  \n  list(threads = threading(8)))\n)\n\n\nRunning MCMC with 4 parallel chains, with 8 thread(s) per chain...\n\nChain 1 finished in 2.1 seconds.\nChain 2 finished in 2.1 seconds.\nChain 3 finished in 2.2 seconds.\nChain 4 finished in 2.8 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.3 seconds.\nTotal execution time: 2.9 seconds.\n\n\n\n\nCode\n# posterior expectations:\nfull_crossing <- expand_grid(\n  \"video_theme\" = unique(gg_video_breakdowns_col$video_theme),\n  \"audience\" = unique(gg_video_breakdowns_col$audience)) %>% \n  mutate(reach = 1,\n         clicks = 1) %>% \nfilter(!(audience==\"Animal\" & (video_theme == \"Climate\" | video_theme == \"Poverty\")))  %>%\n    filter(!(audience==\"Climate\" & (video_theme == \"Animal\" | video_theme == \"Poverty\")))  %>%\n    filter(!(audience==\"Global Poverty\" & (video_theme == \"Animal\" | video_theme == \"Climate\")))\n\n# setting reach/clicks = 1 will give us proportion of conversions (DR: why?)\n\n\nclick_post <- posterior_epred(clicks_logit,\n                              ndraws = 1000,\n                              newdata = full_crossing)\n\nresults_post <- posterior_epred(results_logit,\n                              ndraws = 1000,\n                              full_crossing)\n\ncombined_post <- click_post * results_post #DR: I guess we are multiplying the predicted probabilities of click and conversion here?\n\n\n\n\nCode\n#make tibbles of the stuff above, put it together s\n\npost_tib_clean <- function(df, name) {\n  df %>% \n    as.tibble() %>% \n    pivot_longer(cols = everything(),\n    names_to = \"identifier\",\n    values_to = \"probability\") %>%\n     mutate(level = name,\n       theme = rep(full_crossing$video_theme, 1000),\n       audience = rep(full_crossing$audience, 1000)\n       #     starts = rep(full_crossing$starts, 1000) #ÎR: I think I want starts (start date as a factor) in the model, because the audience may be systematically different on those days, and other things change we leave out here. However, I don't want to see it in the graphs. How to do that? \n     )\n}\n\n# make tibbles\ntib_click_post <- click_post %>% \n  post_tib_clean( \"1. Reach to clicks\")\n\ntib_result_post <- results_post  %>%\n    post_tib_clean(\"2. Clicks to signups\")\n\ntib_combined_post <- combined_post %>%\n      post_tib_clean(\"3. Total\") \n\nfull_post <- bind_rows(tib_click_post,\n                       tib_result_post,\n                       tib_combined_post)\n\n\n\n\nCode\nhdi <- HDInterval::hdi\n\nCI_choice_narrow <- 0.6\nCI_choice_wide <- 0.9\n\nsum_mean_hdi <- function(df) {\n  df %>% \n    summarise(mean = mean(probability) * 100,\n            lower_n = hdi(probability, credMass = CI_choice_narrow)[1] * 100,\n            upper_n = hdi(probability, credMass = CI_choice_narrow)[2] * 100,\n              lower_w = hdi(probability, credMass = CI_choice_wide)[1] * 100,\n            upper_w = hdi(probability, credMass = CI_choice_wide)[2] * 100)\n} \n  \n\npost_summary <- full_post %>% \n  group_by(level, theme, audience) %>% #, starts\n  sum_mean_hdi\n\n\n\n\nCode\n\naud_plots <- function(df) {\n  df %>% \n       filter(audience!=\"Retargeting\")  %>%\n    group_by(level, audience) %>% #, starts\n    sum_mean_hdi %>% \n    mutate(audience = reorder(as.factor(audience), `mean`)) %>% \n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = audience), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = audience),  height=.25, color = \"blue\") +\n  geom_point(\n    aes(x=`mean`, \n    y = audience))\n    } \n\n\n(\nreach_to_clicks_aud_plot <-  full_post  %>%\n    aud_plots() +\n  labs(title = \"By audience (reach, clicks, signups)\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n(\nreach_to_clicks_aud_plot_no_cause <-  full_post  %>%\n    filter(!str_det(theme, \"Animal|Climate|Poverty\"))  %>%\n        aud_plots() +\n labs(title = \"By audience, no cause videos\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n(\nreach_to_clicks_aud_plot_cause <-  full_post  %>%\n    filter(!str_det(theme, \"Animal|Climate|Poverty\"))  %>%\n        aud_plots() +\n labs(title = \"By audience, Cause videos only\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n\n\n\n\n(\nreach_to_clicks_aud_plot_no_cause <-  full_post  %>%\n    filter(audience!=\"Retargeting\" & str_det(theme, \"Animal|Climate|Poverty\"))  %>%\n    group_by(level, audience) %>% #, starts\n    sum_mean_hdi %>% \n    mutate(audience = reorder(as.factor(audience), `mean`)) %>% \n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = audience), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = audience),  height=.25, color = \"blue\") +\n  geom_point(\n    aes(x=`mean`, \n    y = audience)\n    ) +\n  labs(title = \"By audience: Reach to clicks, non-cause messages\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n\n\n(\nreach_to_clicks_plot<-  full_post  %>%\n    group_by(level, theme, audience) %>% #, starts\n    sum_mean_hdi %>% \n    filter(grepl(\"1\", level)) %>% \n    ggplot() + \n  geom_errorbarh(aes(xmin = lower, xmax = upper, y = theme)) +\n  geom_point(aes(x = mean, y = theme)) +\n  facet_wrap(~audience, scales = \"fixed\") +\n  labs(title = \"Reach to clicks\",\n       x = \"Estimated % clicking with 80% HDI\") +\n  facet_wrap(~audience, scales = \"fixed\")\n)\n\n\n(\nreach_to_clicks_plot <-  post_summary %>% \n    filter(grepl(\"1\", level)) %>% \n    filter(audience!=\"Retargeting\")  %>%\n    ggplot() + \n  geom_errorbarh(aes(xmin = lower, xmax = upper, y = theme)) +\n  geom_point(aes(x = mean, y = theme)) +\n  facet_wrap(~audience, scales = \"fixed\") +\n  labs(title = \"Reach to clicks\",\n       x = \"Estimated % clicking with 80% HDI\") +\n  facet_wrap(~audience, scales = \"fixed\")\n)\n\n\nError: <text>:93:0: unexpected end of input\n91: )\n92: \n   ^"
  },
  {
    "objectID": "chapters/gwwc_gg.html#bayesian-logistic-regressions-and-cis-from-jamies-work-in-fb-ad-analysis.r",
    "href": "chapters/gwwc_gg.html#bayesian-logistic-regressions-and-cis-from-jamies-work-in-fb-ad-analysis.r",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.10 Bayesian Logistic regressions and CIs – from Jamie’s work in fb ad analysis.R",
    "text": "1.10 Bayesian Logistic regressions and CIs – from Jamie’s work in fb ad analysis.R\ngoogle drive link\n\n\nCode\nlibrary(pacman)\np_load(brms, install=FALSE)\nlibrary(brms)\np_load(tidybayes, install=FALSE)\nlibrary(tidybayes)\n\n\n\n\nCode\nsum_results <- function(df) {\n    df %>%\n     summarise(\n    results = sum(results, na.rm = TRUE),\n    spend = sum(amount_spent_usd, na.rm = TRUE),\n    clicks = sum(link_clicks, na.rm = TRUE),\n    impressions = sum(impressions, na.rm = TRUE),\n    reach = sum(reach, na.rm = TRUE)\n  )\n}\n\n# collapse into the categories of interest\ngg_video_breakdowns_col <- gg_video_breakdowns %>%\n  group_by(video_theme, audience) %>%\n  #group_by(video_theme, audience, starts) %>%\nsum_results\n#%>%   mutate(starts = as.factor(starts))\n#rem: we are just summing outcomes, so no weights are needed here\n\n\n… checking some reasonable priors by looking at percentage conversion rate with different numbers\n\n\n\nCode\nclicks_per_reach_video_aud <- as.formula(\"clicks | trials(reach) ~ video_theme + audience + video_theme:audience\")\n\n# +  starts\nresults_per_click_video_aud <- as.formula(\"results | trials(clicks) ~ video_theme + audience + video_theme:audience\")\n\n## passing a list\narg.list <- list(init = 0, chains = 4, cores = 4, iter = 2500, warmup = 500, backend = \"cmdstanr\", seed = 1010, silent=2,  refresh = 0) \n\nclicks_logit_vid <-  do.call(\"brm\", c(list(data =gg_video_breakdowns_col, \n  formula = clicks_per_reach_video_aud,\n                  family = binomial(\"logit\"),\n                  control = list(adapt_delta = 0.99, max_treedepth = 15),\n                  prior = c(prior(normal(-3.5, 2), #DR: where do the priors come from?  \n                    class = Intercept),\n                            prior(normal(0, 1), class = b))),\n                  arg.list,                  \n  list(threads = threading(8)))\n)\n\n\nRunning MCMC with 4 parallel chains, with 8 thread(s) per chain...\n\nChain 1 finished in 3.4 seconds.\nChain 3 finished in 4.5 seconds.\nChain 4 finished in 4.7 seconds.\nChain 2 finished in 7.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 4.9 seconds.\nTotal execution time: 7.1 seconds.\n\n\nCode\nresults_logit_vid <-  do.call(\"brm\", c(list(data = gg_video_breakdowns_col, \n  formula = results_per_click_video_aud,\n                  family = binomial(\"logit\"),\n                  control = list(adapt_delta = 0.99, max_treedepth = 15),\n                  prior = c(prior(normal(-3.5, 2), #DR: where do the priors come from?  \n                    class = Intercept),\n                            prior(normal(0, 1), class = b))),\n                  arg.list,                  \n  list(threads = threading(8)))\n)\n\n\nRunning MCMC with 4 parallel chains, with 8 thread(s) per chain...\n\nChain 1 finished in 2.1 seconds.\nChain 2 finished in 2.1 seconds.\nChain 3 finished in 2.2 seconds.\nChain 4 finished in 2.9 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.3 seconds.\nTotal execution time: 3.0 seconds.\n\n\n\n\nCode\n# posterior expectations:\nfull_crossing <- expand_grid(\n  \"video_theme\" = unique(gg_video_breakdowns_col$video_theme),\n  \"audience\" = unique(gg_video_breakdowns_col$audience)) %>% \n  mutate(reach = 1,\n         clicks = 1) %>% \nfilter(!(audience==\"Animal\" & (video_theme == \"Climate\" | video_theme == \"Poverty\")))  %>%\n    filter(!(audience==\"Climate\" & (video_theme == \"Animal\" | video_theme == \"Poverty\")))  %>%\n    filter(!(audience==\"Global Poverty\" & (video_theme == \"Animal\" | video_theme == \"Climate\")))\n\n# setting reach/clicks = 1 will give us proportion of conversions (DR: why?)\n\nclick_post <- posterior_epred(clicks_logit_vid, ndraws = 1000, newdata = full_crossing)\nresults_post <- posterior_epred(results_logit_vid, ndraws = 1000, full_crossing)\n\ncombined_post <- click_post * results_post #DR: I guess we are multiplying the predicted probabilities of click and conversion here?\n\n\n\n\nCode\n#make tibbles of the stuff above, put it together s\n\npost_tib_clean <- function(df, name) {\n  df %>% \n    as.tibble() %>% \n    pivot_longer(cols = everything(),\n    names_to = \"identifier\",\n    values_to = \"probability\") %>%\n     mutate(level = name,\n       theme = rep(full_crossing$video_theme, 1000),\n       audience = rep(full_crossing$audience, 1000)\n       #     starts = rep(full_crossing$starts, 1000) #ÎR: I think I want starts (start date as a factor) in the model, because the audience may be systematically different on those days, and other things change we leave out here. However, I don't want to see it in the graphs. How to do that? \n     )\n}\n\n# make tibbles\ntib_click_post <- click_post %>% \n  post_tib_clean( \"1. Reach to clicks\")\n\ntib_result_post <- results_post  %>%\n    post_tib_clean(\"2. Clicks to signups\")\n\ntib_combined_post <- combined_post %>%\n      post_tib_clean(\"3. Total\") \n\nfull_post <- bind_rows(tib_click_post,\n                       tib_result_post,\n                       tib_combined_post)\n\n\n\n\nCode\nhdi <- HDInterval::hdi\n\nCI_choice_narrow <- 0.6\nCI_choice_wide <- 0.9\n\nsum_mean_hdi <- function(df) {\n  df %>% \n    summarise(mean = mean(probability) * 100,\n            lower_n = hdi(probability, credMass = CI_choice_narrow)[1] * 100,\n            upper_n = hdi(probability, credMass = CI_choice_narrow)[2] * 100,\n              lower_w = hdi(probability, credMass = CI_choice_wide)[1] * 100,\n            upper_w = hdi(probability, credMass = CI_choice_wide)[2] * 100)\n} \n  \n\npost_summary <- full_post %>% \n  group_by(level, theme, audience) %>% #, starts\n  sum_mean_hdi\n\n\n\n1.10.1 Results by audience\nWe ran two Bayesian Logit models, presented above. Results come out of a two-stage process: some people who see the ad click on it. Some of those who click on the ad leave their email (asking for a Giving Guide). We model clicks as a share of unique impressions (‘reach’) and results as a share of clicks, allowing each to vary by video theme and by audience. (Later: by text and by demographics.) The product of these shares (probabilities) yields results as a share of impressions, the main outcome of interest.\nBelow, we plot the point means (aka ‘coefficients’) and ‘highest density intervals’ (HDI) of our posterior beliefs for these. These models consider the audience and video themes at the same time, the imbalance between audiences and themes should probably not be a major biasing factor.\nCaveats:\n\nThe coefficients for the second stage (‘clicks to results’) should be taken lightly; as the audiences may be selected very different ‘conditional on click’; e.g., audiences that are ‘easy to click’ may by ‘harder to convert ot a result’.\nThe results presented below do not control for ‘which text treatment’ nor for ‘which campaign’. (We can do the latter next, but we can only do the former with the other version of the data, which is then missing some detail on who saw which video)\nThe usual ‘divergent delivery’ issue\n\n\n\nCode\naud_plots <- function(df) {\n  df %>% \n       filter(audience!=\"Retargeting\")  %>%\n    group_by(level, audience) %>% #, starts\n    sum_mean_hdi %>% \n    mutate(audience = reorder(as.factor(audience), `mean`)) %>% \n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = audience), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = audience),  height=.25, color = \"blue\") +\n  geom_point(\n    aes(x=`mean`, \n    y = audience))\n    } \n\n\n(\nreach_to_clicks_aud_plot <-  full_post  %>%\n    aud_plots() +\n  labs(title = \"By audience (reach, clicks, signups)\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n\n\n\n\nCode\n(\nreach_to_clicks_aud_plot_no_cause <-  full_post  %>%\n    filter(!str_det(theme, \"Animal|Climate|Poverty\"))  %>%\n        aud_plots() +\n labs(title = \"By audience, no cause videos\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n\n\n\n\nCode\n(\nreach_to_clicks_aud_plot_cause <-  full_post  %>%\n    filter(!str_det(theme, \"Animal|Climate|Poverty\"))  %>%\n        aud_plots() +\n labs(title = \"By audience, Cause videos only\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n\n)\n\n\n\n\n\n\n\n1.10.2 Results by Video\n\n\nCode\nvid_plots <- function(df) {\n  df %>% \n    group_by(level, theme) %>% #, starts\n    sum_mean_hdi %>% \n    mutate(theme = reorder(as.factor(theme), `mean`)) %>% \n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = theme), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = theme),  height=.25, color = \"blue\") +\n  geom_point(\n    aes(x=`mean`, \n    y = theme))\n    } \n\n\n(\nreach_to_clicks_vid_plot <-  full_post  %>%\n    vid_plots() +\n  labs(title = \"By theme (reach, clicks, signups)\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n\n\n\n\nCode\n(\nreach_to_clicks_vid_plot <-  full_post  %>%\n            filter(audience == \"Philanthropy\")  %>%\n    vid_plots() +\n  labs(title = \"By theme, 'philanthropy' audience only\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n\n\n\n\n\n\nCode\nreach_to_clicks_plot <-  full_post  %>%\n    group_by(level, theme) %>% #, starts\n    sum_mean_hdi %>% \n    filter(grepl(\"1\", level)) %>% \n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = theme)) +\n  geom_point(aes(x = mean, y = theme)) +\n  facet_wrap(~audience, scales = \"fixed\") +\n  labs(title = \"Conversions by video theme\",\n       x = \"Estimated % clicking with 80% HDI\") +\n  facet_wrap(~audience, scales = \"fixed\")\n\n\nreach_to_clicks_plot_phil_audience <-  post_summary %>% \n    filter(grepl(\"1\", level)) %>% \n    filter(audience!=\"Retargeting\")  %>%\n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = theme)) +\n  geom_point(aes(x = mean, y = theme)) +\n  facet_wrap(~audience, scales = \"fixed\") +\n  labs(title = \"Reach to clicks\",\n       x = \"Estimated % clicking with 80% HDI\") +\n  facet_wrap(~audience, scales = \"fixed\")"
  },
  {
    "objectID": "chapters/gwwc_gg.html#bayesian-logistic-regressions-and-cis",
    "href": "chapters/gwwc_gg.html#bayesian-logistic-regressions-and-cis",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.9 Bayesian Logistic regressions and CIs",
    "text": "1.9 Bayesian Logistic regressions and CIs\nThis comes from Jamie’s work in fb ad analysis.R\ngoogle drive link\n\n\nCode\nlibrary(pacman)\np_load(brms, install=FALSE)\nlibrary(brms)\np_load(tidybayes, install=FALSE)\nlibrary(tidybayes)\n\n\n\n\nCode\nsum_results <- function(df) {\n    df %>%\n     summarise(\n    results = sum(results, na.rm = TRUE),\n    spend = sum(amount_spent_usd, na.rm = TRUE),\n    clicks = sum(link_clicks, na.rm = TRUE),\n    impressions = sum(impressions, na.rm = TRUE),\n    reach = sum(reach, na.rm = TRUE)\n  )\n}\n\n# collapse into the categories of interest\ngg_video_breakdowns_col <- gg_video_breakdowns %>%\n  group_by(video_theme, audience) %>%\n  #group_by(video_theme, audience, starts) %>%\nsum_results\n#%>%   mutate(starts = as.factor(starts))\n#rem: we are just summing outcomes, so no weights are needed here\n\n\nIn the chunk below, we compute and set minimally informative priors for the click rates model.\n\n\nCode\n#helper function to 'make priors'\nmake_prior_normal <- function(mean, sd, ...) {\n  prior_string(paste0(\"normal(\", mean, \",\", sd, \")\"), ...)\n}\n\nprior_click_per_reach <- 0.028\n\nprior_intercept_click <-  logit(prior_click_per_reach)\n\nprior_intercept_click_ub <- 0.15\nse_prior_click <- (logit(prior_intercept_click_ub) - prior_intercept_click)/1.96\n\nprior_slope_click_ub <- 0.25\nse_prior_slope_click <- (logit(prior_slope_click_ub) - prior_intercept_click)/1.96\n\nprior_click <- c(\n  make_prior_normal(prior_intercept_click, se_prior_click, class = \"Intercept\"),\nmake_prior_normal(0, se_prior_slope_click, class = \"b\")\n)\n\n#DR @Jamie: This is a log ratio of probabilities, iirc. Why are we assuming it is normally distributed? \n\n\n\n\n\n\n\n\nDetermining appropriate priors for click rates - intercept\n\n\n\n\n\nIn the code chunk just above, we define the priors which we use below.\nWhere did this come from? It is somewhat casual, but given the very large dataset, we don’t expect our results to be very sensitive to the priors.\nA 0.028 click rate (as a share of ‘reach’) seemed like a reasonable mean. This is approximately the rate GWWC saw in all of its trials before February 2021, when this trial started. logit(prior_click_per_reach) gives us the intercept associated with this prior expected outcome rate.\nThe prior on the standard error for the intercept is not based on prior data. We considered ‘what baseline rate would we consider to be extremely unlikely?’, and set the standard deviations to be about half of this (recalling that 95% of the area of a normal distribution is within 1.96 sd’s of the mean) . In the positive direction, a rate of 15% or more would be truly shocking. This would yield a logit intercept of logit(prior_intercept_click_ub) = -1.7346011. Differencing this from the prior mean and dividing by two yields our chosen prior intercept standard error: 0.925; note this gives a 95 percent lower-bound of a 0.468% click rate.\n\n\n\n\n\n\n\n\n\nDetermining appropriate priors for click rates - coefficients\n\n\n\n\n\nIn determining priors for the slopes (adjustments for different groups), we start with a mean expected slope of 0; this is consistent with a sort of ‘unbiased’ prior, not loading the dice in either direction, and also most adaptable to a range of groups we might consider. We again considered ‘what mean click rates would be very surprising’. A click rate of 25% of more for any targeted subgroup or treatment would be very unexpected – this seems conservative. By similar calculations above, this yields se_prior_slope_click = 1.2492546.\nCould we instead do this considering reasonable ‘proportional differences in rates’? We will consider this for future work (possible challenge: it may interact with the intercepts).\n\n\n\nIn the chunk below, we compute and set minimally informative priors for the results model. Again, some notes follow.\n\n\nCode\nprior_results_per_click <- 0.20\n\nprior_intercept_results <-  logit(prior_results_per_click)\n\nprior_intercept_results_ub <- 0.75\nse_prior_results <- (logit(prior_intercept_results_ub) - prior_intercept_results)/1.96\n\nprior_slope_results_ub <- 0.85\nse_prior_slope_results <- (logit(prior_slope_results_ub) - prior_intercept_results)/1.96\n\nprior_results <- c(\n  make_prior_normal(prior_intercept_results, se_prior_results, class = \"Intercept\"),\nmake_prior_normal(0, se_prior_slope_results, class = \"b\")\n)\n\n\n\n\n\n\n\n\nDetermining appropriate priors for results (per click)\n\n\n\n\n\nSee the above discussion folds on priors for clicks for our general approach.\nFor results per click (RpC), we had very little data or experience to go on. The little prior data GWWC had on results per click were from very different contexts, e.g., RSVPs for attending events rather than simply leaving an email. In those cases results per click are (as we expect, are results per click for Facebook ads are in general). However, here people are clicking on a call to action like ‘Download the Effective Giving Guide’, directing them to a site where they merely need to leave their email to download this guide. Thus, if the clicks are intentional, a much higher rate of ‘result’ seems reasonable. Thus we compromised on a 20% ‘results per click’ rate as our overall prior mean.\nWe would be ‘very surprised’ (seems 5% likely or less) with an RpC of over 75% overall or 85% for any subgroup – we derive the standard errors of the intercept and slope from these, as for clicks.\n(Note: this implies a 95% CI lower-bound of a 2.04% overall RpC rate.)\n\n\n\n\n1.9.1 Estimating the models\n\n\nCode\nclicks_per_reach_video_aud <- as.formula(\"clicks | trials(reach) ~ video_theme + audience + video_theme:audience\")\n\n# +  starts\nresults_per_click_video_aud <- as.formula(\"results | trials(clicks) ~ video_theme + audience + video_theme:audience\")\n\n## passing a list\narg.list <- list(init = 0, chains = 4, cores = 4, iter = 2500, warmup = 500, backend = \"cmdstanr\", seed = 1010, silent=2,  refresh = 0) \n\nclicks_logit_vid <-  do.call(\"brm\", c(list(\n  data =gg_video_breakdowns_col, \n  formula = clicks_per_reach_video_aud,\n                  family = binomial(\"logit\"),\n                  control = list(adapt_delta = 0.99, max_treedepth = 15),\n                   prior = prior_click),\n                  arg.list,                  \n  list(threads = threading(8)))\n)\n\n\nRunning MCMC with 4 parallel chains, with 8 thread(s) per chain...\n\nChain 2 finished in 4.7 seconds.\nChain 1 finished in 4.8 seconds.\nChain 4 finished in 5.5 seconds.\nChain 3 finished in 8.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 5.8 seconds.\nTotal execution time: 8.2 seconds.\n\n\nCode\nresults_logit_vid <-  do.call(\"brm\", c(list(\n  data = gg_video_breakdowns_col, \n  formula = results_per_click_video_aud,\n                  family = binomial(\"logit\"),\n                  control = list(adapt_delta = 0.99, max_treedepth = 15),\n                  prior = prior_results),\n                  arg.list,                  \n  list(threads = threading(8)))\n)\n\n\nRunning MCMC with 4 parallel chains, with 8 thread(s) per chain...\n\nChain 1 finished in 2.6 seconds.\nChain 2 finished in 2.7 seconds.\nChain 3 finished in 2.9 seconds.\nChain 4 finished in 3.8 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 3.0 seconds.\nTotal execution time: 3.9 seconds.\n\n\n\n\n1.9.2 (To do) Summarize the model results/coefficients in clean tables here\n\n\n1.9.3 Forest plots\n\n\nCode\n# posterior expectations:\nfull_crossing <- expand_grid(\n  \"video_theme\" = unique(gg_video_breakdowns_col$video_theme),\n  \"audience\" = unique(gg_video_breakdowns_col$audience)) %>% \n  mutate(reach = 1, #it is estimating the number of clicks based on the reach\n         clicks = 1) %>% \nfilter(!(audience==\"Animal\" & (video_theme == \"Climate\" | video_theme == \"Poverty\")))  %>%\n    filter(!(audience==\"Climate\" & (video_theme == \"Animal\" | video_theme == \"Poverty\")))  %>%\n    filter(!(audience==\"Global Poverty\" & (video_theme == \"Animal\" | video_theme == \"Climate\"))) #remove combinations where we don't have data ... at least for now\n\n# setting reach and clicks = 1 will give us proportion of conversions (because it makes a prediction for total outcomes per unit )\n\nclick_post <- posterior_epred(clicks_logit_vid, newdata = full_crossing) #ndraws = 1000, \nresults_post <- posterior_epred(results_logit_vid, full_crossing)\n\ncombined_post <- click_post * results_post #DR: multiplying the predicted probabilities of click and conversion here?\n\n\n\n\nCode\n#make tibbles of the stuff above, put it together s\n\npost_tib_clean <- function(df, name) {\n  data <- df %>% \n    as.tibble() %>% \n    pivot_longer(cols = everything(),\n    names_to = \"identifier\",\n    values_to = \"probability\") \n  data <- data %>% \n     mutate(level = name,\n       theme = rep(full_crossing$video_theme, dim(data)[1]/dim(full_crossing)[1]),\n       audience = rep(full_crossing$audience,  dim(data)[1]/dim(full_crossing)[1])\n       #     starts = rep(full_crossing$starts, 1000) #DR: I think I want starts (start date as a factor) in the model, because the audience may be systematically different on those days, and other things change we leave out here. However, I don't want to see it in the graphs. How to do that? \n     )\n  return(data)\n}\n\n# make tibbles\ntib_click_post <- click_post %>% \n  post_tib_clean( \"1. Reach to clicks\")\n\ntib_result_post <- results_post  %>%\n    post_tib_clean(\"2. Clicks to signups\")\n\ntib_combined_post <- combined_post %>%\n      post_tib_clean(\"3. Total\") \n\nfull_post <- bind_rows(tib_click_post,\n                       tib_result_post,\n                       tib_combined_post)\n\n\n\n\nCode\nhdi <- HDInterval::hdi\n\nCI_choice_narrow <- 0.6\nCI_choice_wide <- 0.9\n\nsum_mean_hdi <- function(\n    df, \n  var = probability, scaleme=100, CI_choice_n=CI_choice_narrow, CI_choice_w = CI_choice_wide) {\n  df %>% \n    summarise(\n      mean = mean({{var}}) * scaleme,\n            lower_n = hdi({{var}}, credMass = CI_choice_n)[1] * scaleme,\n            upper_n = hdi({{var}}, credMass = CI_choice_n)[2] * scaleme,\n              lower_w = hdi({{var}}, credMass = CI_choice_w)[1] * scaleme,\n            upper_w = hdi({{var}}, credMass = CI_choice_w)[2] * scaleme,\n          lower_eti = quantile({{var}}, (1-CI_choice_w)/2) * scaleme,\n    upper_eti = quantile({{var}}, 1-(1-CI_choice_w)/2) * scaleme,\n      check = length(hdi({{var}}))\n    )\n} \n\n\nmutate_mean_hdi <- function(\n    df, \n  var = probability, scaleme=100, CI_choice_n=CI_choice_narrow, CI_choice_w = CI_choice_wide) {\n  df %>% \n    dplyr::mutate(\n      mean = mean({{var}}) * scaleme,\n            lower_n = hdi({{var}}, credMass = CI_choice_n)[1] * scaleme,\n            upper_n = hdi({{var}}, credMass = CI_choice_n)[2] * scaleme,\n              lower_w = hdi({{var}}, credMass = CI_choice_wide)[1] * scaleme,\n            upper_w = hdi({{var}}, credMass = CI_choice_wide)[2] * scaleme,\n          lower_eti = quantile({{var}}, (1-CI_choice_wide)/2) * scaleme,\n    upper_eti = quantile({{var}}, 1-(1-CI_choice_wide)/2) * scaleme,\n      check = length(hdi({{var}}))\n    )\n} \n\n\n\nResults by audience\nWe ran two Bayesian Logit models, presented above. Results come out of a two-stage process: some people who see the ad click on it. Some of those who click on the ad leave their email (asking for a Giving Guide). We model clicks as a share of unique impressions (‘reach’) and results as a share of clicks, allowing each to vary by video theme and by audience. (Later: by text and by demographics.) The product of these shares (probabilities) yields results as a share of impressions, the main outcome of interest.\nBelow, we plot the point means (aka ‘coefficients’) and ‘highest density intervals’ (HDI) of our posterior beliefs for these. These models consider the audience and video themes at the same time, the imbalance between audiences and themes should probably not be a major biasing factor.\nCaveats:\n\nThe coefficients for the second stage (‘clicks to results’) should be taken lightly; as the audiences may be selected very different ‘conditional on click’; e.g., audiences that are ‘easy to click’ may by ‘harder to convert ot a result’.\nThe results presented below do not control for ‘which text treatment’ nor for ‘which campaign’. (We can do the latter next, but we can only do the former with the other version of the data, which is then missing some detail on who saw which video)\nThe usual ‘divergent delivery’ issue\n\n\n\nCode\naud_plots <- function(df) {\n  df %>% \n       filter(audience!=\"Retargeting\")  %>%\n    group_by(level, audience) %>% #, starts\n    sum_mean_hdi %>% \n    mutate(audience = reorder(as.factor(audience), `mean`)) %>% \n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = audience), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = audience),  height=.25, color = \"blue\") +\n  geom_point(\n    aes(x=`mean`, \n    y = audience))\n    } \n\n\n(\nreach_to_clicks_aud_plot <-  full_post  %>%\n    aud_plots() +\n  labs(title = \"By audience (reach, clicks, signups)\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n\n\n\n\nCode\n(\nreach_to_clicks_aud_plot_no_cause <-  full_post  %>%\n    filter(!str_det(theme, \"Animal|Climate|Poverty\"))  %>%\n        aud_plots() +\n labs(title = \"By audience, no cause videos\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n\n\n\n\nCode\n(\nreach_to_clicks_aud_plot_cause <-  full_post  %>%\n    filter(str_det(theme, \"Animal|Climate|Poverty\"))  %>%\n        aud_plots() +\n labs(title = \"By audience, Cause videos only\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n\n)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote: the ‘pooled’ graphs in this section may not be correctly weighted across subcategories. We need to reexamine this.\n\n\nFor the ‘cause videos only’ we see (todo: doublecheck after final estimates) that the philanthropy audience, across all causes, seems to perform at least as well as the climate and ‘global poverty’ audiences (when the latter are presented videos for the causes they are said to care about). However, the animal audiences seems to perform substantially better.\nFor example, focusing on climate-cause videos (and removing ‘lookalikes’) below, we see that the philanthropy audience performs substantially better than the climate audience.\n\n\nCode\n(\nreach_to_clicks_aud_plot_climate <-  full_post  %>%\n    filter(str_det(theme, \"Climate\"))  %>%\n    filter(audience!=\"Lookalikes\") %>% \n        aud_plots() +\n labs(title = \"By audience, Climate videos only\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n\n)\n\n\n\n\n\n\n\n\n1.9.4 Results by Video (todo: fix weighting)\n\n\nCode\nvid_plots <- function(df) {\n  df %>% \n    group_by(level, theme) %>% #, starts\n    sum_mean_hdi %>% \n    mutate(theme = reorder(as.factor(theme), `mean`)) %>% \n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = theme), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = theme),  height=.25, color = \"blue\") +\n  geom_point(\n    aes(x=`mean`, \n    y = theme))\n    } \n\n(\nreach_to_clicks_vid_plot <-  full_post  %>%\n    vid_plots() +\n  labs(title = \"By theme (reach, clicks, signups)\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n\n\n\n\nCode\n(\nreach_to_clicks_vid_plot_phil <-  full_post  %>%\n            filter(audience == \"Philanthropy\")  %>%\n    vid_plots() +\n  labs(title = \"By theme, 'philanthropy' audience only\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n\n\n\n\n\n\nCode\n(\nreach_to_clicks_plot <-  full_post  %>%\n      filter(grepl(\"1\", level)) %>% \n    group_by(theme, audience) %>% #, starts\n    sum_mean_hdi %>% \n      mutate(theme = reorder(as.factor(theme), `mean`)) %>% \n      filter(audience!=\"Retargeting\")  %>%\n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = theme), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = theme),  height=.25, color = \"blue\") +\n  geom_point(aes(x = mean, y = theme)) +\n  coord_cartesian(xlim=c(0, 1.75)) +\n  facet_wrap(~audience, scales = \"fixed\") +\n  labs(title = \"Clicks by video theme and audience\",\n       x = \"Estimated % clicking with 60% and 90% HDIs\") +\n  facet_wrap(~audience, scales = \"fixed\")\n)\n\n\n\n\n\nCode\n(\nreach_to_results_plot <-  full_post %>% \n      filter(grepl(\"3\", level)) %>% \n      group_by(theme, audience) %>% #, startslevel, \n      sum_mean_hdi %>% \n        mutate(theme = reorder(as.factor(theme), `mean`)) %>% \n      filter(audience!=\"Retargeting\")  %>%\n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = theme), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = theme),  height=.25, color = \"blue\") +  geom_point(aes(x = mean, y = theme)) +\n  facet_wrap(~audience, scales = \"fixed\") +\n    coord_cartesian(xlim=c(0, 0.8)) +\n  labs(title = \"Reach to results (total)\",\n       x = \"Estimated % results with 60% and 90% HDIs\") +\n  facet_wrap(~factor(audience, levels=audience_levels), scales = \"fixed\")\n)\n\n\n\n\n\nCode\n(\nreach_to_results_plot_flip <-  full_post %>% \n      filter(grepl(\"3\", level)) %>% \n      group_by(audience, theme) %>% #, startslevel, \n      sum_mean_hdi %>% \n        mutate(audience = reorder(as.factor(audience), `mean`)) %>% \n      filter(audience!=\"Retargeting\")  %>%\n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = audience), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = audience),  height=.25, color = \"blue\") +  geom_point(aes(x = mean, y = audience)) +\n  facet_wrap(~audience, scales = \"fixed\") +\n    coord_cartesian(xlim=c(0, 0.8)) +\n  labs(title = \"Reach to results (total)\",\n       x = \"Estimated % results with 60% and 90% HDIs\") +\n  facet_wrap(~theme, scales = \"fixed\")\n)\n\n\n\n\n\n\n\n1.9.5 Outcomes by cost\n\n\nCode\n# Joining spending and conversion ####\n\ncost_tibble <- \n  left_join(tib_combined_post,\n    rename(gg_video_breakdowns_col, theme=video_theme)) %>% \n  mutate(\n    reach_per_dollar = reach / spend,\n    sign_per_dollar = reach_per_dollar * probability,\n    #NOTE this uses the simulated distribution of probabilities, not just averages! \n    sign_per_100d = 100*sign_per_dollar,\n    cost_per_signup = 1/sign_per_dollar\n    ) %>% \n  filter(is.na(spend) == FALSE)  \n\ncost_summary <- cost_tibble %>% \n  group_by(theme, audience) %>% \n  sum_mean_hdi(var= sign_per_100d, scaleme=1)\n\n#dim(filter(cost_summary, check > 2))[1] ... where HDI is not continuous, I guess... this doesn't happen here atm\n\n\n\n\nCode\n(\n  sign_per_100d_plot_vid_by_aud <- cost_tibble %>%\n      filter(audience!=\"Retargeting\")  %>%\nggplot() +\n  scale_x_continuous(limits = c(0, 20)) +\n  ggridges::geom_density_ridges(\n    aes(\n      x = sign_per_100d, \n      y = theme\n      )\n    ) +\n  geom_point(data = cost_summary %>% filter(audience!=\"Retargeting\"), \n    aes(x = mean, y = theme)) +\n  labs(title = \"Signups per $100: Comparing videos by audience\",\n    x = \"Density plots, means\") +\n  facet_wrap(~factor(audience, levels = audience_levels), scales = \"free_x\"  )\n)\n\n\n\n\n\nCode\n# \n# ggplot(filter(cost_tibble, upper_eti < 100)) +\n#   geom_errorbarh(aes(xmin = lower_eti, xmax = upper_eti, y = audience)) +\n#   geom_point(aes(x = mean, y = audience)) +\n#   labs(title = \"Cost per signup ($)\",\n#     x = \"Estimated cost per signup (USD) with 95% ETI\") +\n#   facet_wrap(~theme, scales = \"free_x\")\n\n\nAbove we consider the cost effectiveness of each video by audience.\n‘Factual short’: 16 This video seems to perform as good or better than any other video for each of the cause audiences as well as for the Lookalike audience (but see cav eat). It performs nearly as good as other videos for the other audiences.\nClimate video: This seems to have performed best for the Philanthropy and General audiences, although the distribution is diffuse. Surprisingly, it does not perform best for the climate audience.\nHypercube, Factual Long: These seemed to have performed worst or near-worst for most audiences. ‘Factual long’ seems to have clearly performed worse than ‘Factual short’ version. (But see caveat below.)\n\n\n\n\n\n\nCaveat/todo – Video/campaign date imbalance\n\n\n\n\n\nThere is substantial imbalance in dates the administration of treatments in the pooled data. E.g., the ‘Factual short’ video was the only one shown for the 2021-12-08 trial, which may confound the above result. The Hypercube video was only shown in a single trial, where it was the only video shown. The ‘Factual long’ video was dropped in later trials (?possibly after poor performance in an explicit A/B test?). Again, confounds are certainly possible. We may want to either remove trials from dates that only ran a single trial (at a first pass), or include start date/campaign into our modeling.\n\n\n\n\n\nCode\n(\n  sign_per_100d_plot_aud_by_vid <- cost_tibble %>%\n      filter(audience!=\"Retargeting\" & audience!=\"General audience\")  %>%\nggplot() +\n  scale_x_continuous(limits = c(0, 20)) +\n  ggridges::geom_density_ridges(\n    aes(\n      x = sign_per_100d, \n      y = audience\n      )\n    ) +\n  geom_point(data = cost_summary %>% filter(audience!=\"Retargeting\" & audience!=\"General audience\"), \n    aes(x = mean, y = audience)) +\n  labs(title = \"Signups per $100: Comparing audiences for each video\",\n    x = \"Density plots, means\") +\n  facet_wrap(~theme, scales = \"free_x\")\n)\n\n\n\n\n\nFlipping the previous plot, we compare the cost-effectiveness of each audience for each video.[Again hard-coding here…][Note that the audience-imbalance caveat still applies. We removed the ‘General Audience’ here, as this was only used for the final trial, and this seems particularly non-comparable.]\nThe Lookalike audiences are relatively cost-effective for most videos, although the Philanthropy audience seems to do better per dollar for the Climate video.\nThe cause audiences are relatively cost-effective for their ‘own’ videos, but not overwhelmingly so. They seemed particularly cost-ineffective for the Hypercube video."
  },
  {
    "objectID": "chapters/gwwc_gg.html#caveattodo-videocampaign-date-imbalance",
    "href": "chapters/gwwc_gg.html#caveattodo-videocampaign-date-imbalance",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.10 Caveat/todo – Video/campaign date imbalance",
    "text": "1.10 Caveat/todo – Video/campaign date imbalance\nThere is substantial imbalance in dates the administration of treatments in the pooled data. E.g., the ‘Factual short’ video was the only one shown for the 2021-12-08 trial, which may confound the above result. The Hypercube video was only shown in a single trial, where it was the only video shown. The ‘Factual long’ video was dropped in later trials (?possibly after poor performance in an explicit A/B test?). Again, confounds are certainly possible. We may want to either remove trials from dates that only ran a single trial (at a first pass), or include start date/campaign into our modeling.\n::\n\n\nCode\n(\n  sign_per_100d_plot_aud_by_vid <- cost_tibble %>%\n      filter(audience!=\"Retargeting\" & audience!=\"General audience\")  %>%\nggplot() +\n  scale_x_continuous(limits = c(0, 20)) +\n  ggridges::geom_density_ridges(\n    aes(\n      x = sign_per_100d, \n      y = audience\n      )\n    ) +\n  geom_point(data = cost_summary %>% filter(audience!=\"Retargeting\" & audience!=\"General audience\"), \n    aes(x = mean, y = audience)) +\n  labs(title = \"Signups per $100: Comparing audiences for each video\",\n    x = \"Density plots, means\") +\n  facet_wrap(~theme, scales = \"free_x\")\n)\n\n\nError in filter(., audience != \"Retargeting\" & audience != \"General audience\"): object 'cost_tibble' not found\n\n\nFlipping the previous plot, we compare the cost-effectiveness of each audience for each video.[Again hard-coding here…][Note that the audience-imbalance caveat still applies. We removed the ‘General Audience’ here, as this was only used for the final trial, and this seems particularly non-comparable.]\nThe Lookalike audiences are relatively cost-effective for most videos, although the Philanthropy audience seems to do better per dollar for the Climate video.\nThe cause audiences are relatively cost-effective for their ‘own’ videos, but not overwhelmingly so. They seemed particularly cost-ineffective for the Hypercube video."
  },
  {
    "objectID": "chapters/gwwc_gg.html#modeling-and-simulation",
    "href": "chapters/gwwc_gg.html#modeling-and-simulation",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.5 Modeling and simulation",
    "text": "1.5 Modeling and simulation\nDiscussion moved to separate file modeling_fb_discussion.qmd"
  },
  {
    "objectID": "chapters/gwwc_gg.html#modeling-bayesian-logistic-regressions-and-cis",
    "href": "chapters/gwwc_gg.html#modeling-bayesian-logistic-regressions-and-cis",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.6 Modeling: Bayesian Logistic regressions and CIs",
    "text": "1.6 Modeling: Bayesian Logistic regressions and CIs\n14\n\n\nCode\nlibrary(pacman)\np_load(brms, install=FALSE)\nlibrary(brms)\np_load(tidybayes, install=FALSE)\nlibrary(tidybayes)\n\n\n\n\nCode\nsum_results <- function(df) {\n    df %>%\n     summarise(\n    results = sum(results, na.rm = TRUE),\n    spend = sum(amount_spent_usd, na.rm = TRUE),\n    clicks = sum(link_clicks, na.rm = TRUE),\n    impressions = sum(impressions, na.rm = TRUE),\n    reach = sum(reach, na.rm = TRUE)\n  )\n}\n\n# collapse into the categories of interest\ngg_video_breakdowns_col <- gg_video_breakdowns %>%\n  group_by(video_theme, audience) %>%\n  #group_by(video_theme, audience, starts) %>%\nsum_results\n#%>%   mutate(starts = as.factor(starts))\n#rem: we are just summing outcomes, so no weights are needed here\n\ngg_video_breakdowns_col_mix <- gg_video_breakdowns %>%\n  group_by(video_theme, audience, starts) %>%\n  #group_by(video_theme, audience, starts) %>%\nsum_results\n#%>%   mutate(starts = as.factor(starts))\n#rem: we are just summing outcomes, so no weights are needed here\n\n\nIn the chunk below, we compute and set minimally informative priors for the click rates model.\n\n\nCode\n#helper function to 'make priors'\nmake_prior_normal <- function(mean, sd, ...) {\n  prior_string(paste0(\"normal(\", mean, \",\", sd, \")\"), ...)\n}\n\nprior_click_per_reach <- 0.028\n\nprior_intercept_click <-  logit(prior_click_per_reach)\n\nprior_intercept_click_ub <- 0.15\nse_prior_click <- (logit(prior_intercept_click_ub) - prior_intercept_click)/1.96\n\nprior_slope_click_ub <- 0.25\nse_prior_slope_click <- (logit(prior_slope_click_ub) - prior_intercept_click)/1.96\n\nprior_click <- c(\n  make_prior_normal(prior_intercept_click, se_prior_click, class = \"Intercept\"),\nmake_prior_normal(0, se_prior_slope_click, class = \"b\")\n)\n\n#DR @Jamie: This is a log ratio of probabilities, iirc. Why are we assuming it is normally distributed? \n\n\n\n\n\n\n\n\nDetermining appropriate priors for click rates - intercept\n\n\n\n\n\nIn the code chunk just above, we define the priors which we use below.\nWhere did this come from? It is somewhat casual, but given the very large dataset, we don’t expect our results to be very sensitive to the priors.\nA 0.028 click rate (as a share of ‘reach’) seemed like a reasonable mean. This is approximately the rate GWWC saw in all of its trials before February 2021, when this trial started. logit(prior_click_per_reach) gives us the intercept associated with this prior expected outcome rate.\nThe prior on the standard error for the intercept is not based on prior data. We considered ‘what baseline rate would we consider to be extremely unlikely?’, and set the standard deviations to be about half of this (recalling that 95% of the area of a normal distribution is within 1.96 sd’s of the mean) . In the positive direction, a rate of 15% or more would be truly shocking. This would yield a logit intercept of logit(prior_intercept_click_ub) = -1.7346011. Differencing this from the prior mean and dividing by two yields our chosen prior intercept standard error: 0.925; note this gives a 95 percent lower-bound of a 0.468% click rate.\n\n\n\n\n\n\n\n\n\nDetermining appropriate priors for click rates - coefficients\n\n\n\n\n\nIn determining priors for the slopes (adjustments for different groups), we start with a mean expected slope of 0; this is consistent with a sort of ‘unbiased’ prior, not loading the dice in either direction, and also most adaptable to a range of groups we might consider. We again considered ‘what mean click rates would be very surprising’. A click rate of 25% of more for any targeted subgroup or treatment would be very unexpected – this seems conservative. By similar calculations above, this yields se_prior_slope_click = 1.2492546.\nCould we instead do this considering reasonable ‘proportional differences in rates’? We will consider this for future work (possible challenge: it may interact with the intercepts).\n\n\n\nIn the chunk below, we compute and set minimally informative priors for the results model. Again, some notes follow.\n\n\nCode\nprior_results_per_click <- 0.20\n\nprior_intercept_results <-  logit(prior_results_per_click)\n\nprior_intercept_results_ub <- 0.75\nse_prior_results <- (logit(prior_intercept_results_ub) - prior_intercept_results)/1.96\n\nprior_slope_results_ub <- 0.85\nse_prior_slope_results <- (logit(prior_slope_results_ub) - prior_intercept_results)/1.96\n\nprior_results <- c(\n  make_prior_normal(prior_intercept_results, se_prior_results, class = \"Intercept\"),\nmake_prior_normal(0, se_prior_slope_results, class = \"b\")\n)\n\n\n\n\n\n\n\n\nDetermining appropriate priors for results (per click)\n\n\n\n\n\nSee the above discussion folds on priors for clicks for our general approach.\nFor results per click (RpC), we had very little data or experience to go on. The little prior data GWWC had on results per click were from very different contexts, e.g., RSVPs for attending events rather than simply leaving an email. In those cases results per click are (as we expect, are results per click for Facebook ads are in general). However, here people are clicking on a call to action like ‘Download the Effective Giving Guide’, directing them to a site where they merely need to leave their email to download this guide. Thus, if the clicks are intentional, a much higher rate of ‘result’ seems reasonable. Thus we compromised on a 20% ‘results per click’ rate as our overall prior mean.\nWe would be ‘very surprised’ (seems 5% likely or less) with an RpC of over 75% overall or 85% for any subgroup – we derive the standard errors of the intercept and slope from these, as for clicks.\n(Note: this implies a 95% CI lower-bound of a 2.04% overall RpC rate.)\n\n\n\n\n1.6.1 Estimating the models\n\n\nCode\n#| output: false\n\n\nclicks_per_reach_video_aud <- as.formula(\"clicks | trials(reach) ~ video_theme + audience + video_theme:audience\")\n\n# +  starts\nresults_per_click_video_aud <- as.formula(\"results | trials(clicks) ~ video_theme + audience + video_theme:audience\")\n\n#  For comparison: a one-step model \nresults_per_reach_video_aud <- as.formula(\"results | trials(reach) ~ video_theme + audience + (video_theme|audience)\")\n\n#  Fuller, mixed model \n# results_per_reach_video_aud_mix <- as.formula(\"results | trials(reach) ~ (1|starts) + video_theme + audience + (video_theme | audience) + (video_theme:audience)\")\n\n\n\n\nCode\n#| output: false\n\n\n## passing a list\narg.list <- list(init = 0, chains = 4, cores = 4, iter = 2500, warmup = 500, backend = \"cmdstanr\", seed = 1010, silent=2,  refresh = 0) \n\nclicks_logit_vid <-  do.call(\"brm\", c(list(\n  data =gg_video_breakdowns_col, \n  formula = clicks_per_reach_video_aud,\n                  family = binomial(\"logit\"),\n                  control = list(adapt_delta = 0.99, max_treedepth = 15),\n                   prior = prior_click),\n                  arg.list,                  \n  list(threads = threading(8)))\n)\n\n\nRunning MCMC with 4 parallel chains, with 8 thread(s) per chain...\n\nChain 2 finished in 4.6 seconds.\nChain 1 finished in 4.7 seconds.\nChain 4 finished in 5.4 seconds.\nChain 3 finished in 7.9 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 5.7 seconds.\nTotal execution time: 8.1 seconds.\n\n\nCode\nresults_logit_vid <-  do.call(\"brm\", c(list(\n  data = gg_video_breakdowns_col, \n  formula = results_per_click_video_aud,\n                  family = binomial(\"logit\"),\n                  control = list(adapt_delta = 0.99, max_treedepth = 15),\n                  prior = prior_results),\n                  arg.list,                  \n  list(threads = threading(8)))\n)\n\n\nRunning MCMC with 4 parallel chains, with 8 thread(s) per chain...\n\nChain 1 finished in 2.6 seconds.\nChain 2 finished in 2.6 seconds.\nChain 3 finished in 2.9 seconds.\nChain 4 finished in 3.7 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.9 seconds.\nTotal execution time: 3.8 seconds.\n\n\nCode\nresults_per_reach_logit_vid <-  do.call(\"brm\", c(list(\n  data = gg_video_breakdowns_col, \n  formula = results_per_reach_video_aud,\n                  family = binomial(\"logit\"),\n                  control = list(adapt_delta = 0.99, max_treedepth = 15),\n                  prior = prior_results),\n                  arg.list,                  \n  list(threads = threading(8)))\n)\n\n\nRunning MCMC with 4 parallel chains, with 8 thread(s) per chain...\n\nChain 3 finished in 20.2 seconds.\nChain 2 finished in 21.1 seconds.\nChain 1 finished in 23.2 seconds.\nChain 4 finished in 33.5 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 24.5 seconds.\nTotal execution time: 33.6 seconds.\n\n\nCode\n# rpi_logit_mix_vid <-  do.call(\"brm\", c(list(\n#   data = gg_video_breakdowns_col_mix, \n#   formula = results_per_reach_video_aud_mix,\n#                   family = binomial(\"logit\"),\n#                   control = list(adapt_delta = 0.99, max_treedepth = 15),\n#                   prior = prior_results),\n#                   arg.list,                  \n#   list(threads = threading(8)))\n# )\n\n\n\n\n1.6.2 (To do) Summarize the model results/coefficients in clean tables here\n\n\n1.6.3 Forest plots\n\n\nCode\n# posterior expectations:\nfull_crossing <- expand_grid(\n  \"video_theme\" = unique(gg_video_breakdowns_col$video_theme),\n  \"audience\" = unique(gg_video_breakdowns_col$audience)) %>% \n  mutate(reach = 1, #it is estimating the number of clicks based on the reach\n         clicks = 1) %>% \nfilter(!(audience==\"Animal\" & (video_theme == \"Climate\" | video_theme == \"Poverty\")))  %>%\n    filter(!(audience==\"Climate\" & (video_theme == \"Animal\" | video_theme == \"Poverty\")))  %>%\n    filter(!(audience==\"Global Poverty\" & (video_theme == \"Animal\" | video_theme == \"Climate\"))) #remove combinations where we don't have data ... at least for now\n\n# setting reach and clicks = 1 will give us proportion of conversions (because it makes a prediction for total outcomes per unit )\n\nclick_post <- posterior_epred(clicks_logit_vid, newdata = full_crossing) #ndraws = 1000, \nresults_post <- posterior_epred(results_logit_vid, full_crossing)\n\ncombined_post <- click_post * results_post #DR: multiplying the predicted probabilities of click and conversion here?\n\n\n\n\nCode\n#make tibbles of the stuff above, put it together s\n\npost_tib_clean <- function(df, name) {\n  data <- df %>% \n    as.tibble() %>% \n    pivot_longer(cols = everything(),\n    names_to = \"identifier\",\n    values_to = \"probability\") \n  data <- data %>% \n     mutate(level = name,\n       theme = rep(full_crossing$video_theme, dim(data)[1]/dim(full_crossing)[1]),\n       audience = rep(full_crossing$audience,  dim(data)[1]/dim(full_crossing)[1])\n       #     starts = rep(full_crossing$starts, 1000) #DR: I think I want starts (start date as a factor) in the model, because the audience may be systematically different on those days, and other things change we leave out here. However, I don't want to see it in the graphs. How to do that? \n     )\n  return(data)\n}\n\n# make tibbles\ntib_click_post <- click_post %>% \n  post_tib_clean( \"1. Reach to clicks\")\n\ntib_result_post <- results_post  %>%\n    post_tib_clean(\"2. Clicks to signups\")\n\ntib_combined_post <- combined_post %>%\n      post_tib_clean(\"3. Total\") \n\nfull_post <- bind_rows(tib_click_post,\n                       tib_result_post,\n                       tib_combined_post)\n\n\n\n\nCode\nhdi <- HDInterval::hdi\n\nCI_choice_narrow <- 0.6\nCI_choice_wide <- 0.9\n\nsum_mean_hdi <- function(\n    df, \n  var = probability, scaleme=100, CI_choice_n=CI_choice_narrow, CI_choice_w = CI_choice_wide) {\n  df %>% \n    summarise(\n      mean = mean({{var}}) * scaleme,\n            lower_n = hdi({{var}}, credMass = CI_choice_n)[1] * scaleme,\n            upper_n = hdi({{var}}, credMass = CI_choice_n)[2] * scaleme,\n              lower_w = hdi({{var}}, credMass = CI_choice_w)[1] * scaleme,\n            upper_w = hdi({{var}}, credMass = CI_choice_w)[2] * scaleme,\n          lower_eti = quantile({{var}}, (1-CI_choice_w)/2) * scaleme,\n    upper_eti = quantile({{var}}, 1-(1-CI_choice_w)/2) * scaleme,\n      check = length(hdi({{var}}))\n    )\n} \n\n\nmutate_mean_hdi <- function(\n    df, \n  var = probability, scaleme=100, CI_choice_n=CI_choice_narrow, CI_choice_w = CI_choice_wide) {\n  df %>% \n    dplyr::mutate(\n      mean = mean({{var}}) * scaleme,\n            lower_n = hdi({{var}}, credMass = CI_choice_n)[1] * scaleme,\n            upper_n = hdi({{var}}, credMass = CI_choice_n)[2] * scaleme,\n              lower_w = hdi({{var}}, credMass = CI_choice_wide)[1] * scaleme,\n            upper_w = hdi({{var}}, credMass = CI_choice_wide)[2] * scaleme,\n          lower_eti = quantile({{var}}, (1-CI_choice_wide)/2) * scaleme,\n    upper_eti = quantile({{var}}, 1-(1-CI_choice_wide)/2) * scaleme,\n      check = length(hdi({{var}}))\n    )\n} \n\n\n\nResults by audience\nWe ran two Bayesian Logit models, presented above (Todo: tables summarizing these). Results come from a two-stage process: 1. some people who see the ad click on it. 2. Some of those who click on the ad leave their email (asking for a Giving Guide). We model clicks as a share of unique impressions (‘reach’) and results as a share of clicks, allowing each to vary by video theme and by audience. (Later: by text and by demographics.) The product of these shares (probabilities) yields results as a share of impressions, the main outcome of interest.\nBelow, we plot the point means (aka ‘coefficients’) and ‘highest density intervals’ (HDI) of our posterior beliefs for these. These models consider the audience and video themes at the same time, the imbalance between audiences and themes should probably not be a major biasing factor.\nCaveats:\n\nThe coefficients for the second stage (‘clicks to results’) should be taken lightly; as the audiences may be selected very differently ‘conditional on click’; e.g., audiences that are ‘easy to click’ may by ‘harder to convert ot a result’.\nThe results presented below do not control for ‘which text treatment’ nor for ‘which campaign’. (We can do the latter next, but we can only do the former with the other version of the data, which is then missing some detail on who saw which video)\nThe usual ‘divergent delivery’ issue\n\n\n\nCode\naud_plots <- function(df) {\n  df %>% \n       filter(audience!=\"Retargeting\")  %>%\n    group_by(level, audience) %>% #, starts\n    sum_mean_hdi %>% \n    mutate(audience = reorder(as.factor(audience), `mean`)) %>% \n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = audience), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = audience),  height=.25, color = \"blue\") +\n  geom_point(\n    aes(x=`mean`, \n    y = audience))\n    } \n\n(\nreach_to_clicks_aud_plot <-  full_post  %>%\n    aud_plots() +\n  labs(title = \"By audience (reach, clicks, signups)\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n\n\n\n\nCode\n(\nreach_to_clicks_aud_plot_no_cause <-  full_post  %>%\n    filter(!str_det(theme, \"Animal|Climate|Poverty\"))  %>%\n        aud_plots() +\n labs(title = \"By audience, no cause videos\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n\n\n\n\nCode\n(\nreach_to_clicks_aud_plot_cause <-  full_post  %>%\n    filter(str_det(theme, \"Animal|Climate|Poverty\"))  %>%\n        aud_plots() +\n labs(title = \"By audience, Cause videos only\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n\n)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote: the ‘pooled’ graphs in this section may not be correctly weighted across subcategories. We need to reexamine this.\n\n\nFor the ‘cause videos only’ we see 15 that the philanthropy audience, across all causes, seems to perform at least as well as the climate and ‘global poverty’ audiences (when the latter are presented videos for the causes they are said to care about). However, the animal audiences seems to perform substantially better.\nFor example, focusing on climate-cause videos (and removing ‘lookalikes’) below, we see that the philanthropy audience performs substantially better than the climate audience.\n\n\nCode\n(\nreach_to_clicks_aud_plot_climate <-  full_post  %>%\n    filter(str_det(theme, \"Climate\"))  %>%\n    filter(audience!=\"Lookalikes\") %>% \n        aud_plots() +\n labs(title = \"By audience, Climate videos only\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n\n)\n\n\n\n\n\n\n\n\n1.6.4 Results by Video (todo: fix weighting)\n\n\nCode\nvid_plots <- function(df) {\n  df %>% \n    group_by(level, theme) %>% #, starts\n    sum_mean_hdi %>% \n    mutate(theme = reorder(as.factor(theme), `mean`)) %>% \n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = theme), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = theme),  height=.25, color = \"blue\") +\n  geom_point(\n    aes(x=`mean`, \n    y = theme))\n    } \n\n(\nreach_to_clicks_vid_plot <-  full_post  %>%\n    vid_plots() +\n  labs(title = \"By video theme (reach, clicks, signups)\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n\n\n\n\nCode\n(\nreach_to_clicks_vid_plot_phil <-  full_post  %>%\n            filter(audience == \"Philanthropy\")  %>%\n    vid_plots() +\n  labs(title = \"By theme, 'philanthropy' audience only\",\n       x = \"Estimated % 'converting' with 60% and 90% HDI\")  +\n      facet_grid(~level, scales = \"free\")\n)\n\n\n\n\n\n\n\nCode\n(\nreach_to_clicks_plot <-  full_post  %>%\n      filter(grepl(\"1\", level)) %>% \n    group_by(theme, audience) %>% #, starts\n    sum_mean_hdi %>% \n      mutate(theme = reorder(as.factor(theme), `mean`)) %>% \n      filter(audience!=\"Retargeting\")  %>%\n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = theme), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = theme),  height=.25, color = \"blue\") +\n  geom_point(aes(x = mean, y = theme)) +\n  coord_cartesian(xlim=c(0, 1.75)) +\n  facet_wrap(~audience, scales = \"fixed\") +\n  labs(title = \"Clicks by video theme and audience\",\n       x = \"Estimated % clicking with 60% and 90% HDIs\") +\n  facet_wrap(~audience, scales = \"fixed\")\n)\n\n\n\n\n\nCode\n(\nreach_to_results_plot <-  full_post %>% \n      filter(grepl(\"3\", level)) %>% \n      group_by(theme, audience) %>% #, startslevel, \n      sum_mean_hdi %>% \n        mutate(theme = reorder(as.factor(theme), `mean`)) %>% \n      filter(audience!=\"Retargeting\")  %>%\n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = theme), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = theme),  height=.25, color = \"blue\") +  geom_point(aes(x = mean, y = theme)) +\n  facet_wrap(~audience, scales = \"fixed\") +\n    coord_cartesian(xlim=c(0, 0.8)) +\n  labs(title = \"Reach to results (total)\",\n       x = \"Estimated % results with 60% and 90% HDIs\") +\n  facet_wrap(~factor(audience, levels=audience_levels), scales = \"fixed\")\n)\n\n\n\n\n\nCode\n(\nreach_to_results_plot_flip <-  full_post %>% \n      filter(grepl(\"3\", level)) %>% \n      group_by(audience, theme) %>% #, startslevel, \n      sum_mean_hdi %>% \n        mutate(audience = reorder(as.factor(audience), `mean`)) %>% \n      filter(audience!=\"Retargeting\")  %>%\n    ggplot() + \n  geom_errorbarh(aes(xmin = lower_n, xmax = upper_n, y = audience), height = .7, color = \"red\") +\n  geom_errorbarh(aes(xmin = lower_w, xmax = upper_w, y = audience),  height=.25, color = \"blue\") +  geom_point(aes(x = mean, y = audience)) +\n  facet_wrap(~audience, scales = \"fixed\") +\n    coord_cartesian(xlim=c(0, 0.8)) +\n  labs(title = \"Reach to results (total)\",\n       x = \"Estimated % results with 60% and 90% HDIs\") +\n  facet_wrap(~theme, scales = \"fixed\")\n)\n\n\n\n\n\n\n\n1.6.5 Outcomes by cost\n\n\nCode\n# Joining spending and conversion ####\n\ncost_tibble <- \n  left_join(tib_combined_post,\n    rename(gg_video_breakdowns_col, theme=video_theme)) %>% \n  mutate(\n    reach_per_dollar = reach / spend,\n    sign_per_dollar = reach_per_dollar * probability,\n    #NOTE this uses the simulated distribution of probabilities, not just averages! \n    sign_per_100d = 100*sign_per_dollar,\n    cost_per_signup = 1/sign_per_dollar\n    ) %>% \n  filter(is.na(spend) == FALSE)  \n\ncost_summary <- cost_tibble %>% \n  group_by(theme, audience) %>% \n  sum_mean_hdi(var= sign_per_100d, scaleme=1)\n\n#dim(filter(cost_summary, check > 2))[1] ... where HDI is not continuous, I guess... this doesn't happen here atm\n\n\n\n\nCode\n(\n  sign_per_100d_plot_vid_by_aud <- cost_tibble %>%\n      filter(audience!=\"Retargeting\")  %>%\nggplot() +\n  scale_x_continuous(limits = c(0, 20)) +\n  ggridges::geom_density_ridges(\n    aes(\n      x = sign_per_100d, \n      y = theme\n      )\n    ) +\n  geom_point(data = cost_summary %>% filter(audience!=\"Retargeting\"), \n    aes(x = mean, y = theme)) +\n  labs(title = \"Signups per $100: Comparing videos by audience\",\n    x = \"Density plots, means\") +\n  facet_wrap(~factor(audience, levels = audience_levels), scales = \"free_x\"  )\n)\n\n\n\n\n\nCode\n# \n# ggplot(filter(cost_tibble, upper_eti < 100)) +\n#   geom_errorbarh(aes(xmin = lower_eti, xmax = upper_eti, y = audience)) +\n#   geom_point(aes(x = mean, y = audience)) +\n#   labs(title = \"Cost per signup ($)\",\n#     x = \"Estimated cost per signup (USD) with 95% ETI\") +\n#   facet_wrap(~theme, scales = \"free_x\")\n\n\nAbove we consider the cost effectiveness of each video by audience.\n‘Factual short’: 16 This video seems to perform as good or better than any other video for each of the cause audiences as well as for the Lookalike audience (but see cav eat). It performs nearly as good as other videos for the other audiences.\nClimate video: This seems to have performed best for the Philanthropy and General audiences, although the distribution is diffuse. Surprisingly, it does not perform best for the climate audience.\nBrand Video, Factual Long: These seemed to have performed worst or near-worst for most audiences. ‘Factual long’ seems to have clearly performed worse than ‘Factual short’ version. (But see caveat below.)\n\n\n\n\n\n\nCaveat/todo – Video/campaign date imbalance\n\n\n\n\n\nThere is substantial imbalance in dates the administration of treatments in the pooled data. E.g., the ‘Factual short’ video was the only one shown for the 2021-12-08 trial, which may confound the above result. The Brand Video was only shown in a single trial, where it was the only video shown. The ‘Factual long’ video was dropped in later trials (?possibly after poor performance in an explicit A/B test?). Again, confounds are certainly possible. We may want to either remove trials from dates that only ran a single trial (at a first pass), or include start date/campaign into our modeling.\n\n\n\n\n\nCode\n(\n  sign_per_100d_plot_aud_by_vid <- cost_tibble %>%\n      filter(audience!=\"Retargeting\" & audience!=\"General audience\")  %>%\nggplot() +\n  scale_x_continuous(limits = c(0, 20)) +\n  ggridges::geom_density_ridges(\n    aes(\n      x = sign_per_100d, \n      y = audience\n      )\n    ) +\n  geom_point(data = cost_summary %>% filter(audience!=\"Retargeting\" & audience!=\"General audience\"), \n    aes(x = mean, y = audience)) +\n  labs(title = \"Signups per $100: Comparing audiences for each video\",\n    x = \"Density plots, means\") +\n  facet_wrap(~theme, scales = \"free_x\")\n)\n\n\n\n\n\nFlipping the previous plot, we compare the cost-effectiveness of each audience for each video.17, 18\nThe Lookalike audiences are relatively cost-effective for most videos, although the Philanthropy audience seems to do better per dollar for the Climate video.\nThe cause audiences are relatively cost-effective for their ‘own’ videos, but not overwhelmingly so. They seemed particularly cost-ineffective for the Brand video."
  },
  {
    "objectID": "chapters/gwwc_gg.html#q_and_a",
    "href": "chapters/gwwc_gg.html#q_and_a",
    "title": "1  Giving What We Can: Giving guides",
    "section": "1.7 Asking and answering questions",
    "text": "1.7 Asking and answering questions\n\n\n\n\n\n\nThis dynamic document format allows us to ask and answer a series of questions\n\n\n\n\n\n\nUsing the data, with all coding steps shown\nIdeally, following a pre-defined (pre-analysis) plan\nUsing the data and statistics directly and automatically in the narrative\n\nAnd everything will be automatically adjusted if we bring in new data or adjust/correct features\n\n\n\n\n\n\nIn this context, how much does it cost to get a ’Result”, i.e., to get a person to give their email to receive a Giving Guide?\n\n\nWhich pre-defined audience yields a Result at the lowest cost? How does this cost vary by audience?\n\nRefer to models/estimates above\n\n\n\nCode\nlimits <- aes(ymax = mean_dv + (se_dv), ymin = mean_dv - (se_dv))\ndodge <- position_dodge(width = 0.9)\n\n\ngg_gg_options <- list(geom_bar(stat = 'identity', position=dodge),\n  geom_errorbar(limits, position=dodge,  width=0.25, color=\"red\"),\n  jtools::theme_apa(),\n  theme(legend.position=\"none\"),\n  geom_text(aes(label = paste(\"$\", mean_dv %>% round(.,2)), y=5), position = position_dodge(.9), size=4, color=\"white\"),\n  theme(text=element_text(size=10))\n)\n  \n\nlimits <- aes(ymax = mean_dv , ymin = mean_dv)\ndodge <- position_dodge(width = 0.9)\n\n\n\n(\n  result_by_age <-  gg_campaign_by_ad_by_text_age_gender %>%\n        mutate(results_per_100usd = results/(amount_spent_usd/100)) %>%\n     uncount(weights = .$reach) %>%\n   group_by(age) %>%\n  summarise(mean_dv = mean(results_per_100usd, na.rm=TRUE)) %>% \n  ggplot(aes(x=age, mean_dv)) +\n  geom_bar(stat='identity',fill=\"#0072B2\", position=dodge) +\n  ylab('Results/$ spent') +\n  xlab('Video') +\n  ggtitle('Results/$ spent by Age') \n#+  scale_x_discrete(labels=vid_types)\n)\n\n\n\n\n\n\n\nWhich pre-defined audience yields the highest ‘rate of Result’? How does this vary by audience?\nNote, this is not the same as the previous question because some audiences are more costly to target on Facebook.\n\nRe-run above models for ‘results per impression’\n\nImportant caveat: this does not tell us the effect ‘on a particular group’, because of FB’s optimization algorithms; see discussion here.\nInteractions/separate models for ‘vary by audience’.\n\n\nWhich video yields a Result at the highest rate/lowest cost?\n\n\nCode\n#Plot options in common\n\n#limits <- aes(ymax = mean_dv + (ci_spread), ymin = mean_dv - (ci_spread))\ndodge <- position_dodge(width = 0.9)\n\nvid_types <-\n  c(\"factual short\",\n    \"animal\",\n    \"climate\",\n    \"factual long\",\n    \"hypercube\",\n    \"poverty\")\n\n\n\ngrpsumgg <- function(df, gvar, var, ci_ends) {\n  df %>%\n  group_by({{gvar}}) %>%\n  summarise(mean_dv = mean({{var}}, na.rm=TRUE),\n            se_dv = sd({{var}}, na.rm=TRUE)/sqrt(n()),\n            ci_spread = qt(1 - (ci_ends / 2), n() - 1) * se_dv)\n}\n\n\n\n\nCode\ngg_video_breakdowns %>%\n        mutate(results_per_100usd = results/(amount_spent_usd/100)) %>%\n     uncount(weights = .$reach) %>%\n   group_by(video_theme) %>%\n  summarise(mean_dv = mean(results_per_100usd, na.rm=TRUE)) %>% \n  #grpsumgg(video_theme, results_per_100usd, 0.1) %>%\n  ggplot(aes(x=video_theme, mean_dv)) +\n  geom_bar(stat='identity',fill=\"#0072B2\", position=dodge) +\n  #gg_gg_options +\n  ylab('Results/$ spent') +\n  xlab('Video') +\n  #ggtitle('Results/$ spent by Video, 90% CIs') +\n  ggtitle('Results/$ spent by Video') +\n  scale_x_discrete(labels=vid_types)\n\n\n\n\n\nCode\n# gwwc_vid_results %>%\n#   grpsumgg(media, DV_costadj, 0.1) %>%\n#   ggplot(aes(x=media, y=mean_dv)) +\n#   geom_bar(stat='identity',fill=\"#0072B2\", position=dodge) +\n#   gg_gg_options +\n#   ylab('Results/$ spent') +\n#   xlab('Video') +\n#   ggtitle('Results/$ spent by Video, 90% CIs') +\n#   scale_y_continuous(limits = c(0,.2),  breaks=seq(0,.2, by=.05)) +\n#   scale_x_discrete(labels=vid_types)\n# \n\n\n\nRefer to models/estimates above, coefficient on ‘video’\n\n19\n\nHow does the ‘best video’ vary by audience?\n\nInclude interactions in above model\nRun model separately for each group (or allowing everything to interact) for robustness\nAlso consider ‘what did FB serve to each group’, assuming it is optimizing.\n\n\n\nAggregating: Which category of videos yields a result at the highest rate/lowest cost? (“Facts”, “Cause focus”, or “Arguments, rich content”)\n\nAbove, pooling videos of similar type. (Random effects models?)\n\n\n\n\nWhich message yields a Result at the highest rate/lowest cost?\n20\nSub-questions\n\nHow does the ‘best message’ vary by audience?\n\n\n\n\n\n\nOther questions (less interest or less feasible)\n\n\n\n\n\n\nDo the message treatments ‘interact’ with the video treatments (i.e., are their synergies and better pairings)?\nDo some videos lead to higher click rates?\nDo some videos lead to higher watch rates?"
  }
]